{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/ipykernel/__main__.py:16: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3,4,5,6,7'\n",
    "import yaml\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import utils.train_util as train_util\n",
    "from dataloader.dataloader import TestingDataset,MultimodaFeaturesDataset\n",
    "from src.loss.loss_compute import SimpleLossCompute\n",
    "from src.model.baseline_model import Baseline\n",
    "from src.loop.run_epoch import training_loop,validating_loop\n",
    "\n",
    "config_path = './config/config.yaml'\n",
    "config = yaml.load(open(config_path))\n",
    "train_dataset = MultimodaFeaturesDataset(config['DatasetConfig'],job='training')\n",
    "val_dataset = MultimodaFeaturesDataset(config['DatasetConfig'],job='valdation')\n",
    "test_dataset = TestingDataset(config['DatasetConfig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.5063, -1.3404, -1.0076,  ..., -0.9102,  0.0265,  1.1618],\n",
       "         [ 1.2224, -0.9595, -0.9289,  ..., -0.0388, -0.0936,  0.5921],\n",
       "         [ 1.7696, -1.0206, -1.0104,  ...,  1.5784, -0.6792,  0.5998],\n",
       "         ...,\n",
       "         [ 1.8942, -0.9977, -0.9623,  ...,  0.8192, -0.7299,  0.7455],\n",
       "         [ 1.7594, -0.8933, -0.9115,  ...,  0.5582, -0.9112, -0.2808],\n",
       "         [ 1.5019, -0.5789, -1.0068,  ...,  0.8961, -0.6365,  0.9117]]),\n",
       " tensor([[ 1.1552, -1.7376,  0.2501,  ..., -0.4245,  0.0156,  6.6787],\n",
       "         [ 0.7874, -1.8205,  1.2265,  ..., -0.0799, -0.3481,  6.8582],\n",
       "         [ 0.7530, -1.6834,  1.3468,  ..., -0.7737, -1.6918,  5.6804],\n",
       "         ...,\n",
       "         [ 0.6713, -1.8014,  0.8079,  ...,  0.3014, -0.5942,  6.2051],\n",
       "         [ 0.8289, -1.6909,  1.1255,  ...,  0.0485, -0.7019,  4.8522],\n",
       "         [ 0.7106, -1.8769,  1.0616,  ...,  2.0977, -1.1343,  6.8735]]),\n",
       " tensor([ 101,  872, 2157, 7770,  704, 4495, 3221,  679, 3221, 6820, 1905,  754,\n",
       "         6821, 3416, 4638, 7348, 3667, 6427, 3152,  671, 5663, 3144, 2110, 2159,\n",
       "         3211, 2309, 3971, 4289, 4415, 6375,  782, 2552, 4810, 5739, 6427, 3683,\n",
       "         6772, 7575, 2426, 2769, 2972, 5773, 2792, 3300, 2157, 7270, 2845, 1399,\n",
       "         6821,  702, 7770, 6854, 6440, 1828, 1159, 7770, 1059, 4906, 1399, 2360,\n",
       "         4408,  712, 6382, 1399, 2360, 3341, 5632, 3680, 2399, 6963, 5543, 6783,\n",
       "         6843,  677, 4636, 1399, 1266, 1920, 3926, 1290, 2110, 2094, 4638,  671,\n",
       "         5296, 1399, 3413,  800,  812,  704, 3300,  704, 7770, 5440, 4777, 4955,\n",
       "          683, 2157, 4689, 5277, 7770, 5440, 4307, 1039, 5023, 2398, 1772, 3136,\n",
       "         7977, 2399, 6427, 3152, 7325, 6438,  676, 3635, 3791, 3144, 2110, 7770,\n",
       "         5440, 1920, 2553, 5440, 3563, 3352, 5739, 6427, 1296, 6404, 6381, 2554,\n",
       "         3791, 4289, 4415, 1366, 6394, 3791, 5320, 5320, 3136, 5314,  872, 6440,\n",
       "         4923, 5165, 6585, 3136, 3332, 6820, 3118, 2898, 2399, 1079, 3187, 7361,\n",
       "         3613, 1726, 3123, 2157, 7270,  812, 4385, 1762, 4157, 1140, 6228, 7574,\n",
       "          678, 3175, 6848, 2885, 2190, 2418, 2399, 5277, 2218, 1377,  809, 2845,\n",
       "         1399, 1568, 7770, 6854, 6440, 1828, 3851, 3736, 1310, 6228, 7770, 6854,\n",
       "         6440, 1828, 3851, 3736, 1310, 6228, 1059, 1744, 4636,  881, 3136, 2360,\n",
       "         2372, 7339, 3136, 2110, 2398, 1772, 3136, 7977, 2399, 1159, 7770, 1059,\n",
       "         4906, 1399, 2360, 4408, 3173, 4500, 2787,  683,  775, 4989, 1315,  860,\n",
       "         7741, 3851, 3736, 1310, 6228, 2900, 2137, 1762, 5296, 3136, 5509, 1501,\n",
       "         4277, 1399, 2360, 4294, 6378, 4408, 6375,  872, 1914, 6438,  741, 1290,\n",
       "         2208,  788, 7444,  102]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_py3",
   "language": "python",
   "name": "conda_pytorch_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
