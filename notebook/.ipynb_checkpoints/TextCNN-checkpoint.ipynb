{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting jieba\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/c6/cb/18eeb235f833b726522d7ebed54f2278ce28ba9438e3135ab0278d9792a2/jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.2 MB 783 kB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314478 sha256=2cf68e2c7eadaaa16b73f320033d4344c819555a06e50ce0b70d2b6c6439ce34\n",
      "  Stored in directory: /home/tione/.cache/pip/wheels/de/99/39/55dd43d023169a4464b9118a252e188367c3750c62526c46f3\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.42.1\n"
     ]
    }
   ],
   "source": [
    "!pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TextCnn(nn.Module):\n",
    "    def __init__(self, embed_num, embed_dim, class_num, kernel_num, kernel_sizes, dropout = 0.5):\n",
    "        super(TextCnn, self).__init__()\n",
    "\n",
    "        Ci = 1\n",
    "        Co = kernel_num\n",
    "\n",
    "        self.embed = nn.Embedding(embed_num, embed_dim)\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(Ci, Co, (f, embed_dim), padding = (2, 0)) for f in kernel_sizes])\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(Co * len(kernel_sizes), class_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)  # (N, token_num, embed_dim)\n",
    "        x = x.unsqueeze(1)  # (N, Ci, token_num, embed_dim)\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, token_num) * len(kernel_sizes)]\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co) * len(kernel_sizes)]\n",
    "        x = torch.cat(x, 1) # (N, Co * len(kernel_sizes))\n",
    "        x = self.dropout(x)  # (N, Co * len(kernel_sizes))\n",
    "        logit = self.fc(x)  # (N, class_num)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodaFeaturesDataset(Dataset):\n",
    "\n",
    "    def __init__(self,dataset_config,job='training'):\n",
    "        \n",
    "        self.data_num_per_sample = 6 # 在train.txt中每个sample占6行\n",
    "        self.text_max_len = dataset_config['text_max_len']\n",
    "        self.device = dataset_config['device']\n",
    "        \n",
    "        if(job=='training'):\n",
    "            self.meta_path = dataset_config['train_data_path']\n",
    "        elif(job=='valdation'):\n",
    "            self.meta_path = dataset_config['val_data_path']\n",
    "        else:\n",
    "            self.meta_path = dataset_config['test_data_path']\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(dataset_config['bert_path'])\n",
    "        self.label2id = {}\n",
    "        with open(dataset_config['label_id_path'],'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip('\\r\\n')\n",
    "                line = line.split('\\t')\n",
    "                self.label2id[line[0]] = int(line[1])\n",
    "    def __getitem__(self, index):\n",
    "        # 1. 从train.txt读取对应 idx 的path\n",
    "        data_list = [] # 存储对于index的各个模态数据的路径和样本标签\n",
    "        for line_i in range(self.data_num_per_sample*index+1,self.data_num_per_sample*(index+1)):\n",
    "            line = linecache.getline(self.meta_path,line_i)\n",
    "            line = line.strip('\\r\\n')\n",
    "            data_list.append(line)\n",
    "        video,audio,text_ids,text_attention_mask,label_ids = self.preprocess(data_list)\n",
    "        return video,audio,text_ids,text_attention_mask,label_ids\n",
    "    def __len__(self):\n",
    "        # TODO 不能固定长度\n",
    "        with open(self.meta_path,'r') as f:\n",
    "            lines = f.readlines()\n",
    "        return len(lines)//self.data_num_per_sample\n",
    "    def preprocess(self,data_list):\n",
    "        \n",
    "        video_path,audio_path,image_path,text_path,label = data_list\n",
    "        \n",
    "        #--------------- video ----------------#\n",
    "        video = torch.tensor(np.load(video_path).astype(np.float32))\n",
    "        \n",
    "        #--------------- audio ----------------#\n",
    "        if os.path.exists(audio_path):\n",
    "            audio = torch.tensor(np.load(audio_path).astype(np.float32))\n",
    "        else:\n",
    "            audio = torch.tensor(np.random.random((video.shape[0],128)).astype(np.float32))\n",
    "            \n",
    "        #--------------- text ----------------#\n",
    "        \n",
    "        text = ''\n",
    "        with open(text_path,'r') as f:\n",
    "            for line in f:\n",
    "                dic = eval(line)\n",
    "           \n",
    "        for key in dic:\n",
    "            dic[key] = ''.join(re.findall('[\\u4e00-\\u9fa5]',dic[key]))\n",
    "            text += dic[key]\n",
    "        \n",
    "        # text = ''.join(re.findall('[\\u4e00-\\u9fa5]',dic['video_asr']))\n",
    "        inputs = \n",
    "        text_ids = inputs['input_ids']\n",
    "        text_attention_mask = inputs['attention_mask']\n",
    "        text_ids = torch.tensor(np.array(text_ids).astype('int64'))\n",
    "        text_attention_mask = torch.tensor(np.array(text_attention_mask).astype('int64'))\n",
    "        #--------------- label ----------------#\n",
    "        label_ids = []\n",
    "        label = label.split(',')\n",
    "        np.random.shuffle(label)\n",
    "        for i in label:\n",
    "            label_ids.append(self.label2id[i])\n",
    "        # label_ids = torch.tensor(np.array(label_ids).astype('int64'))\n",
    "        dense_label_ids = torch.zeros(82)# ,dtype=torch.int64)\n",
    "        dense_label_ids[label_ids] = 1\n",
    "        # return video,audio,label_ids\n",
    "        return video,audio,text_ids,text_attention_mask,dense_label_ids\n",
    "    \n",
    "    def collate_fn(self,batch):\n",
    "        # 自定义dataloader 对一个batch的处理方式\n",
    "        # 需要完成的任务有：\n",
    "        # 1. 对video和audio的序列进行padding\n",
    "        # 2. 对text，label_ids同样padding\n",
    "        video_stacks = []\n",
    "        audio_stacks = []\n",
    "        text_stacks = []\n",
    "        label_stacks = []\n",
    "        text_attention_stacks = []\n",
    "        for i in batch:\n",
    "            video_stacks.append(i[0])\n",
    "            audio_stacks.append(i[1])\n",
    "            text_stacks.append(i[2])\n",
    "            text_attention_stacks.append(i[3])\n",
    "            label_stacks.append(i[4])\n",
    "        \n",
    "        video_stacks = pad_sequence(video_stacks,batch_first=True,padding_value=0)\n",
    "        audio_stacks = pad_sequence(audio_stacks,batch_first=True,padding_value=0)\n",
    "        text_stacks = pad_sequence(text_stacks,batch_first=True,padding_value=0) # 实际上没有pad\n",
    "        # 实际上并没有padding，因为label变成multi-hot向量，长度都是82\n",
    "        label_stacks = pad_sequence(label_stacks,batch_first=True,padding_value=0) \n",
    "        text_attention_stacks = pad_sequence(text_attention_stacks,batch_first=True,padding_value=0) # 实际上也没有pad\n",
    "        return video_stacks,audio_stacks,text_stacks,text_attention_stacks,label_stacks\n",
    "        # return video_stacks,audio_stacks,label_stacks\n",
    "    def tokenize(text):\n",
    "        return [word for word in jieba.cut(text) if word.strip()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_py3",
   "language": "python",
   "name": "conda_pytorch_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
