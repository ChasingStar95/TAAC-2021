{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting albumentations\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/b0/be/3db3cd8af771988748f69eace42047d5edebf01eaa7e1293f3b3f75f989e/albumentations-1.0.0-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 8.1 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from albumentations) (5.3.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from albumentations) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from albumentations) (1.18.5)\n",
      "Collecting scikit-image>=0.16.1\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/0e/ba/53e1bfbdfd0f94514d71502e3acea494a8b4b57c457adbc333ef386485da/scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 11.7 MB/s eta 0:00:01    |██████████▌                     | 4.1 MB 11.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-python-headless>=4.1.1\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/cc/09/3ed889f37b1bb1dff85f10d91b1f9e8b8a812a7e8413c4e906c21aab9469/opencv_python_headless-4.5.2.52-cp36-cp36m-manylinux2014_x86_64.whl (38.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 38.2 MB 469 kB/s eta 0:00:011     |███████████                     | 13.1 MB 25.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n",
      "Collecting imageio>=2.3.0\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/6e/57/5d899fae74c1752f52869b613a8210a2480e1a69688e65df6cb26117d45d/imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 7.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from scikit-image>=0.16.1->albumentations) (2.2.2)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/42/6b/93a8ee61c6fbe20fa9c17928bd3b80484902b7fd454cecaffba42f5052cb/tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
      "\u001b[K     |████████████████████████████████| 148 kB 69.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx>=2.0\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/f3/b7/c7f488101c0bb5e4178f3cde416004280fd40262433496830de8a8c21613/networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 19.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/59/bb/d2b85265ec9fa3c1922210c9393d4cdf7075cc87cce6fe671d7455f80fbc/PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 77.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2020.1)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.2.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
      "Installing collected packages: imageio, tifffile, networkx, PyWavelets, scikit-image, opencv-python-headless, albumentations\n",
      "Successfully installed PyWavelets-1.1.1 albumentations-1.0.0 imageio-2.9.0 networkx-2.5.1 opencv-python-headless-4.5.2.52 scikit-image-0.17.2 tifffile-2020.9.3\n",
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting transformers\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dataclasses; python_version < \"3.7\"\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/fe/ca/75fac5856ab5cfa51bbbcefa250182e50441074fdc3f803f6e76451fab43/dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from transformers) (1.18.5)\n",
      "Collecting filelock\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/93/83/71a2ee6158bb9f39a90c0dea1637f81d5eef866e188e1971a1b1ab01a35a/filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from transformers) (2.24.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/6b/38/0ed2670578d803cb14350c54adb2a79835870aa9e3ad2e732be7359cb0e8/regex-2021.4.4-cp36-cp36m-manylinux2014_x86_64.whl (722 kB)\n",
      "\u001b[K     |████████████████████████████████| 722 kB 9.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from transformers) (4.46.1)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/bf/20/3605db440db4f96d5ffd66b231a043ae451ec7e5e4d1a2fb6f20608006c4/tokenizers-0.10.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 14.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 79.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from transformers) (1.7.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from requests->transformers) (1.25.9)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from sacremoses->transformers) (0.15.1)\n",
      "Requirement already satisfied: six in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Collecting click\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/76/0a/b6c5f311e32aeb3b406e03c079ade51e905ea630fc19d1262a46249c1c86/click-8.0.1-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 21.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from packaging->transformers) (2.4.7)\n",
      "Installing collected packages: dataclasses, filelock, regex, huggingface-hub, tokenizers, click, sacremoses, transformers\n",
      "Successfully installed click-8.0.1 dataclasses-0.8 filelock-3.0.12 huggingface-hub-0.0.8 regex-2021.4.4 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n",
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting tensorboard\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/44/f5/7feea02a3fb54d5db827ac4b822a7ba8933826b36de21880518250b8733a/tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 7.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/bd/24/11c3ea5a7e866bf2d97f0501d0b4b1c9bbeade102bb4b588f0d2919a5212/Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "\u001b[K     |████████████████████████████████| 288 kB 20.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/35/d2/0a79bc7e201c1b38ce46d607eb9398dc362dff1b054c7bba8e4e195c2ed7/google_auth-1.30.1-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 15.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/9d/d3/7541e89f1fc456eef157224f597a8bba22589db6369a03eaba68c11f07a0/google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from tensorboard) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from tensorboard) (47.3.1.post20200616)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/0e/4b/c4e1839cdb3248e1006837e1d427e1843f80f2e6ba69f3af77f00bb51ac4/grpcio-1.38.0-cp36-cp36m-manylinux2014_x86_64.whl (4.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 7.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/1a/c1/499e600ba0c618b451cd9c425ae1c177249940a2086316552fee7d86c954/tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 25.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/60/f9/802efd84988bffd9f644c03b6e66fde8e76c3aa33db4279ddd11c5d61f4b/tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 73.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.4\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/92/c9/ef0fae29182d7a867d203f0eff8296b60da92098cc41db33a434f4be84bf/absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "\u001b[K     |████████████████████████████████| 129 kB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/6e/33/1ae0f71395e618d6140fbbc9587cc3156591f748226075e0f7d6f9176522/Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 62.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.12.0 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from tensorboard) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from tensorboard) (3.12.2)\n",
      "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard) (0.8)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/bf/28/c4f5796c67ad06bb91d98d543a5e01805c1ff065e08871f78e52d2a331ad/cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 68.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/e9/93/0c0f002031f18b53af7a6166103c02b9c0667be528944137cc954ec921b3/rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard) (1.15.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (1.7.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 64.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/e8/5d/9dd1c29e5a786525f6342f6c1d812ed2e37edc653ad297048c1668988053/oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 72.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.1.0)\n",
      "Installing collected packages: werkzeug, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, grpcio, tensorboard-plugin-wit, tensorboard-data-server, absl-py, markdown, tensorboard\n",
      "Successfully installed absl-py-0.12.0 cachetools-4.2.2 google-auth-1.30.1 google-auth-oauthlib-0.4.4 grpcio-1.38.0 markdown-3.3.4 oauthlib-3.1.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 werkzeug-2.0.1\n",
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting torchtext==0.5\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/79/ef/54b8da26f37787f5c670ae2199329e7dccf195c060b25628d99e587dac51/torchtext-0.5.0-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 9.4 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from torchtext==0.5) (1.4.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from torchtext==0.5) (1.15.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from torchtext==0.5) (1.18.5)\n",
      "Collecting sentencepiece\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 14.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from torchtext==0.5) (2.24.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from torchtext==0.5) (4.46.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from requests->torchtext==0.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from requests->torchtext==0.5) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from requests->torchtext==0.5) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from requests->torchtext==0.5) (2020.6.20)\n",
      "Installing collected packages: sentencepiece, torchtext\n",
      "Successfully installed sentencepiece-0.1.95 torchtext-0.5.0\n",
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting jieba\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/c6/cb/18eeb235f833b726522d7ebed54f2278ce28ba9438e3135ab0278d9792a2/jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.2 MB 495 kB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314478 sha256=ad0f1a74600eb9a91637adf061bb3640fdd2980fcaf21dea7f05642fd53c4c7b\n",
      "  Stored in directory: /home/tione/.cache/pip/wheels/de/99/39/55dd43d023169a4464b9118a252e188367c3750c62526c46f3\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.42.1\n"
     ]
    }
   ],
   "source": [
    "!./setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "initialization: Kaiming\n",
      "train (0): 100%|██████████████████████████████| 141/141 [02:12<00:00,  1.07it/s]\n",
      "2e-05\n",
      "epoch(0)(video):  0.517427510163736\n",
      "epoch(0)(audio):  0.6356625087667326\n",
      "epoch(0)(text):  0.6442729874090938\n",
      "epoch(0)(fusion):  0.6651918289236867\n",
      "train (1): 100%|██████████████████████████████| 141/141 [02:07<00:00,  1.10it/s]\n",
      "4e-05\n",
      "train (2): 100%|██████████████████████████████| 141/141 [02:09<00:00,  1.09it/s]\n",
      "6e-05\n",
      "epoch(2)(video):  0.6626732556639149\n",
      "epoch(2)(audio):  0.6577208178481936\n",
      "epoch(2)(text):  0.6812049369343561\n",
      "epoch(2)(fusion):  0.7039961134936991\n",
      "train (3): 100%|██████████████████████████████| 141/141 [02:09<00:00,  1.09it/s]\n",
      "8e-05\n",
      "train (4): 100%|██████████████████████████████| 141/141 [02:09<00:00,  1.09it/s]\n",
      "0.0001\n",
      "epoch(4)(video):  0.6807132379751395\n",
      "epoch(4)(audio):  0.6543855010033326\n",
      "epoch(4)(text):  0.7023032519548927\n",
      "epoch(4)(fusion):  0.7344206985630717\n",
      "train (5): 100%|██████████████████████████████| 141/141 [02:09<00:00,  1.09it/s]\n",
      "0.0001\n",
      "train (6): 100%|██████████████████████████████| 141/141 [02:10<00:00,  1.08it/s]\n",
      "0.0001\n",
      "epoch(6)(video):  0.6926362755411274\n",
      "epoch(6)(audio):  0.6642457327327749\n",
      "epoch(6)(text):  0.7150901552172416\n",
      "epoch(6)(fusion):  0.7475099635074646\n",
      "train (7): 100%|██████████████████████████████| 141/141 [02:10<00:00,  1.08it/s]\n",
      "0.0001\n",
      "train (8): 100%|██████████████████████████████| 141/141 [02:09<00:00,  1.09it/s]\n",
      "0.0001\n",
      "epoch(8)(video):  0.6982162851226831\n",
      "epoch(8)(audio):  0.6691726015310235\n",
      "epoch(8)(text):  0.708784741033079\n",
      "epoch(8)(fusion):  0.7494426170770344\n",
      "train (9): 100%|██████████████████████████████| 141/141 [02:10<00:00,  1.08it/s]\n",
      "0.0001\n",
      "train (10): 100%|█████████████████████████████| 141/141 [02:10<00:00,  1.08it/s]\n",
      "0.0001\n",
      "epoch(10)(video):  0.7002808834322118\n",
      "epoch(10)(audio):  0.6629185154420751\n",
      "epoch(10)(text):  0.7202167079488886\n",
      "epoch(10)(fusion):  0.7545019451876807\n",
      "train (11): 100%|█████████████████████████████| 141/141 [02:10<00:00,  1.08it/s]\n",
      "0.0001\n",
      "train (12): 100%|█████████████████████████████| 141/141 [02:10<00:00,  1.08it/s]\n",
      "0.0001\n",
      "epoch(12)(video):  0.7128508012230025\n",
      "epoch(12)(audio):  0.6728096716387874\n",
      "epoch(12)(text):  0.7262110293333539\n",
      "epoch(12)(fusion):  0.7621318825902368\n",
      "train (13): 100%|█████████████████████████████| 141/141 [02:10<00:00,  1.08it/s]\n",
      "0.0001\n",
      "train (14): 100%|█████████████████████████████| 141/141 [02:09<00:00,  1.08it/s]\n",
      "0.0001\n",
      "epoch(14)(video):  0.7092555773772545\n",
      "epoch(14)(audio):  0.6723249331038568\n",
      "epoch(14)(text):  0.7258789491388037\n",
      "epoch(14)(fusion):  0.7621809133750744\n",
      "train (15): 100%|█████████████████████████████| 141/141 [02:10<00:00,  1.08it/s]\n",
      "0.0001\n",
      "train (16): 100%|█████████████████████████████| 141/141 [02:09<00:00,  1.08it/s]\n",
      "0.0001\n",
      "epoch(16)(video):  0.7093045256242299\n",
      "epoch(16)(audio):  0.6735126251958484\n",
      "epoch(16)(text):  0.7263104007374884\n",
      "epoch(16)(fusion):  0.7643975205125996\n",
      "train (17): 100%|█████████████████████████████| 141/141 [02:09<00:00,  1.08it/s]\n",
      "0.0001\n",
      "train (18): 100%|█████████████████████████████| 141/141 [02:10<00:00,  1.08it/s]\n",
      "0.0001\n",
      "epoch(18)(video):  0.7086770544893889\n",
      "epoch(18)(audio):  0.6773978030771984\n",
      "epoch(18)(text):  0.7227936188578983\n",
      "epoch(18)(fusion):  0.7655603300126852\n",
      "train (19): 100%|█████████████████████████████| 141/141 [02:10<00:00,  1.08it/s]\n",
      "0.0001\n",
      "train (20): 100%|█████████████████████████████| 141/141 [02:10<00:00,  1.08it/s]\n",
      "1e-05\n",
      "epoch(20)(video):  0.7159478499345407\n",
      "epoch(20)(audio):  0.6793923668007673\n",
      "epoch(20)(text):  0.729203439604124\n",
      "epoch(20)(fusion):  0.7692438530298444\n",
      "train (21): 100%|█████████████████████████████| 141/141 [02:09<00:00,  1.08it/s]\n",
      "1e-05\n",
      "train (22): 100%|█████████████████████████████| 141/141 [02:09<00:00,  1.09it/s]\n",
      "1e-05\n",
      "epoch(22)(video):  0.7187659334303496\n",
      "epoch(22)(audio):  0.6793999544319341\n",
      "epoch(22)(text):  0.7289219350287953\n",
      "epoch(22)(fusion):  0.7716135444780211\n",
      "train (23): 100%|█████████████████████████████| 141/141 [02:10<00:00,  1.08it/s]\n",
      "1e-05\n",
      "train (24): 100%|█████████████████████████████| 141/141 [02:09<00:00,  1.09it/s]\n",
      "1e-05\n",
      "epoch(24)(video):  0.7193516314710378\n",
      "epoch(24)(audio):  0.6818922145237492\n",
      "epoch(24)(text):  0.7286535416388524\n",
      "epoch(24)(fusion):  0.7718408066928676\n",
      "train (25): 100%|█████████████████████████████| 141/141 [02:10<00:00,  1.08it/s]\n",
      "1e-05\n",
      "train (26): 100%|█████████████████████████████| 141/141 [02:10<00:00,  1.08it/s]\n",
      "1e-05\n",
      "epoch(26)(video):  0.7182577331464088\n",
      "epoch(26)(audio):  0.6794852337855913\n",
      "epoch(26)(text):  0.7269907341509622\n",
      "epoch(26)(fusion):  0.7681450871240783\n",
      "train (27): 100%|█████████████████████████████| 141/141 [02:10<00:00,  1.08it/s]\n",
      "1e-05\n",
      "train (28): 100%|█████████████████████████████| 141/141 [02:10<00:00,  1.08it/s]\n",
      "1e-05\n",
      "epoch(28)(video):  0.7195963689999955\n",
      "epoch(28)(audio):  0.6802178389351028\n",
      "epoch(28)(text):  0.7264565835821809\n",
      "epoch(28)(fusion):  0.769904508299242\n",
      "train (29): 100%|█████████████████████████████| 141/141 [02:09<00:00,  1.08it/s]\n",
      "1e-05\n",
      "train (30): 100%|█████████████████████████████| 141/141 [02:10<00:00,  1.08it/s]\n",
      "1e-05\n",
      "epoch(30)(video):  0.7187741162918928\n",
      "epoch(30)(audio):  0.6809396774887975\n",
      "epoch(30)(text):  0.7268530078762611\n",
      "epoch(30)(fusion):  0.770952374426247\n",
      "train (31): 100%|█████████████████████████████| 141/141 [02:09<00:00,  1.09it/s]\n",
      "1e-05\n",
      "train (32):  32%|█████████▌                    | 45/141 [00:53<01:16,  1.26it/s]^C\n"
     ]
    }
   ],
   "source": [
    "# 三个模态 raw + classifier head修改\n",
    "!python -W ignore main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "initialization: Kaiming\n",
      "train (0): 100%|██████████████████████████████| 141/141 [01:21<00:00,  1.72it/s]\n",
      "2e-05\n",
      "epoch(0)(video):  0.604442537655402\n",
      "epoch(0)(audio):  0.63144968581377\n",
      "epoch(0)(text):  0.6717858308069573\n",
      "epoch(0)(fusion):  0.6773704157621776\n",
      "train (1): 100%|██████████████████████████████| 141/141 [01:20<00:00,  1.75it/s]\n",
      "4e-05\n",
      "train (2): 100%|██████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "6e-05\n",
      "epoch(2)(video):  0.6900283814418575\n",
      "epoch(2)(audio):  0.6610275997184704\n",
      "epoch(2)(text):  0.6941606418126337\n",
      "epoch(2)(fusion):  0.7155593426745501\n",
      "train (3): 100%|██████████████████████████████| 141/141 [01:20<00:00,  1.74it/s]\n",
      "8e-05\n",
      "train (4): 100%|██████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "0.0001\n",
      "epoch(4)(video):  0.6987112124631798\n",
      "epoch(4)(audio):  0.6486082687504475\n",
      "epoch(4)(text):  0.7109523778044713\n",
      "epoch(4)(fusion):  0.740197414793946\n",
      "train (5): 100%|██████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "0.0001\n",
      "train (6): 100%|██████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "0.0001\n",
      "epoch(6)(video):  0.7110235533715371\n",
      "epoch(6)(audio):  0.6657835735177384\n",
      "epoch(6)(text):  0.7160090420902269\n",
      "epoch(6)(fusion):  0.7525114203762983\n",
      "train (7): 100%|██████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "0.0001\n",
      "train (8): 100%|██████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "0.0001\n",
      "epoch(8)(video):  0.7139646890648426\n",
      "epoch(8)(audio):  0.6682295622480683\n",
      "epoch(8)(text):  0.7253360937731321\n",
      "epoch(8)(fusion):  0.7550725305782644\n",
      "train (9): 100%|██████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "0.0001\n",
      "train (10): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "0.0001\n",
      "epoch(10)(video):  0.7160854287533681\n",
      "epoch(10)(audio):  0.6646747287790844\n",
      "epoch(10)(text):  0.725798455319558\n",
      "epoch(10)(fusion):  0.760333367774347\n",
      "train (11): 100%|█████████████████████████████| 141/141 [01:20<00:00,  1.74it/s]\n",
      "0.0001\n",
      "train (12): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "0.0001\n",
      "epoch(12)(video):  0.7221094107905889\n",
      "epoch(12)(audio):  0.6746634463454094\n",
      "epoch(12)(text):  0.7288901793861152\n",
      "epoch(12)(fusion):  0.7652921166722352\n",
      "train (13): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "0.0001\n",
      "train (14): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "0.0001\n",
      "epoch(14)(video):  0.7260205971153234\n",
      "epoch(14)(audio):  0.6787773431937187\n",
      "epoch(14)(text):  0.7273898877173515\n",
      "epoch(14)(fusion):  0.7677470469435166\n",
      "train (15): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "0.0001\n",
      "train (16): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "0.0001\n",
      "epoch(16)(video):  0.7222856757639197\n",
      "epoch(16)(audio):  0.6733597789060194\n",
      "epoch(16)(text):  0.7285909275954469\n",
      "epoch(16)(fusion):  0.7678510627323352\n",
      "train (17): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "0.0001\n",
      "train (18): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "0.0001\n",
      "epoch(18)(video):  0.7217951467434217\n",
      "epoch(18)(audio):  0.6761161742408933\n",
      "epoch(18)(text):  0.7196033979189301\n",
      "epoch(18)(fusion):  0.768467950688929\n",
      "train (19): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "0.0001\n",
      "train (20): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1e-05\n",
      "epoch(20)(video):  0.7264130852316815\n",
      "epoch(20)(audio):  0.6808238990421379\n",
      "epoch(20)(text):  0.7354104111684229\n",
      "epoch(20)(fusion):  0.7752373071583872\n",
      "train (21): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1e-05\n",
      "train (22): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1e-05\n",
      "epoch(22)(video):  0.7309117094582886\n",
      "epoch(22)(audio):  0.6829289168343715\n",
      "epoch(22)(text):  0.734039993593387\n",
      "epoch(22)(fusion):  0.7745898738674086\n",
      "train (23): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1e-05\n",
      "train (24): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1e-05\n",
      "epoch(24)(video):  0.7308077420514177\n",
      "epoch(24)(audio):  0.6849142904175559\n",
      "epoch(24)(text):  0.7367298467320331\n",
      "epoch(24)(fusion):  0.7768917056362271\n",
      "train (25): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1e-05\n",
      "train (26): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1e-05\n",
      "epoch(26)(video):  0.7306767923052243\n",
      "epoch(26)(audio):  0.6839027801972261\n",
      "epoch(26)(text):  0.7339786263049131\n",
      "epoch(26)(fusion):  0.7756946588399581\n",
      "train (27): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1e-05\n",
      "train (28): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1e-05\n",
      "epoch(28)(video):  0.7303149412138817\n",
      "epoch(28)(audio):  0.6861119366342892\n",
      "epoch(28)(text):  0.7337700253424789\n",
      "epoch(28)(fusion):  0.776645297319104\n",
      "train (29): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1e-05\n",
      "train (30): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1e-05\n",
      "epoch(30)(video):  0.7300553773234476\n",
      "epoch(30)(audio):  0.6858998647775989\n",
      "epoch(30)(text):  0.7333368089558915\n",
      "epoch(30)(fusion):  0.7770046653889066\n",
      "train (31): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1e-05\n",
      "train (32): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1e-05\n",
      "epoch(32)(video):  0.7293605735606712\n",
      "epoch(32)(audio):  0.6843639568641556\n",
      "epoch(32)(text):  0.7331516419967921\n",
      "epoch(32)(fusion):  0.7768658885556433\n",
      "train (33): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1e-05\n",
      "train (34): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1e-05\n",
      "epoch(34)(video):  0.7296004183148511\n",
      "epoch(34)(audio):  0.6836234166076915\n",
      "epoch(34)(text):  0.732235296658773\n",
      "epoch(34)(fusion):  0.7767748543470776\n",
      "train (35): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1e-05\n",
      "train (36): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1e-05\n",
      "epoch(36)(video):  0.7306270504098078\n",
      "epoch(36)(audio):  0.6841939876352283\n",
      "epoch(36)(text):  0.7320602535459851\n",
      "epoch(36)(fusion):  0.77752538288883\n",
      "train (37): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1e-05\n",
      "train (38): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1e-05\n",
      "epoch(38)(video):  0.7282977624977126\n",
      "epoch(38)(audio):  0.6831591150445614\n",
      "epoch(38)(text):  0.7318418493056682\n",
      "epoch(38)(fusion):  0.7771451759547184\n",
      "train (39): 100%|█████████████████████████████| 141/141 [01:20<00:00,  1.74it/s]\n",
      "1e-05\n",
      "train (40): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-06\n",
      "epoch(40)(video):  0.7295225494482667\n",
      "epoch(40)(audio):  0.6843039173970262\n",
      "epoch(40)(text):  0.7289293594990225\n",
      "epoch(40)(fusion):  0.7775905468042796\n",
      "train (41): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-06\n",
      "train (42): 100%|█████████████████████████████| 141/141 [01:32<00:00,  1.52it/s]\n",
      "1.0000000000000002e-06\n",
      "epoch(42)(video):  0.7297202264989465\n",
      "epoch(42)(audio):  0.6846714260713862\n",
      "epoch(42)(text):  0.7300540317050589\n",
      "epoch(42)(fusion):  0.7763582702133232\n",
      "train (43): 100%|█████████████████████████████| 141/141 [01:46<00:00,  1.32it/s]\n",
      "1.0000000000000002e-06\n",
      "train (44): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-06\n",
      "epoch(44)(video):  0.7284616158762556\n",
      "epoch(44)(audio):  0.6849592840065907\n",
      "epoch(44)(text):  0.7309474477399899\n",
      "epoch(44)(fusion):  0.7766698661246328\n",
      "train (45): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-06\n",
      "train (46): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-06\n",
      "epoch(46)(video):  0.7303983491247629\n",
      "epoch(46)(audio):  0.6845468107014747\n",
      "epoch(46)(text):  0.7322016367821953\n",
      "epoch(46)(fusion):  0.7768816966782904\n",
      "train (47): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-06\n",
      "train (48): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-06\n",
      "epoch(48)(video):  0.7300488257659912\n",
      "epoch(48)(audio):  0.6839616211104602\n",
      "epoch(48)(text):  0.7329360848882033\n",
      "epoch(48)(fusion):  0.7773898615377761\n",
      "train (49): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-06\n",
      "train (50): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-06\n",
      "epoch(50)(video):  0.7282531316773442\n",
      "epoch(50)(audio):  0.6833171678813617\n",
      "epoch(50)(text):  0.7314459437722727\n",
      "epoch(50)(fusion):  0.7773035190931119\n",
      "train (51): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-06\n",
      "train (52): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-06\n",
      "epoch(52)(video):  0.7296807109886241\n",
      "epoch(52)(audio):  0.6845132932941768\n",
      "epoch(52)(text):  0.7318209747430011\n",
      "epoch(52)(fusion):  0.7766937372392653\n",
      "train (53): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-06\n",
      "train (54): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-06\n",
      "epoch(54)(video):  0.7294282348929585\n",
      "epoch(54)(audio):  0.6843703430934187\n",
      "epoch(54)(text):  0.7293060672185201\n",
      "epoch(54)(fusion):  0.7756516257201251\n",
      "train (55): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-06\n",
      "train (56): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-06\n",
      "epoch(56)(video):  0.7299403699897139\n",
      "epoch(56)(audio):  0.6835751934292492\n",
      "epoch(56)(text):  0.7300404479415185\n",
      "epoch(56)(fusion):  0.776792257451802\n",
      "train (57): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-06\n",
      "train (58): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-06\n",
      "epoch(58)(video):  0.728771619612945\n",
      "epoch(58)(audio):  0.6846641766781744\n",
      "epoch(58)(text):  0.730963458833324\n",
      "epoch(58)(fusion):  0.7766163354729868\n",
      "train (59): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-06\n",
      "train (60): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-07\n",
      "epoch(60)(video):  0.7294186084654994\n",
      "epoch(60)(audio):  0.6848730526506225\n",
      "epoch(60)(text):  0.7298705181645774\n",
      "epoch(60)(fusion):  0.7770942642042518\n",
      "train (61): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-07\n",
      "train (62): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-07\n",
      "epoch(62)(video):  0.7298827112102914\n",
      "epoch(62)(audio):  0.6856351674373717\n",
      "epoch(62)(text):  0.7326503994858312\n",
      "epoch(62)(fusion):  0.777655463550257\n",
      "train (63): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-07\n",
      "train (64): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-07\n",
      "epoch(64)(video):  0.7286326423124582\n",
      "epoch(64)(audio):  0.6847206776532465\n",
      "epoch(64)(text):  0.7312749325888965\n",
      "epoch(64)(fusion):  0.777120103256339\n",
      "train (65): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-07\n",
      "train (66): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-07\n",
      "epoch(66)(video):  0.7306436577303764\n",
      "epoch(66)(audio):  0.6847476264838417\n",
      "epoch(66)(text):  0.7311685547269184\n",
      "epoch(66)(fusion):  0.7768722223165289\n",
      "train (67): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-07\n",
      "train (68): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-07\n",
      "epoch(68)(video):  0.7288170610785453\n",
      "epoch(68)(audio):  0.6862199104967445\n",
      "epoch(68)(text):  0.7317952105309735\n",
      "epoch(68)(fusion):  0.7768609192669123\n",
      "train (69): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-07\n",
      "train (70): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-07\n",
      "epoch(70)(video):  0.7295875604405168\n",
      "epoch(70)(audio):  0.6844676734386691\n",
      "epoch(70)(text):  0.7326714548992551\n",
      "epoch(70)(fusion):  0.7775053637822814\n",
      "train (71): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-07\n",
      "train (72): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-07\n",
      "epoch(72)(video):  0.7284406177210686\n",
      "epoch(72)(audio):  0.6854135957666664\n",
      "epoch(72)(text):  0.7312960375902603\n",
      "epoch(72)(fusion):  0.7773335808385311\n",
      "train (73): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-07\n",
      "train (74): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-07\n",
      "epoch(74)(video):  0.7288871578915783\n",
      "epoch(74)(audio):  0.685358986504861\n",
      "epoch(74)(text):  0.7304517215401377\n",
      "epoch(74)(fusion):  0.777332201646909\n",
      "train (75): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-07\n",
      "train (76): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-07\n",
      "epoch(76)(video):  0.7270125691993934\n",
      "epoch(76)(audio):  0.6844329291390499\n",
      "epoch(76)(text):  0.7324224542920896\n",
      "epoch(76)(fusion):  0.7775893316423683\n",
      "train (77): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-07\n",
      "train (78): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-07\n",
      "epoch(78)(video):  0.7285767233866015\n",
      "epoch(78)(audio):  0.6845978425499176\n",
      "epoch(78)(text):  0.7308678948471247\n",
      "epoch(78)(fusion):  0.7766697689511166\n",
      "train (79): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-07\n",
      "train (80): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-07\n",
      "epoch(80)(video):  0.7286815442263577\n",
      "epoch(80)(audio):  0.6851633622832074\n",
      "epoch(80)(text):  0.7308421876588005\n",
      "epoch(80)(fusion):  0.7781798792256629\n",
      "train (81): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-07\n",
      "train (82): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-07\n",
      "epoch(82)(video):  0.7286048654468695\n",
      "epoch(82)(audio):  0.6838584742808625\n",
      "epoch(82)(text):  0.7312827954985655\n",
      "epoch(82)(fusion):  0.7767265199760971\n",
      "train (83): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-07\n",
      "train (84): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-07\n",
      "epoch(84)(video):  0.7265505466195203\n",
      "epoch(84)(audio):  0.6851898457244099\n",
      "epoch(84)(text):  0.7304410989571376\n",
      "epoch(84)(fusion):  0.7759222908595483\n",
      "train (85): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-07\n",
      "train (86): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-07\n",
      "epoch(86)(video):  0.7297855093525\n",
      "epoch(86)(audio):  0.6854822983860934\n",
      "epoch(86)(text):  0.7308449954961184\n",
      "epoch(86)(fusion):  0.7762411109162575\n",
      "train (87): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-07\n",
      "train (88): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-07\n",
      "epoch(88)(video):  0.7287959818581847\n",
      "epoch(88)(audio):  0.6841010336623768\n",
      "epoch(88)(text):  0.7313450025714386\n",
      "epoch(88)(fusion):  0.7768974310684197\n",
      "train (89): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.74it/s]\n",
      "1.0000000000000002e-07\n",
      "train (90): 100%|█████████████████████████████| 141/141 [01:21<00:00,  1.73it/s]\n",
      "1.0000000000000002e-07\n",
      "epoch(90)(video):  0.7291876356324556\n",
      "epoch(90)(audio):  0.683899101237129\n",
      "epoch(90)(text):  0.7307244257661534\n",
      "epoch(90)(fusion):  0.7765259413004716\n",
      "train (91):  11%|███▏                          | 15/141 [00:22<01:11,  1.76it/s]"
     ]
    }
   ],
   "source": [
    "# 三个模态 + video text with projector自监督 + classifier head 修改\n",
    "!python -W ignore main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "initialization: Kaiming\n",
      "train (0): 100%|██████████████████████████████| 141/141 [01:23<00:00,  1.69it/s]\n",
      "2e-05\n",
      "epoch(0)(video):  0.6419423715912773\n",
      "epoch(0)(audio):  0.6338057226341484\n",
      "epoch(0)(text):  0.643280833542588\n",
      "epoch(0)(fusion):  0.6601524903764499\n",
      "train (1): 100%|██████████████████████████████| 141/141 [01:21<00:00,  1.72it/s]\n",
      "4e-05\n",
      "train (2): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.72it/s]\n",
      "6e-05\n",
      "epoch(2)(video):  0.6483011915775264\n",
      "epoch(2)(audio):  0.6370716305043205\n",
      "epoch(2)(text):  0.6941306690800912\n",
      "epoch(2)(fusion):  0.7109354795117948\n",
      "train (3): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "8e-05\n",
      "train (4): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "0.0001\n",
      "epoch(4)(video):  0.6850789493296643\n",
      "epoch(4)(audio):  0.6576791010021241\n",
      "epoch(4)(text):  0.700131499517907\n",
      "epoch(4)(fusion):  0.7348924357376766\n",
      "train (5): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "0.0001\n",
      "train (6): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "0.0001\n",
      "epoch(6)(video):  0.6992293363550182\n",
      "epoch(6)(audio):  0.6648890302214521\n",
      "epoch(6)(text):  0.7136018927354534\n",
      "epoch(6)(fusion):  0.7515445197708867\n",
      "train (7): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "0.0001\n",
      "train (8): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "0.0001\n",
      "epoch(8)(video):  0.713914168469918\n",
      "epoch(8)(audio):  0.6604528269343437\n",
      "epoch(8)(text):  0.7161203276642308\n",
      "epoch(8)(fusion):  0.7583698252874903\n",
      "train (9): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "0.0001\n",
      "train (10): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "0.0001\n",
      "epoch(10)(video):  0.7201346560353853\n",
      "epoch(10)(audio):  0.6636241263606262\n",
      "epoch(10)(text):  0.7142502049886243\n",
      "epoch(10)(fusion):  0.7634899047498704\n",
      "train (11): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "0.0001\n",
      "train (12): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "0.0001\n",
      "epoch(12)(video):  0.7261462725408647\n",
      "epoch(12)(audio):  0.6701350591072276\n",
      "epoch(12)(text):  0.7187950036792033\n",
      "epoch(12)(fusion):  0.7673284282226619\n",
      "train (13): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "0.0001\n",
      "train (14): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "0.0001\n",
      "epoch(14)(video):  0.7290854062217741\n",
      "epoch(14)(audio):  0.6727773405669543\n",
      "epoch(14)(text):  0.718313886530406\n",
      "epoch(14)(fusion):  0.7691385617635405\n",
      "train (15): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "0.0001\n",
      "train (16): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "0.0001\n",
      "epoch(16)(video):  0.727643716697489\n",
      "epoch(16)(audio):  0.6792132957707763\n",
      "epoch(16)(text):  0.7206302790359147\n",
      "epoch(16)(fusion):  0.7702905789968852\n",
      "train (17): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "0.0001\n",
      "train (18): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "0.0001\n",
      "epoch(18)(video):  0.727654598610076\n",
      "epoch(18)(audio):  0.6797102169035132\n",
      "epoch(18)(text):  0.7195652662659953\n",
      "epoch(18)(fusion):  0.7725286433249551\n",
      "train (19): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "0.0001\n",
      "train (20): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1e-05\n",
      "epoch(20)(video):  0.746732124229049\n",
      "epoch(20)(audio):  0.6813088817943476\n",
      "epoch(20)(text):  0.7274232057342787\n",
      "epoch(20)(fusion):  0.7802792575226097\n",
      "train (21): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "1e-05\n",
      "train (22): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1e-05\n",
      "epoch(22)(video):  0.7516458190615405\n",
      "epoch(22)(audio):  0.6824187669270739\n",
      "epoch(22)(text):  0.7288750649740497\n",
      "epoch(22)(fusion):  0.7814672085497731\n",
      "train (23): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1e-05\n",
      "train (24): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1e-05\n",
      "epoch(24)(video):  0.7496834433815049\n",
      "epoch(24)(audio):  0.6836786931645561\n",
      "epoch(24)(text):  0.7249612132420566\n",
      "epoch(24)(fusion):  0.7812659141635452\n",
      "train (25): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1e-05\n",
      "train (26): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1e-05\n",
      "epoch(26)(video):  0.7502620338914298\n",
      "epoch(26)(audio):  0.6833035402635236\n",
      "epoch(26)(text):  0.7244913870600842\n",
      "epoch(26)(fusion):  0.7813139614695508\n",
      "train (27): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1e-05\n",
      "train (28): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1e-05\n",
      "epoch(28)(video):  0.7441950370963927\n",
      "epoch(28)(audio):  0.6824023280111156\n",
      "epoch(28)(text):  0.7246967865493279\n",
      "epoch(28)(fusion):  0.7798818151322235\n",
      "train (29): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1e-05\n",
      "train (30): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1e-05\n",
      "epoch(30)(video):  0.7473390020599338\n",
      "epoch(30)(audio):  0.6829512267800203\n",
      "epoch(30)(text):  0.7244047995025845\n",
      "epoch(30)(fusion):  0.7816500286110674\n",
      "train (31): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1e-05\n",
      "train (32): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1e-05\n",
      "epoch(32)(video):  0.745687462366879\n",
      "epoch(32)(audio):  0.6819241378482436\n",
      "epoch(32)(text):  0.7250265027250903\n",
      "epoch(32)(fusion):  0.7816447816822745\n",
      "train (33): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1e-05\n",
      "train (34): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1e-05\n",
      "epoch(34)(video):  0.7456084220434557\n",
      "epoch(34)(audio):  0.6821178211850075\n",
      "epoch(34)(text):  0.7257997690957356\n",
      "epoch(34)(fusion):  0.7822709882334843\n",
      "train (35): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1e-05\n",
      "train (36): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1e-05\n",
      "epoch(36)(video):  0.7438871369979013\n",
      "epoch(36)(audio):  0.6833105960930089\n",
      "epoch(36)(text):  0.7227562266013862\n",
      "epoch(36)(fusion):  0.7821286263073817\n",
      "train (37): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1e-05\n",
      "train (38): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "1e-05\n",
      "epoch(38)(video):  0.7436525987246972\n",
      "epoch(38)(audio):  0.6827190150515172\n",
      "epoch(38)(text):  0.7224315225612354\n",
      "epoch(38)(fusion):  0.7816874299007726\n",
      "train (39): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1e-05\n",
      "train (40): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1.0000000000000002e-06\n",
      "epoch(40)(video):  0.7446969255029937\n",
      "epoch(40)(audio):  0.6824658066290542\n",
      "epoch(40)(text):  0.7222977568201415\n",
      "epoch(40)(fusion):  0.7821466080267351\n",
      "train (41): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1.0000000000000002e-06\n",
      "train (42): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "1.0000000000000002e-06\n",
      "epoch(42)(video):  0.7444351277721338\n",
      "epoch(42)(audio):  0.6830522917368148\n",
      "epoch(42)(text):  0.7234602738864878\n",
      "epoch(42)(fusion):  0.7821012130869657\n",
      "train (43):  12%|███▌                          | 17/141 [00:23<01:04,  1.92it/s]^C\n"
     ]
    }
   ],
   "source": [
    "# 三个模态 + 新feature\n",
    "!python -W ignore main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "initialization: Kaiming\n",
      "train (0): 100%|██████████████████████████████| 141/141 [01:24<00:00,  1.66it/s]\n",
      "epoch(0)(video):  0.6902635999701432\n",
      "epoch(0)(audio):  0.6334134171064916\n",
      "epoch(0)(text):  0.6799770587694437\n",
      "epoch(0)(fusion):  0.6832036375910947\n",
      "train (1): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (2): 100%|██████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "epoch(2)(video):  0.7002878936141929\n",
      "epoch(2)(audio):  0.6506764540381339\n",
      "epoch(2)(text):  0.7017522833776935\n",
      "epoch(2)(fusion):  0.7291972673500767\n",
      "train (3): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (4): 100%|██████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "epoch(4)(video):  0.7156443449478636\n",
      "epoch(4)(audio):  0.6588074654702207\n",
      "epoch(4)(text):  0.7083750355777741\n",
      "epoch(4)(fusion):  0.7434003900385746\n",
      "train (5): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (6): 100%|██████████████████████████████| 141/141 [01:23<00:00,  1.69it/s]\n",
      "epoch(6)(video):  0.718899081851766\n",
      "epoch(6)(audio):  0.6637205602164147\n",
      "epoch(6)(text):  0.7222121219646579\n",
      "epoch(6)(fusion):  0.7548879594594068\n",
      "train (7): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (8): 100%|██████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "epoch(8)(video):  0.7171986308772532\n",
      "epoch(8)(audio):  0.6594331731810028\n",
      "epoch(8)(text):  0.7265157082591214\n",
      "epoch(8)(fusion):  0.7576509235231839\n",
      "train (9): 100%|██████████████████████████████| 141/141 [01:23<00:00,  1.69it/s]\n",
      "train (10): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(10)(video):  0.7309727998054477\n",
      "epoch(10)(audio):  0.6692163003108014\n",
      "epoch(10)(text):  0.7274543442532638\n",
      "epoch(10)(fusion):  0.7663418532208043\n",
      "train (11): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (12): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(12)(video):  0.7350242381465626\n",
      "epoch(12)(audio):  0.6720530933123405\n",
      "epoch(12)(text):  0.7277406559688995\n",
      "epoch(12)(fusion):  0.7692821330902501\n",
      "train (13): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (14): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(14)(video):  0.7330329299821454\n",
      "epoch(14)(audio):  0.6690254869602046\n",
      "epoch(14)(text):  0.7302061547483075\n",
      "epoch(14)(fusion):  0.7744264237275219\n",
      "train (15): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (16): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(16)(video):  0.7297837804302656\n",
      "epoch(16)(audio):  0.671478900877674\n",
      "epoch(16)(text):  0.7234904583527386\n",
      "epoch(16)(fusion):  0.774474559937036\n",
      "train (17): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (18): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(18)(video):  0.7197830673896749\n",
      "epoch(18)(audio):  0.6790320922303705\n",
      "epoch(18)(text):  0.7279800003483615\n",
      "epoch(18)(fusion):  0.7724299416847095\n",
      "train (19): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (20): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(20)(video):  0.7458418169569316\n",
      "epoch(20)(audio):  0.6791833226865605\n",
      "epoch(20)(text):  0.7319956335517074\n",
      "epoch(20)(fusion):  0.7812204832913145\n",
      "train (21): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (22): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "epoch(22)(video):  0.749186360234696\n",
      "epoch(22)(audio):  0.6821101519672109\n",
      "epoch(22)(text):  0.7327859378035894\n",
      "epoch(22)(fusion):  0.7811666454826944\n",
      "train (23): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (24): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "epoch(24)(video):  0.7473835895238025\n",
      "epoch(24)(audio):  0.6812324765370487\n",
      "epoch(24)(text):  0.7315909155226684\n",
      "epoch(24)(fusion):  0.7804235589809501\n",
      "train (25): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "train (26): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(26)(video):  0.7478852852247287\n",
      "epoch(26)(audio):  0.6808645276282725\n",
      "epoch(26)(text):  0.7311016163071323\n",
      "epoch(26)(fusion):  0.7810644499990579\n",
      "train (27): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (28): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(28)(video):  0.7433590460931044\n",
      "epoch(28)(audio):  0.6801521771337999\n",
      "epoch(28)(text):  0.7318251697663385\n",
      "epoch(28)(fusion):  0.7805337347979255\n",
      "train (29): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (30): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "epoch(30)(video):  0.7422511515693341\n",
      "epoch(30)(audio):  0.6815853808980348\n",
      "epoch(30)(text):  0.7323603166691672\n",
      "epoch(30)(fusion):  0.7801702029195567\n",
      "train (31):  37%|███████████                   | 52/141 [00:40<00:41,  2.13it/s]^C\n"
     ]
    }
   ],
   "source": [
    "# 三个模态 + 新 resnet50 feature + 自监督\n",
    "!python -W ignore main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "initialization: Kaiming\n",
      "train (0): 100%|██████████████████████████████| 141/141 [01:24<00:00,  1.67it/s]\n",
      "epoch(0)(video):  0.6902636011868287\n",
      "epoch(0)(audio):  0.6334099612917061\n",
      "epoch(0)(text):  0.6799770675409502\n",
      "epoch(0)(fusion):  0.6832050636180214\n",
      "train (1): 100%|██████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "train (2): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(2)(video):  0.6993738868672738\n",
      "epoch(2)(audio):  0.6498484765901059\n",
      "epoch(2)(text):  0.702161802798722\n",
      "epoch(2)(fusion):  0.7292222953444044\n",
      "train (3): 100%|██████████████████████████████| 141/141 [01:23<00:00,  1.69it/s]\n",
      "train (4): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(4)(video):  0.7143293241128451\n",
      "epoch(4)(audio):  0.6559574042020808\n",
      "epoch(4)(text):  0.7084222863315424\n",
      "epoch(4)(fusion):  0.7421685048193435\n",
      "train (5): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (6): 100%|██████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "epoch(6)(video):  0.7187014675191429\n",
      "epoch(6)(audio):  0.665372893864778\n",
      "epoch(6)(text):  0.7217526558018751\n",
      "epoch(6)(fusion):  0.753532587803213\n",
      "train (7): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (8): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(8)(video):  0.7232569456361565\n",
      "epoch(8)(audio):  0.6604294054766361\n",
      "epoch(8)(text):  0.7234078195967879\n",
      "epoch(8)(fusion):  0.7597439303619725\n",
      "train (9): 100%|██████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "train (10): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "epoch(10)(video):  0.7264435467671595\n",
      "epoch(10)(audio):  0.670056773113019\n",
      "epoch(10)(text):  0.7258253645343042\n",
      "epoch(10)(fusion):  0.7650962301319282\n",
      "train (11): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (12): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "epoch(12)(video):  0.7373002181627076\n",
      "epoch(12)(audio):  0.6708545018621064\n",
      "epoch(12)(text):  0.7267082308776384\n",
      "epoch(12)(fusion):  0.7678288366038497\n",
      "train (13): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "train (14): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "epoch(14)(video):  0.7383919906673625\n",
      "epoch(14)(audio):  0.6725636102700363\n",
      "epoch(14)(text):  0.7309785472864785\n",
      "epoch(14)(fusion):  0.7733701264453797\n",
      "train (15): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (16): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(16)(video):  0.7318646914422418\n",
      "epoch(16)(audio):  0.6758310804003375\n",
      "epoch(16)(text):  0.7258880793434054\n",
      "epoch(16)(fusion):  0.770184170067881\n",
      "train (17): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "train (18): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "epoch(18)(video):  0.7275563752224048\n",
      "epoch(18)(audio):  0.679373631481092\n",
      "epoch(18)(text):  0.7266320328396609\n",
      "epoch(18)(fusion):  0.7750447130318864\n",
      "train (19): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (20): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.69it/s]\n",
      "epoch(20)(video):  0.7303673527902147\n",
      "epoch(20)(audio):  0.6680581853383633\n",
      "epoch(20)(text):  0.7285602733916009\n",
      "epoch(20)(fusion):  0.7730636980024091\n",
      "train (21): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (22): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(22)(video):  0.7259691386201678\n",
      "epoch(22)(audio):  0.6707024894465069\n",
      "epoch(22)(text):  0.730264034770045\n",
      "epoch(22)(fusion):  0.7757492942846886\n",
      "train (23): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (24): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "epoch(24)(video):  0.7311277391926765\n",
      "epoch(24)(audio):  0.6784610586029565\n",
      "epoch(24)(text):  0.7268306208389261\n",
      "epoch(24)(fusion):  0.7787214965316588\n",
      "train (25): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (26): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "epoch(26)(video):  0.7197765431271467\n",
      "epoch(26)(audio):  0.6703755360273311\n",
      "epoch(26)(text):  0.7252369778108697\n",
      "epoch(26)(fusion):  0.7731615603192223\n",
      "train (27): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (28): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(28)(video):  0.7329926006145276\n",
      "epoch(28)(audio):  0.6772469687562785\n",
      "epoch(28)(text):  0.7282271340456363\n",
      "epoch(28)(fusion):  0.7764963633737141\n",
      "train (29): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (30): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "epoch(30)(video):  0.7168777655586643\n",
      "epoch(30)(audio):  0.6749960013327468\n",
      "epoch(30)(text):  0.7277401514887873\n",
      "epoch(30)(fusion):  0.7747399236289955\n",
      "train (31): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "train (32): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(32)(video):  0.7191680287689078\n",
      "epoch(32)(audio):  0.6748209731439324\n",
      "epoch(32)(text):  0.7214257355994839\n",
      "epoch(32)(fusion):  0.7756622543003237\n",
      "train (33): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (34):  63%|██████████████████▉           | 89/141 [00:58<00:24,  2.11it/s]^C\n"
     ]
    }
   ],
   "source": [
    "# 三个模态 + 新 resnet50 feature + 自监督 + lr调整降低更快 --> 效果更差\n",
    "!python -W ignore main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "initialization: Kaiming\n",
      "train (0): 100%|██████████████████████████████| 141/141 [01:24<00:00,  1.67it/s]\n",
      "epoch(0)(video):  0.6419424287897074\n",
      "epoch(0)(audio):  0.6336281179136517\n",
      "epoch(0)(text):  0.6432808721609516\n",
      "epoch(0)(fusion):  0.6601544817916665\n",
      "train (1): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "train (2): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(2)(video):  0.6498337685153079\n",
      "epoch(2)(audio):  0.6377781371149478\n",
      "epoch(2)(text):  0.6944373618108999\n",
      "epoch(2)(fusion):  0.7114343891919491\n",
      "train (3): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (4): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(4)(video):  0.681475582950793\n",
      "epoch(4)(audio):  0.6562993247428563\n",
      "epoch(4)(text):  0.6984362581382573\n",
      "epoch(4)(fusion):  0.7329938958757429\n",
      "train (5): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (6): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "epoch(6)(video):  0.6986994349031354\n",
      "epoch(6)(audio):  0.6626336507066121\n",
      "epoch(6)(text):  0.7119359462109005\n",
      "epoch(6)(fusion):  0.7501202590796314\n",
      "train (7): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (8): 100%|██████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "epoch(8)(video):  0.7151400943862704\n",
      "epoch(8)(audio):  0.6616538987511967\n",
      "epoch(8)(text):  0.7170718825713723\n",
      "epoch(8)(fusion):  0.7591756043099257\n",
      "train (9): 100%|██████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "train (10): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "epoch(10)(video):  0.7185969431549618\n",
      "epoch(10)(audio):  0.6639937202256927\n",
      "epoch(10)(text):  0.7192399873480897\n",
      "epoch(10)(fusion):  0.7628862985955969\n",
      "train (11): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (12): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(12)(video):  0.7214599532994207\n",
      "epoch(12)(audio):  0.6680132185673776\n",
      "epoch(12)(text):  0.721872412826246\n",
      "epoch(12)(fusion):  0.7685503014839568\n",
      "train (13): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (14): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(14)(video):  0.7290136260647562\n",
      "epoch(14)(audio):  0.674943438175475\n",
      "epoch(14)(text):  0.7197563638204508\n",
      "epoch(14)(fusion):  0.7697122026472127\n",
      "train (15): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "train (16): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(16)(video):  0.7266564521099541\n",
      "epoch(16)(audio):  0.6761447195196042\n",
      "epoch(16)(text):  0.7186507487906274\n",
      "epoch(16)(fusion):  0.7686818050557969\n",
      "train (17): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (18): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "epoch(18)(video):  0.7188322794057526\n",
      "epoch(18)(audio):  0.676222235010959\n",
      "epoch(18)(text):  0.7197671962904058\n",
      "epoch(18)(fusion):  0.7700915311870876\n",
      "train (19): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "train (20): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.69it/s]\n",
      "epoch(20)(video):  0.7434700430240158\n",
      "epoch(20)(audio):  0.6788825461157229\n",
      "epoch(20)(text):  0.7238260866665155\n",
      "epoch(20)(fusion):  0.780922558750912\n",
      "train (21): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "train (22): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(22)(video):  0.7452312313334858\n",
      "epoch(22)(audio):  0.6796354627220609\n",
      "epoch(22)(text):  0.7256545717019819\n",
      "epoch(22)(fusion):  0.781059155831812\n",
      "train (23): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "train (24): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(24)(video):  0.7449902208119586\n",
      "epoch(24)(audio):  0.6821787427908509\n",
      "epoch(24)(text):  0.7231171733613093\n",
      "epoch(24)(fusion):  0.7817065939529362\n",
      "train (25): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "train (26): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "epoch(26)(video):  0.745617533787054\n",
      "epoch(26)(audio):  0.6805194544347936\n",
      "epoch(26)(text):  0.7233917666964575\n",
      "epoch(26)(fusion):  0.7817881583112707\n",
      "train (27): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (28): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(28)(video):  0.739066859132191\n",
      "epoch(28)(audio):  0.6821840629123588\n",
      "epoch(28)(text):  0.7240394164921448\n",
      "epoch(28)(fusion):  0.7798346434859014\n",
      "train (29): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "train (30): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "epoch(30)(video):  0.7443993281899345\n",
      "epoch(30)(audio):  0.6831501737919072\n",
      "epoch(30)(text):  0.724568268577587\n",
      "epoch(30)(fusion):  0.7803710346141055\n",
      "train (31): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "train (32): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "epoch(32)(video):  0.7431470474645546\n",
      "epoch(32)(audio):  0.6817095264543943\n",
      "epoch(32)(text):  0.7254612567573833\n",
      "epoch(32)(fusion):  0.7808741399858612\n",
      "train (33): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "train (34): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(34)(video):  0.7450062356460636\n",
      "epoch(34)(audio):  0.681094157398793\n",
      "epoch(34)(text):  0.7254479059358904\n",
      "epoch(34)(fusion):  0.7816780007307877\n",
      "train (35): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (36): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "epoch(36)(video):  0.7450925327585056\n",
      "epoch(36)(audio):  0.6840757950526821\n",
      "epoch(36)(text):  0.7236644302843456\n",
      "epoch(36)(fusion):  0.7823123523061686\n",
      "train (37): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.69it/s]\n",
      "train (38): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(38)(video):  0.7443098297909037\n",
      "epoch(38)(audio):  0.6831874700668805\n",
      "epoch(38)(text):  0.7238444257609802\n",
      "epoch(38)(fusion):  0.7816819971309966\n",
      "train (39): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "train (40): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "epoch(40)(video):  0.7443631980581341\n",
      "epoch(40)(audio):  0.682347247417321\n",
      "epoch(40)(text):  0.7237721429170886\n",
      "epoch(40)(fusion):  0.7815907419881338\n",
      "train (41): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (42): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(42)(video):  0.7446411536130897\n",
      "epoch(42)(audio):  0.6832699161212421\n",
      "epoch(42)(text):  0.7252957157526881\n",
      "epoch(42)(fusion):  0.782091003704853\n",
      "train (43): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (44): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(44)(video):  0.7440312230414909\n",
      "epoch(44)(audio):  0.6815394275030024\n",
      "epoch(44)(text):  0.724939805505128\n",
      "epoch(44)(fusion):  0.7808641793662271\n",
      "train (45): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "train (46): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "epoch(46)(video):  0.743343809059333\n",
      "epoch(46)(audio):  0.6823318658756801\n",
      "epoch(46)(text):  0.7224968533554393\n",
      "epoch(46)(fusion):  0.7817692253087393\n",
      "train (47): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (48): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "epoch(48)(video):  0.7436503568320024\n",
      "epoch(48)(audio):  0.6822114722392332\n",
      "epoch(48)(text):  0.7221466947542285\n",
      "epoch(48)(fusion):  0.780459353545105\n",
      "train (49): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "train (50): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "epoch(50)(video):  0.7441618823546421\n",
      "epoch(50)(audio):  0.6833937815218121\n",
      "epoch(50)(text):  0.7238859529943139\n",
      "epoch(50)(fusion):  0.7805089988104384\n",
      "train (51): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.70it/s]\n",
      "train (52): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(52)(video):  0.744410684782352\n",
      "epoch(52)(audio):  0.6815845019644734\n",
      "epoch(52)(text):  0.7231258824961986\n",
      "epoch(52)(fusion):  0.7820222059867519\n",
      "train (53): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "train (54): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "epoch(54)(video):  0.7434232877774734\n",
      "epoch(54)(audio):  0.6828905401530176\n",
      "epoch(54)(text):  0.7233301324576259\n",
      "epoch(54)(fusion):  0.7821242558104499\n",
      "train (55): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (56): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "epoch(56)(video):  0.744456881436231\n",
      "epoch(56)(audio):  0.6822280051585818\n",
      "epoch(56)(text):  0.7226923461304996\n",
      "epoch(56)(fusion):  0.7812739632084016\n",
      "train (57): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "train (58): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(58)(video):  0.7432581472986441\n",
      "epoch(58)(audio):  0.6821098852134877\n",
      "epoch(58)(text):  0.7224617848870414\n",
      "epoch(58)(fusion):  0.7818069280129215\n",
      "train (59): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "train (60): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "epoch(60)(video):  0.7444356489744531\n",
      "epoch(60)(audio):  0.6828627300338183\n",
      "epoch(60)(text):  0.7230402290396274\n",
      "epoch(60)(fusion):  0.7826275462547294\n",
      "train (61): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (62): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "epoch(62)(video):  0.7436407252949535\n",
      "epoch(62)(audio):  0.6831908542319495\n",
      "epoch(62)(text):  0.7230825327872002\n",
      "epoch(62)(fusion):  0.7812638889912451\n",
      "train (63): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (64): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(64)(video):  0.7443614530736695\n",
      "epoch(64)(audio):  0.6821811919174999\n",
      "epoch(64)(text):  0.7225641681395006\n",
      "epoch(64)(fusion):  0.7812077260999649\n",
      "train (65): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "train (66): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(66)(video):  0.743280842835967\n",
      "epoch(66)(audio):  0.6818075114657977\n",
      "epoch(66)(text):  0.7237992742293373\n",
      "epoch(66)(fusion):  0.7818384024057042\n",
      "train (67): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (68): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(68)(video):  0.7419528116486928\n",
      "epoch(68)(audio):  0.6816431820644961\n",
      "epoch(68)(text):  0.7220483297385246\n",
      "epoch(68)(fusion):  0.7821778263328031\n",
      "train (69): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (70): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(70)(video):  0.743087495220526\n",
      "epoch(70)(audio):  0.682905287757661\n",
      "epoch(70)(text):  0.7237999243469214\n",
      "epoch(70)(fusion):  0.7807973087758233\n",
      "train (71): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "train (72): 100%|█████████████████████████████| 141/141 [01:23<00:00,  1.69it/s]\n",
      "epoch(72)(video):  0.7414699133274459\n",
      "epoch(72)(audio):  0.6835430861505719\n",
      "epoch(72)(text):  0.7240720590606594\n",
      "epoch(72)(fusion):  0.7808526387261904\n",
      "train (73): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "train (74): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.71it/s]\n",
      "epoch(74)(video):  0.7429250242084608\n",
      "epoch(74)(audio):  0.6819577798334436\n",
      "epoch(74)(text):  0.723131022415366\n",
      "epoch(74)(fusion):  0.7823562276255851\n",
      "train (75): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (76): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "epoch(76)(video):  0.74444595790628\n",
      "epoch(76)(audio):  0.6819484625976987\n",
      "epoch(76)(text):  0.722777869753548\n",
      "epoch(76)(fusion):  0.7820994698050956\n",
      "train (77): 100%|█████████████████████████████| 141/141 [01:22<00:00,  1.70it/s]\n",
      "train (78):  38%|███████████▎                  | 53/141 [00:41<00:41,  2.12it/s]^C\n"
     ]
    }
   ],
   "source": [
    "!python -W ignore main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "initialization: Kaiming\n",
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "initialization: Kaiming\n",
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "initialization: Kaiming\n",
      "100%|███████████████████████████████████████| 5000/5000 [05:35<00:00, 14.90it/s]\n"
     ]
    }
   ],
   "source": [
    "!python -W ignore ensemble_inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -W ignore end2end_main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "initialization: Kaiming\n",
      "train (0): 100%|██████████████████████████████| 142/142 [03:49<00:00,  1.62s/it]\n",
      "9.366913352214114\n",
      "train (1): 100%|██████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "6.514036913992653\n",
      "train (2): 100%|██████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "4.723316543538806\n",
      "train (3): 100%|██████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "3.946944408013787\n",
      "train (4): 100%|██████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "3.360135189244445\n",
      "train (5): 100%|██████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "3.105098417107488\n",
      "train (6): 100%|██████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "2.880410173409422\n",
      "train (7): 100%|██████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "2.7021657161309687\n",
      "train (8): 100%|██████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "2.6136323457032864\n",
      "train (9): 100%|██████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "2.4704924729508413\n",
      "train (10): 100%|█████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "2.4048215176018193\n",
      "train (11): 100%|█████████████████████████████| 142/142 [04:53<00:00,  2.07s/it]\n",
      "2.3034196210579134\n",
      "train (12): 100%|█████████████████████████████| 142/142 [03:53<00:00,  1.65s/it]\n",
      "2.264077472854668\n",
      "train (13): 100%|█████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "2.178941273353469\n",
      "train (14): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "2.086400933668647\n",
      "train (15): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "2.155493936068575\n",
      "train (16): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "2.0587834153376834\n",
      "train (17): 100%|█████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "2.08125823820141\n",
      "train (18): 100%|█████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "1.9688180030231746\n",
      "train (19): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "1.947150190951119\n",
      "train (20): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.62s/it]\n",
      "1.8860853205264454\n",
      "train (21): 100%|█████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "1.9366214006719455\n",
      "train (22): 100%|█████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "1.889982842223745\n",
      "train (23): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "1.8743702517428869\n",
      "train (24): 100%|█████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "1.85834508882442\n",
      "train (25): 100%|█████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "1.8802690321290996\n",
      "train (26): 100%|█████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "1.8813851437938045\n",
      "train (27): 100%|█████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "1.8514005315135902\n",
      "train (28): 100%|█████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "1.8128094975377473\n",
      "train (29): 100%|█████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "1.8589697186376009\n",
      "train (30): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "1.8440852484232944\n",
      "train (31): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "1.7915971094453838\n",
      "train (32): 100%|█████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "1.7964106051015183\n",
      "train (33): 100%|█████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "1.8941896776078453\n",
      "train (34): 100%|█████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "1.799225585561403\n",
      "train (35): 100%|█████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "1.8272384547851455\n",
      "train (36): 100%|█████████████████████████████| 142/142 [03:48<00:00,  1.61s/it]\n",
      "1.8538921945531603\n",
      "train (37): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "1.8031935792573741\n",
      "train (38): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "1.8023949953871714\n",
      "train (39): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "1.813293134662467\n",
      "train (40): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "1.8314421420365992\n",
      "train (41): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "1.7644122998479386\n",
      "train (42): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.62s/it]\n",
      "1.7876035747393755\n",
      "train (43): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "1.829881256734821\n",
      "train (44): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "1.848603925234835\n",
      "train (45): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "1.7831532291963066\n",
      "train (46): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "1.8093742921318807\n",
      "train (47): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "1.7935681452213879\n",
      "train (48): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "1.811235333832217\n",
      "train (49): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.62s/it]\n",
      "1.7537535957887138\n",
      "train (50): 100%|█████████████████████████████| 142/142 [03:49<00:00,  1.61s/it]\n",
      "1.807280120715289\n"
     ]
    }
   ],
   "source": [
    "# without projector\n",
    "!python -W ignore enhance_main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "initialization: Kaiming\n",
      "train (0): 100%|██████████████████████████████| 142/142 [02:37<00:00,  1.11s/it]\n",
      "4.337402454564269\n",
      "train (1): 100%|██████████████████████████████| 142/142 [02:16<00:00,  1.04it/s]\n",
      "2.98784107221684\n",
      "train (2): 100%|██████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "2.7946327504977373\n",
      "train (3): 100%|██████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "2.7608521958472023\n",
      "train (4): 100%|██████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "2.7310451772851003\n",
      "train (5): 100%|██████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "2.6302693855594583\n",
      "train (6): 100%|██████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "2.5157128085552807\n",
      "train (7): 100%|██████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "2.4987536005570856\n",
      "train (8): 100%|██████████████████████████████| 142/142 [02:18<00:00,  1.03it/s]\n",
      "2.4160651430277755\n",
      "train (9): 100%|██████████████████████████████| 142/142 [02:18<00:00,  1.03it/s]\n",
      "2.3888443834345106\n",
      "train (10): 100%|█████████████████████████████| 142/142 [02:18<00:00,  1.03it/s]\n",
      "2.3101551885336216\n",
      "train (11): 100%|█████████████████████████████| 142/142 [02:18<00:00,  1.03it/s]\n",
      "2.249055890969827\n",
      "train (12): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "2.1818922044525686\n",
      "train (13): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "2.0879664874412645\n",
      "train (14): 100%|█████████████████████████████| 142/142 [02:18<00:00,  1.03it/s]\n",
      "2.1119546613223115\n",
      "train (15): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "2.128420476342591\n",
      "train (16): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "2.0466151741189016\n",
      "train (17): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "2.1216982880108795\n",
      "train (18): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "2.025287222694343\n",
      "train (19): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "2.0182325168394706\n",
      "train (20): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.7752763880810267\n",
      "train (21): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.6982080814704088\n",
      "train (22): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.6479625013512624\n",
      "train (23): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.6290364861488342\n",
      "train (24): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.5502891133368855\n",
      "train (25): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.593741541177454\n",
      "train (26): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.5513160623295206\n",
      "train (27): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.5942608243982557\n",
      "train (28): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.581561931422059\n",
      "train (29): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.5136235935587279\n",
      "train (30): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.5489438990472069\n",
      "train (31): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.5749913487635867\n",
      "train (32): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.5229730350030979\n",
      "train (33): 100%|█████████████████████████████| 142/142 [02:18<00:00,  1.03it/s]\n",
      "1.5322386303418118\n",
      "train (34): 100%|█████████████████████████████| 142/142 [02:18<00:00,  1.03it/s]\n",
      "1.5451569855213165\n",
      "train (35): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.5149604304575583\n",
      "train (36): 100%|█████████████████████████████| 142/142 [02:18<00:00,  1.03it/s]\n",
      "1.5414072577382478\n",
      "train (37): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.4827025343834515\n",
      "train (38): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.5246380063849436\n",
      "train (39): 100%|█████████████████████████████| 142/142 [02:18<00:00,  1.03it/s]\n",
      "1.5144769822207975\n",
      "train (40): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.497603993600523\n",
      "train (41): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.4641303793645242\n",
      "train (42): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.4528612469283628\n",
      "train (43): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.4949052875310602\n",
      "train (44): 100%|█████████████████████████████| 142/142 [02:17<00:00,  1.03it/s]\n",
      "1.456768491738279\n",
      "train (45):  30%|█████████                     | 43/142 [00:52<01:25,  1.16it/s]^C\n"
     ]
    }
   ],
   "source": [
    "# with projector\n",
    "!python -W ignore enhance_main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "initialization: Kaiming\n",
      "train (0): 100%|██████████████████████████████| 157/157 [02:36<00:00,  1.01it/s]\n",
      "7.031297176506869\n",
      "train (1): 100%|██████████████████████████████| 157/157 [02:34<00:00,  1.01it/s]\n",
      "5.372189801210051\n",
      "train (2): 100%|██████████████████████████████| 157/157 [02:34<00:00,  1.02it/s]\n",
      "4.0318496834700275\n",
      "train (3): 100%|██████████████████████████████| 157/157 [02:35<00:00,  1.01it/s]\n",
      "3.317514676197319\n",
      "train (4): 100%|██████████████████████████████| 157/157 [02:35<00:00,  1.01it/s]\n",
      "2.9855342442822304\n",
      "train (5): 100%|██████████████████████████████| 157/157 [02:35<00:00,  1.01it/s]\n",
      "2.746630644342702\n",
      "train (6): 100%|██████████████████████████████| 157/157 [02:34<00:00,  1.01it/s]\n",
      "2.6514366948680514\n",
      "train (7): 100%|██████████████████████████████| 157/157 [02:35<00:00,  1.01it/s]\n",
      "2.5285404639638913\n",
      "train (8): 100%|██████████████████████████████| 157/157 [02:35<00:00,  1.01it/s]\n",
      "2.423624826844331\n",
      "train (9): 100%|██████████████████████████████| 157/157 [02:35<00:00,  1.01it/s]\n",
      "2.3070915550183337\n",
      "train (10): 100%|█████████████████████████████| 157/157 [02:34<00:00,  1.01it/s]\n",
      "2.27108249315031\n",
      "train (11): 100%|█████████████████████████████| 157/157 [02:35<00:00,  1.01it/s]\n",
      "2.2028841691411984\n",
      "train (12): 100%|█████████████████████████████| 157/157 [02:34<00:00,  1.01it/s]\n",
      "2.141093247255702\n",
      "train (13): 100%|█████████████████████████████| 157/157 [02:34<00:00,  1.01it/s]\n",
      "2.1046714729564204\n",
      "train (14): 100%|█████████████████████████████| 157/157 [02:34<00:00,  1.01it/s]\n",
      "2.0442323308841437\n",
      "train (15): 100%|█████████████████████████████| 157/157 [02:34<00:00,  1.01it/s]\n",
      "2.0479110737515103\n",
      "train (16): 100%|█████████████████████████████| 157/157 [02:35<00:00,  1.01it/s]\n",
      "1.947649125080959\n",
      "train (17): 100%|█████████████████████████████| 157/157 [02:35<00:00,  1.01it/s]\n",
      "1.964892947749727\n",
      "train (18): 100%|█████████████████████████████| 157/157 [02:34<00:00,  1.01it/s]\n",
      "1.941655725430531\n",
      "train (19): 100%|█████████████████████████████| 157/157 [02:35<00:00,  1.01it/s]\n",
      "1.9111405861605504\n",
      "train (20): 100%|█████████████████████████████| 157/157 [02:35<00:00,  1.01it/s]\n",
      "1.8336310242391696\n",
      "train (21): 100%|█████████████████████████████| 157/157 [02:34<00:00,  1.01it/s]\n",
      "1.8602240920826127\n",
      "train (22): 100%|█████████████████████████████| 157/157 [02:34<00:00,  1.01it/s]\n",
      "1.8098095943973322\n",
      "train (23): 100%|█████████████████████████████| 157/157 [02:34<00:00,  1.01it/s]\n",
      "1.784247669444722\n",
      "train (24): 100%|█████████████████████████████| 157/157 [02:34<00:00,  1.01it/s]\n",
      "1.7634438173786091\n",
      "train (25): 100%|█████████████████████████████| 157/157 [02:35<00:00,  1.01it/s]\n",
      "1.776153509024602\n",
      "train (26): 100%|█████████████████████████████| 157/157 [02:34<00:00,  1.02it/s]\n",
      "1.76669145237868\n",
      "train (27): 100%|█████████████████████████████| 157/157 [02:34<00:00,  1.01it/s]\n",
      "1.8288243082678242\n",
      "train (28): 100%|█████████████████████████████| 157/157 [02:35<00:00,  1.01it/s]\n",
      "1.8005298239410303\n",
      "train (29): 100%|█████████████████████████████| 157/157 [02:34<00:00,  1.01it/s]\n",
      "1.767478009697738\n",
      "train (30): 100%|█████████████████████████████| 157/157 [02:34<00:00,  1.02it/s]\n",
      "1.7697781977380158\n",
      "train (31): 100%|█████████████████████████████| 157/157 [02:34<00:00,  1.02it/s]\n",
      "1.7694302994734163\n",
      "train (32):   0%|                                       | 0/157 [00:00<?, ?it/s]^C\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/spawn.py\", line 105, in spawn_main\n",
      "    exitcode = _main(fd)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/spawn.py\", line 114, in _main\n",
      "    prepare(preparation_data)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/spawn.py\", line 225, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/spawn.py\", line 277, in _fixup_main_from_path\n",
      "    run_name=\"__mp_main__\")\n",
      "train (32):   0%|                                       | 0/157 [00:03<?, ?it/s]\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/runpy.py\", line 263, in run_path\n",
      "Traceback (most recent call last):\n",
      "  File \"enhance_main.py\", line 76, in <module>\n",
      "    pkg_name=pkg_name, script_name=fname)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/runpy.py\", line 96, in _run_module_code\n",
      "    mod_name, mod_spec, pkg_name, script_name)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    loss = dual_training_loop(model, train_loader, loss_compute, modal_name_list,train_dataset.device, epoch,TBoard)\n",
      "  File \"/home/tione/notebook/TAAC-2021/src/loop/run_epoch.py\", line 199, in dual_training_loop\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/tione/notebook/TAAC-2021/enhance_main.py\", line 12, in <module>\n",
      "    from src.model.baseline_model import Baseline,Dual\n",
      "  File \"/home/tione/notebook/TAAC-2021/src/model/baseline_model.py\", line 2, in <module>\n",
      "    for i, batch in enumerate(tqdm(loader, desc=f'train ({epoch})')):\n",
      "    import src.text_head as text_head\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/tqdm/std.py\", line 1129, in __iter__\n",
      "  File \"/home/tione/notebook/TAAC-2021/src/text_head/__init__.py\", line 1, in <module>\n",
      "    from src.text_head.fine_bert import BERT,TextCnn\n",
      "  File \"/home/tione/notebook/TAAC-2021/src/text_head/fine_bert.py\", line 3, in <module>\n",
      "    from transformers import BertTokenizer,BertModel\n",
      "  File \"<frozen importlib._bootstrap>\", line 1020, in _handle_fromlist\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/transformers/__init__.py\", line 2709, in __getattr__\n",
      "    for obj in iterable:\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 279, in __iter__\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 719, in __init__\n",
      "    return super().__getattr__(name)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/transformers/file_utils.py\", line 1822, in __getattr__\n",
      "    w.start()\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/context.py\", line 223, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/context.py\", line 284, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\n",
      "    super().__init__(process_obj)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 62, in _launch\n",
      "    value = getattr(module, name)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/transformers/file_utils.py\", line 1821, in __getattr__\n",
      "    f.write(fp.getbuffer())\n",
      "KeyboardInterrupt\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/transformers/models/bert/__init__.py\", line 153, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 1742, in <module>\n",
      "    class BertForQuestionAnswering(BertPreTrainedModel):\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\", line 1774, in BertForQuestionAnswering\n",
      "    return_dict=None,\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/transformers/file_utils.py\", line 1076, in docstring_decorator\n",
      "    output_doc = _prepare_output_docstrings(output_type, config_class) if output_type is not None else \"\"\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/transformers/file_utils.py\", line 673, in _prepare_output_docstrings\n",
      "    intro = intro.format(full_output_type=full_output_type, config_class=config_class)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# resnet50 feature without projector\n",
    "!python -W ignore enhance_main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "initialization: Kaiming\n",
      "100%|███████████████████████████████████████| 5000/5000 [04:40<00:00, 17.83it/s]\n"
     ]
    }
   ],
   "source": [
    "!python -W ignore inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/ipykernel/__main__.py:21: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization: Kaiming\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization: Kaiming\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization: Kaiming\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization: Kaiming\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video': 0.7511614413498369, 'audio': 0.6839780922242963, 'text': 0.727922833791057, 'fusion': 0.7823667049925701}\n"
     ]
    }
   ],
   "source": [
    "# ensemble 模型在验证集上测试\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3,4,5,6,7'\n",
    "import yaml\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import utils.train_util as train_util\n",
    "from dataloader.dataloader import TestingDataset\n",
    "from src.loss.loss_compute import SimpleLossCompute\n",
    "from src.model.baseline_model import Baseline\n",
    "from src.loop.run_epoch import training_loop,validating_loop\n",
    "from dataloader.dataloader import MultimodaFeaturesDataset,Datasetfortextcnn\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 16\n",
    "modal_name_list = ['video','audio','text']\n",
    "config_path = './config/config.yaml'\n",
    "config = yaml.load(open(config_path))\n",
    "dataset = MultimodaFeaturesDataset(config['DatasetConfig'],job='valdation')\n",
    "loader = DataLoader(dataset,num_workers=8,\n",
    "                    batch_size=batch_size,\n",
    "                    pin_memory=False,\n",
    "                    collate_fn=dataset.collate_fn)\n",
    "\n",
    "model_path_1 = \"../checkpoint/0604/resnet50/epoch_22 0.7814.pt\" # 已保存模型的路径\n",
    "model_path_2 = '../checkpoint/0604/resnet50/epoch_34 0.7822.pt'\n",
    "model_path_3 = '../checkpoint/0604/resnet50/epoch_20 0.7802.pt'\n",
    "model_path_4 = '../checkpoint/0604/resnet50/epoch_30 0.7816.pt'\n",
    "#model_path_3 = '../checkpoint/0604/resnet50_with_selfsupervised/epoch_20 0.7812.pt'\n",
    "#model_path_4 = '../checkpoint/0604/lr/epoch_22 0.7797.pt'\n",
    "#model_path_5 = '../checkpoint/0604/lr/epoch_42 0.7810.pt'\n",
    "\n",
    "models_path = [model_path_1,model_path_2,model_path_3,model_path_4]\n",
    "device = 'cuda'\n",
    "top_k=20\n",
    "# output_json = './0604_resnet_ensemble.json'\n",
    "models = []\n",
    "for path in models_path:\n",
    "    model = Baseline(config['ModelConfig'])\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "\n",
    "tagging_class_num = 82\n",
    "evl_metrics = [train_util.EvaluationMetrics(tagging_class_num, top_k=20)\n",
    "                           for i in range(len(modal_name_list)+1)] #+1 for fusion\n",
    "for i in range(len(evl_metrics)):\n",
    "    evl_metrics[i].clear()\n",
    "metric_dict = {}\n",
    "gap_dict = {}\n",
    "for i,batch in enumerate(loader):\n",
    "    if(len(batch)==5):\n",
    "        video,audio,text,text_mask,label = batch\n",
    "        video = video.to(device)\n",
    "        audio = audio.to(device)\n",
    "        text = text.to(device)\n",
    "        text_mask = text_mask.to(device)\n",
    "        label = label.to(device)\n",
    "    else:\n",
    "        video,audio,text,label = batch\n",
    "        video = video.to(device)\n",
    "        audio = audio.to(device)\n",
    "        text = text.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "    inputs_dict={}\n",
    "    inputs_dict['video'] = video\n",
    "    inputs_dict['audio'] = audio\n",
    "    inputs_dict['text'] = text \n",
    "    if(len(batch)==5):\n",
    "        inputs_dict['attention_mask'] = text_mask\n",
    "    else:\n",
    "        inputs_dict['attention_mask'] = None\n",
    "        \n",
    "    B = video.shape[0]\n",
    "    pred_dict_ensemble = {}\n",
    "    for modal_name in (modal_name_list+['fusion']):\n",
    "        pred_dict_ensemble['tagging_output_'+modal_name] = {}\n",
    "        pred_dict_ensemble['tagging_output_'+modal_name]['predictions'] = torch.zeros(B,82).cuda()\n",
    "    \n",
    "    for model in models:\n",
    "        pred_dict = model(inputs_dict)\n",
    "        for modal_name in (modal_name_list+['fusion']):\n",
    "            pred_dict_ensemble['tagging_output_'+modal_name]['predictions'] += pred_dict['tagging_output_'+modal_name]['predictions']\n",
    "            \n",
    "    for modal_name in (modal_name_list+['fusion']):\n",
    "        pred_dict_ensemble['tagging_output_'+modal_name]['predictions'] = pred_dict_ensemble['tagging_output_'+modal_name]['predictions']/len(models)\n",
    "        \n",
    "    for index,modal_name in enumerate(modal_name_list+['fusion']):\n",
    "        pred = pred_dict_ensemble['tagging_output_'+modal_name]\n",
    "        pred = pred['predictions'].detach().cpu().numpy()\n",
    "        val_label = label.cpu().numpy()\n",
    "        gap = train_util.calculate_gap(pred, val_label)\n",
    "        evl_metrics[index].accumulate(pred, val_label, loss=0)\n",
    "for index,modal_name in enumerate(modal_name_list+['fusion']):\n",
    "    metric_dict[modal_name] = evl_metrics[index].get()\n",
    "    gap_dict[modal_name] = metric_dict[modal_name]['gap']\n",
    "print(gap_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_py3",
   "language": "python",
   "name": "conda_pytorch_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
