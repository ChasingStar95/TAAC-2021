{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "config_path = './config/config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/ipykernel/__main__.py:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "config = yaml.load(open(config_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset和dataloader 定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import dataloader.dataloader\n",
    "importlib.reload(dataloader.dataloader)\n",
    "from dataloader.dataloader import MultimodaFeaturesDataset\n",
    "dataset = MultimodaFeaturesDataset(config['DatasetConfig'],job='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(dataset,num_workers=0,batch_size=config['DatasetConfig']['batch_size'],collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteor = iter(loader)\n",
    "batch = next(iteor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "video,audio,text,label = batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization: xavier\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import src.model.baseline_model\n",
    "importlib.reload(src.model.baseline_model)\n",
    "from src.model.baseline_model import Baseline\n",
    "model = Baseline(config['ModelConfig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.loss.loss_compute\n",
    "importlib.reload(src.loss.loss_compute)\n",
    "from src.loss.loss_compute import SimpleLossCompute\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "criterion = nn.BCELoss(reduction='sum')# sum应该没问题吧\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_compute = SimpleLossCompute(criterion,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (1):   0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video\n",
      "after nextvlad shape:  torch.Size([32, 16384])\n",
      "after SE shape:  torch.Size([32, 1024])\n",
      "audio\n",
      "after nextvlad shape:  torch.Size([32, 1024])\n",
      "after SE shape:  torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (1):   0%|          | 0/157 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import src.loop.run_epoch\n",
    "importlib.reload(src.loop.run_epoch)\n",
    "from src.loop.run_epoch import training_loop\n",
    "training_loop(model, loader, loss_compute, epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "for batch in loader:\n",
    "    video,audio,text,label = batch\n",
    "    inputs_dict={}\n",
    "    inputs_dict['video'] = video\n",
    "    inputs_dict['audio'] = audio\n",
    "    inputs_dict['text'] = text\n",
    "    inputs_dict['label'] = label\n",
    "    # 预测\n",
    "    pred = model(inputs_dict)\n",
    "    # 计算损失\n",
    "    #loss = loss_compute(pred['tagging_output_fusion']['predictions'],label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 1])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred['video_loss_weight'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ultis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '/Users/mafp/code/datasets/tagging_dataset_train_5k/train_full.txt'\n",
    "with open(train_data_path,'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file = './mac_train.txt'\n",
    "with open(new_file,'a') as f:\n",
    "    for line in lines:\n",
    "        path = line.rstrip('\\n')\n",
    "        new_path = path.replace('../dataset/tagging/','/Users/mafp/code/datasets/')\n",
    "        # print(new_path)\n",
    "        f.write(new_path+'\\n')\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)//6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/ipykernel/__main__.py:16: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization: xavier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (0): 100%|██████████| 141/141 [00:16<00:00,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.27587278329643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "# from munch import Munch\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3,4,5,6,7'\n",
    "\n",
    "from dataloader.dataloader import MultimodaFeaturesDataset\n",
    "from src.loss.loss_compute import SimpleLossCompute\n",
    "from src.model.baseline_model import Baseline\n",
    "from src.loop.run_epoch import training_loop,validating_loop\n",
    "\n",
    "#torch.multiprocessing.set_start_method('spawn')\n",
    "config_path = './config/config.yaml'\n",
    "config = yaml.load(open(config_path))\n",
    "# 定义数据集并封装dataloader\n",
    "dataset = MultimodaFeaturesDataset(config['DatasetConfig'],job='training')\n",
    "loader = DataLoader(dataset,num_workers=8,batch_size=config['DatasetConfig']['batch_size'],collate_fn=dataset.collate_fn)\n",
    "# 定义模型\n",
    "model = Baseline(config['ModelConfig'])\n",
    "# model = torch.nn.DataParallel(model,[0,1])\n",
    "model.to(dataset.device)\n",
    "# 定义loss函数和优化器\n",
    "criterion = nn.BCELoss(reduction='none')# sum应该没问题吧\n",
    "# 不同部件采用不同的学习率\n",
    "\n",
    "classifier_params = list(map(id, model.classifier_dict.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in classifier_params,\n",
    "                     model.parameters())\n",
    "optimizer = torch.optim.Adam([\n",
    "            {'params': base_params},\n",
    "            {'params': model.classifier_dict.parameters(), 'lr': 1e-2}],lr=1e-4)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "loss_compute = SimpleLossCompute(criterion,optimizer)\n",
    "\n",
    "\n",
    "epoch_num=100\n",
    "loss_epoch = []\n",
    "for epoch in range(epoch_num):\n",
    "    loss = training_loop(model, loader, loss_compute, epoch)\n",
    "    loss_epoch.append(loss)\n",
    "    print(sum(loss_epoch[epoch])/157)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-b9da430cc202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'keys'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2e8481db70>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_mean_epoch = []\n",
    "for epoch in range(epoch_num):\n",
    "    loss_mean_epoch.append(sum(loss_epoch[epoch])/157)\n",
    "plt.plot(loss_mean_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'./checkpoint/temp.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gap:  0.9947396877274343\n",
      "gap:  0.9824204769295231\n",
      "gap:  0.9947389925049824\n",
      "gap:  0.9849995300545505\n",
      "gap:  0.9743947073137559\n",
      "gap:  0.9849504304974611\n",
      "gap:  0.9999030963690078\n",
      "gap:  0.9903641571057922\n",
      "gap:  0.9999239971563098\n",
      "gap:  0.9950859950859898\n",
      "gap:  0.9780105008492771\n",
      "gap:  0.9950555862671162\n",
      "gap:  0.9973495842419039\n",
      "gap:  0.9890720336062035\n",
      "gap:  0.9974100150560822\n",
      "gap:  0.9998819309566224\n",
      "gap:  0.9873112850150898\n",
      "gap:  1.0000000000000042\n",
      "gap:  0.9753570341275639\n",
      "gap:  0.9599348685717313\n",
      "gap:  0.97536325396137\n",
      "gap:  0.997566909975668\n",
      "gap:  0.9910614971280045\n",
      "gap:  0.997566909975668\n",
      "gap:  0.9973545157719649\n",
      "gap:  0.9884101056732897\n",
      "gap:  0.9973545157719649\n",
      "gap:  1.0000000000000075\n",
      "gap:  0.9866552715727663\n",
      "gap:  1.0000000000000075\n",
      "gap:  0.9799670391477386\n",
      "gap:  0.9719914960571758\n",
      "gap:  0.9800372004979281\n",
      "gap:  0.9997580394223576\n",
      "gap:  0.9866161166897337\n",
      "gap:  0.9998618080992486\n",
      "gap:  0.9999999999999989\n",
      "gap:  0.9909164478691321\n",
      "gap:  0.9999940944416874\n",
      "gap:  0.9898121371334503\n",
      "gap:  0.9792881670866114\n",
      "gap:  0.9898175013363163\n",
      "gap:  0.994974874371852\n",
      "gap:  0.9756920230552365\n",
      "gap:  0.994974874371852\n",
      "gap:  0.992366412213736\n",
      "gap:  0.9826565422631873\n",
      "gap:  0.992366412213736\n",
      "gap:  1.0000000000000075\n",
      "gap:  0.9863839017969807\n",
      "gap:  1.0000000000000075\n",
      "gap:  0.9944444444444415\n",
      "gap:  0.9805423155459064\n",
      "gap:  0.9944444444444415\n",
      "gap:  0.9999364336117395\n",
      "gap:  0.9870079283768259\n",
      "gap:  0.9999884569045917\n",
      "gap:  0.992457419133487\n",
      "gap:  0.9839404474981785\n",
      "gap:  0.9925560713063648\n",
      "gap:  0.9999933057530388\n",
      "gap:  0.9840487857782609\n",
      "gap:  1.0000000000000029\n",
      "gap:  0.9999522057250886\n",
      "gap:  0.9891249289334432\n",
      "gap:  0.9999727306813861\n",
      "gap:  0.9929035404944827\n",
      "gap:  0.9773491040808663\n",
      "gap:  0.9935299226359822\n",
      "gap:  0.9944674647608353\n",
      "gap:  0.9805548865274119\n",
      "gap:  0.9944903581267293\n",
      "gap:  0.99955504050858\n",
      "gap:  0.9627931680134849\n",
      "gap:  0.9997019360612374\n",
      "gap:  0.999999999999994\n",
      "gap:  0.9911018521369983\n",
      "gap:  0.999999999999994\n",
      "gap:  0.9948186528497439\n",
      "gap:  0.9850432180524911\n",
      "gap:  0.9948186528497439\n",
      "gap:  0.9939931604663218\n",
      "gap:  0.9784408658334668\n",
      "gap:  0.996455807197489\n",
      "gap:  0.9972146968923397\n",
      "gap:  0.9833899264342317\n",
      "gap:  0.9971383604828314\n",
      "gap:  0.9949874686716682\n",
      "gap:  0.9876085253287028\n",
      "gap:  0.9949874686716682\n",
      "gap:  1.0000000000000067\n",
      "gap:  0.9892980400455509\n",
      "gap:  1.0000000000000067\n",
      "gap:  1.0000000000000009\n",
      "gap:  0.9804532216490316\n",
      "gap:  1.0000000000000009\n",
      "gap:  0.99706648985477\n",
      "gap:  0.9903044413375639\n",
      "gap:  0.9971769823326584\n",
      "gap:  0.9999789479593497\n",
      "gap:  0.9962787143041402\n",
      "gap:  0.9999999999999941\n",
      "gap:  0.9999999999999931\n",
      "gap:  0.9836016479793808\n",
      "gap:  0.9999999999999931\n",
      "gap:  0.9951100244498704\n",
      "gap:  0.985283388833214\n",
      "gap:  0.9951100244498704\n",
      "gap:  0.9998889645895177\n",
      "gap:  0.9946069892434118\n",
      "gap:  0.9999756583006341\n",
      "gap:  1.0000000000000062\n",
      "gap:  0.9930495218392005\n",
      "gap:  1.0000000000000062\n",
      "gap:  0.999999999999997\n",
      "gap:  0.9925398343797645\n",
      "gap:  0.999999999999997\n",
      "gap:  0.9975062344139578\n",
      "gap:  0.9924334614661592\n",
      "gap:  0.9975062344139578\n",
      "gap:  0.9948979591836664\n",
      "gap:  0.9878276661811928\n",
      "gap:  0.9948717610688804\n",
      "gap:  0.9995555083574964\n",
      "gap:  0.9892216844856329\n",
      "gap:  0.9995658888647749\n",
      "gap:  0.9975490196078401\n",
      "gap:  0.9878499305086168\n",
      "gap:  0.9975490196078401\n",
      "gap:  0.997109826589602\n",
      "gap:  0.9822899390050175\n",
      "gap:  0.997109826589602\n",
      "gap:  0.9974619289340017\n",
      "gap:  0.9769576982748892\n",
      "gap:  0.9974619289340017\n",
      "gap:  0.9998281701605402\n",
      "gap:  0.9912960228332611\n",
      "gap:  0.9997830476145516\n",
      "gap:  0.9975369458128179\n",
      "gap:  0.9819827429316732\n",
      "gap:  0.9975369458128179\n",
      "gap:  0.9944598337950069\n",
      "gap:  0.981843388967168\n",
      "gap:  0.9944521391197222\n",
      "gap:  0.999999999999997\n",
      "gap:  0.9897204752518387\n",
      "gap:  0.9998749447928171\n",
      "gap:  0.9951296491345605\n",
      "gap:  0.9814689608435688\n",
      "gap:  0.9951695098310297\n",
      "gap:  0.9852155325970885\n",
      "gap:  0.9776419172302817\n",
      "gap:  0.9852216748768571\n",
      "gap:  1.0000000000000047\n",
      "gap:  0.9905311185666205\n",
      "gap:  0.9999872461180418\n",
      "gap:  0.9999999999999936\n",
      "gap:  0.98188238422005\n",
      "gap:  0.9999999999999936\n",
      "gap:  0.999999999999997\n",
      "gap:  0.9926713168720404\n",
      "gap:  0.999999999999997\n",
      "gap:  1.0000000000000033\n",
      "gap:  0.9936364880956657\n",
      "gap:  1.0000000000000033\n",
      "gap:  0.9998885607622399\n",
      "gap:  0.9892634572149203\n",
      "gap:  0.9999935418038988\n",
      "gap:  0.9999027139549775\n",
      "gap:  0.9896908076780925\n",
      "gap:  0.999944524095636\n",
      "gap:  0.9974160206718303\n",
      "gap:  0.9858355809114303\n",
      "gap:  0.9974160206718303\n",
      "gap:  0.9998211520483179\n",
      "gap:  0.9806977329164644\n",
      "gap:  0.9989011860988474\n",
      "gap:  0.9972602739725993\n",
      "gap:  0.9881501559265263\n",
      "gap:  0.9972376936994177\n",
      "gap:  0.9999933744997718\n",
      "gap:  0.9975272460392952\n",
      "gap:  0.9999342153253938\n",
      "gap:  0.9923273657289071\n",
      "gap:  0.9863278619950305\n",
      "gap:  0.9923273657289071\n",
      "gap:  0.9946524064171156\n",
      "gap:  0.9825523727317954\n",
      "gap:  0.9946524064171156\n",
      "gap:  0.9874056210701678\n",
      "gap:  0.9721726591324964\n",
      "gap:  0.987437185929641\n",
      "gap:  0.9999999999999927\n",
      "gap:  0.9932849421158437\n",
      "gap:  0.9999999999999927\n",
      "gap:  0.9999028462836212\n",
      "gap:  0.9896897524376609\n",
      "gap:  0.9999508084107807\n",
      "gap:  0.999999999999997\n",
      "gap:  0.9952349041042318\n",
      "gap:  0.9999934421929277\n",
      "gap:  0.9999999999999923\n",
      "gap:  0.9918351230765499\n",
      "gap:  0.9999782624447427\n",
      "gap:  0.9953649871089445\n",
      "gap:  0.9848979405406574\n",
      "gap:  0.9953107576053221\n",
      "gap:  0.9999999999999929\n",
      "gap:  0.9942333459462507\n",
      "gap:  0.9999999999999929\n",
      "gap:  1.0000000000000024\n",
      "gap:  0.9922114868236317\n",
      "gap:  1.0000000000000024\n",
      "gap:  1.0000000000000067\n",
      "gap:  0.9935613884710599\n",
      "gap:  1.0000000000000067\n",
      "gap:  0.9864130434782546\n",
      "gap:  0.9787709799662968\n",
      "gap:  0.9864130434782546\n",
      "gap:  0.9950980392156833\n",
      "gap:  0.9895123987307853\n",
      "gap:  0.9950980392156833\n",
      "gap:  0.9756610329282491\n",
      "gap:  0.9669038488999047\n",
      "gap:  0.9757382004466273\n",
      "gap:  0.9946380697050944\n",
      "gap:  0.9901245186521969\n",
      "gap:  0.9946380697050944\n",
      "gap:  0.9999576156687792\n",
      "gap:  0.9793074503853952\n",
      "gap:  0.9999999999999941\n",
      "gap:  0.9953810623556534\n",
      "gap:  0.9868181138023105\n",
      "gap:  0.9953810623556534\n",
      "gap:  0.9974875930511532\n",
      "gap:  0.99172678308841\n",
      "gap:  0.9974875930511532\n",
      "gap:  0.9971671388102062\n",
      "gap:  0.9919743231021005\n",
      "gap:  0.997102776967584\n",
      "gap:  0.9976020542174516\n",
      "gap:  0.9928629321550821\n",
      "gap:  0.997607696220888\n",
      "gap:  0.9949494949494884\n",
      "gap:  0.9813167621273237\n",
      "gap:  0.9949494949494884\n",
      "gap:  0.999999999999997\n",
      "gap:  0.9877223652307616\n",
      "gap:  0.999999999999997\n",
      "gap:  0.9838709677419347\n",
      "gap:  0.9771245243137745\n",
      "gap:  0.9838709677419347\n",
      "gap:  0.9949238904021838\n",
      "gap:  0.9828840553386373\n",
      "gap:  0.9949367088607641\n",
      "gap:  0.9999999999999954\n",
      "gap:  0.9946292736118214\n",
      "gap:  0.9999999999999954\n",
      "gap:  0.9948120618545615\n",
      "gap:  0.9897781931969136\n",
      "gap:  0.9947186525941633\n",
      "gap:  0.9999999999999942\n",
      "gap:  0.9844077553180037\n",
      "gap:  0.9999999999999942\n",
      "gap:  0.9998470921387783\n",
      "gap:  0.9935506457761988\n",
      "gap:  0.9999054931985197\n",
      "gap:  0.9891008979205987\n",
      "gap:  0.973777415805538\n",
      "gap:  0.9890861484014922\n",
      "gap:  1.0000000000000042\n",
      "gap:  0.9900054952052075\n",
      "gap:  0.9999795484757974\n",
      "gap:  0.9999592061320893\n",
      "gap:  0.9907717848669217\n",
      "gap:  1.0000000000000044\n",
      "gap:  0.9999999999999931\n",
      "gap:  0.9927236204709069\n",
      "gap:  0.9999999999999931\n",
      "gap:  0.9998958041628934\n",
      "gap:  0.9925749726718532\n",
      "gap:  0.9999120023970891\n",
      "gap:  0.9996616386149475\n",
      "gap:  0.9783048619647349\n",
      "gap:  0.99970440106809\n",
      "gap:  0.9920634920634998\n",
      "gap:  0.9803030750566082\n",
      "gap:  0.9920634920634998\n",
      "gap:  0.9999876853357049\n",
      "gap:  0.9931477169406195\n",
      "gap:  0.9999570950461729\n",
      "gap:  0.9813261065944053\n",
      "gap:  0.9734228126344701\n",
      "gap:  0.9813333333333394\n",
      "gap:  0.9976076555023853\n",
      "gap:  0.9885300698595255\n",
      "gap:  0.9976019321901901\n",
      "gap:  0.9856799862307927\n",
      "gap:  0.9786313282509003\n",
      "gap:  0.9857142857142828\n",
      "gap:  1.0000000000000075\n",
      "gap:  0.9879959004804713\n",
      "gap:  1.0000000000000075\n",
      "gap:  0.997340425531909\n",
      "gap:  0.9865914858102548\n",
      "gap:  0.997340425531909\n",
      "gap:  0.9999999999999954\n",
      "gap:  0.9949406679437011\n",
      "gap:  0.9999999999999954\n",
      "gap:  0.9951690821256076\n",
      "gap:  0.9854880203176413\n",
      "gap:  0.9951690821256076\n",
      "gap:  0.9995878380602078\n",
      "gap:  0.9904934685302197\n",
      "gap:  0.9999046406271973\n",
      "gap:  0.9948849104859404\n",
      "gap:  0.9757340037250205\n",
      "gap:  0.9948849104859404\n",
      "gap:  0.9999999999999927\n",
      "gap:  0.998603094034307\n",
      "gap:  0.9999999999999927\n",
      "gap:  0.9918526262422904\n",
      "gap:  0.9866105426522546\n",
      "gap:  0.991974310599427\n",
      "gap:  0.9999817549322507\n",
      "gap:  0.9953966494068772\n",
      "gap:  0.9999513747523314\n",
      "gap:  0.9999933402594592\n",
      "gap:  0.9888379856446167\n",
      "gap:  0.9999866633102908\n",
      "gap:  0.997180865729252\n",
      "gap:  0.9810642791552594\n",
      "gap:  0.9973118279569885\n",
      "gap:  0.9874565020057382\n",
      "gap:  0.9788810903401175\n",
      "gap:  0.9873526666261534\n",
      "gap:  0.9972752043596795\n",
      "gap:  0.9845147108570385\n",
      "gap:  0.997267779848398\n",
      "gap:  0.9927536231884095\n",
      "gap:  0.9810819816856979\n",
      "gap:  0.9927536231884095\n",
      "gap:  1.00000000000001\n",
      "gap:  0.9886905893357454\n",
      "gap:  1.00000000000001\n",
      "gap:  0.9999999999999933\n",
      "gap:  0.9958289260005375\n",
      "gap:  0.9999999999999933\n",
      "gap:  1.0000000000000016\n",
      "gap:  0.9927246007924468\n",
      "gap:  1.0000000000000016\n",
      "gap:  1.0000000000000078\n",
      "gap:  0.9963959606439489\n",
      "gap:  1.0000000000000078\n",
      "gap:  0.9948717948717919\n",
      "gap:  0.9886249167616357\n",
      "gap:  0.9948717948717919\n",
      "gap:  0.999999999999997\n",
      "gap:  0.9962427650266366\n",
      "gap:  0.9999921756412032\n",
      "gap:  1.0000000000000075\n",
      "gap:  0.9933987033721036\n",
      "gap:  1.0000000000000075\n",
      "gap:  0.9922511457432527\n",
      "gap:  0.9832075912042115\n",
      "gap:  0.9922186178081132\n",
      "gap:  0.9975903614457772\n",
      "gap:  0.9931543381899904\n",
      "gap:  0.9975787347048342\n",
      "gap:  0.9926108374384336\n",
      "gap:  0.9842720569425402\n",
      "gap:  0.9926108374384336\n",
      "gap:  0.999840544985424\n",
      "gap:  0.9909478468064462\n",
      "gap:  0.9996970556778564\n",
      "gap:  0.9947042146578688\n",
      "gap:  0.980911500470668\n",
      "gap:  0.9946703079840362\n",
      "gap:  1.00000000000001\n",
      "gap:  0.9817370598113481\n",
      "gap:  1.00000000000001\n",
      "gap:  0.984320425470357\n",
      "gap:  0.9799940867311371\n",
      "gap:  0.9842648903373181\n",
      "gap:  0.9999567885230207\n",
      "gap:  0.9806664606736223\n",
      "gap:  0.9999505071554414\n",
      "gap:  0.9975062344139578\n",
      "gap:  0.995117389107914\n",
      "gap:  0.9975062344139578\n",
      "gap:  0.9927249525910655\n",
      "gap:  0.9856317753564222\n",
      "gap:  0.9927536230528938\n",
      "gap:  0.9928229665071701\n",
      "gap:  0.9908855255629032\n",
      "gap:  0.9928229665071701\n",
      "gap:  0.9999791692705156\n",
      "gap:  0.9953646547202866\n",
      "gap:  0.9999721705862682\n",
      "gap:  0.9974424552429737\n",
      "gap:  0.9896686201552307\n",
      "gap:  0.9974424552429737\n",
      "gap:  0.9922693014324135\n",
      "gap:  0.9868374348699458\n",
      "gap:  0.9923338062161395\n",
      "gap:  0.9923403642812479\n",
      "gap:  0.9883091395858075\n",
      "gap:  0.9923337057498066\n",
      "gap:  0.9974293059126036\n",
      "gap:  0.9908769776079647\n",
      "gap:  0.9974293059126036\n",
      "gap:  0.9999926756024351\n",
      "gap:  0.9879356405170303\n",
      "gap:  1.0000000000000033\n",
      "gap:  0.9825814274099346\n",
      "gap:  0.9695278302427531\n",
      "gap:  0.9825249204809849\n",
      "gap:  1.0000000000000007\n",
      "gap:  0.9915184046632766\n",
      "gap:  1.0000000000000007\n",
      "gap:  1.00000000000001\n",
      "gap:  0.9958839704371423\n",
      "gap:  1.00000000000001\n",
      "gap:  0.9797081843656438\n",
      "gap:  0.9711809911387146\n",
      "gap:  0.9797016426458256\n",
      "gap:  0.999899216072794\n",
      "gap:  0.9950001015463977\n",
      "gap:  0.9998652917313497\n",
      "gap:  0.9950859950859898\n",
      "gap:  0.9921740314087646\n",
      "gap:  0.9950859950859898\n",
      "gap:  0.9999999999999942\n",
      "gap:  0.9898994250032637\n",
      "gap:  0.9999999999999942\n",
      "gap:  0.98247591775559\n",
      "gap:  0.9711472085261778\n",
      "gap:  0.9800930858442698\n",
      "gap:  0.9974358974358944\n",
      "gap:  0.9898759284563614\n",
      "gap:  0.9974358974358944\n",
      "gap:  1.0000000000000047\n",
      "gap:  0.9919953414600273\n",
      "gap:  1.0000000000000047\n",
      "gap:  0.9999124979807282\n",
      "gap:  0.9939550988252398\n",
      "gap:  1.0000000000000056\n",
      "gap:  0.994565217391298\n",
      "gap:  0.9843799863808361\n",
      "gap:  0.994565217391298\n",
      "gap:  0.9999613469306311\n",
      "gap:  0.9972445145066849\n",
      "gap:  0.9999613469306311\n",
      "gap:  0.9950495049504958\n",
      "gap:  0.9901199101168606\n",
      "gap:  0.9950495049504958\n",
      "gap:  0.9999999999999947\n",
      "gap:  0.9927680787237309\n",
      "gap:  0.9999999999999947\n",
      "gap:  0.9999999999999941\n",
      "gap:  0.9940952890045907\n",
      "gap:  0.9999999999999941\n",
      "gap:  0.9975430854552971\n",
      "gap:  0.9862088683519169\n",
      "gap:  0.9975490342597113\n",
      "gap:  0.987437185929641\n",
      "gap:  0.9756021554242899\n",
      "gap:  0.987437185929641\n",
      "gap:  0.9999999999999988\n",
      "gap:  0.9999999999999988\n",
      "gap:  0.9999999999999988\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import utils.train_util as train_util\n",
    "model.eval()\n",
    "modal_name_list=['video','audio']\n",
    "tagging_class_num = 82\n",
    "evl_metrics = [train_util.EvaluationMetrics(tagging_class_num, top_k=20)\n",
    "                           for i in range(len(modal_name_list)+1)] #+1 for fusion\n",
    "for i in range(len(evl_metrics)):\n",
    "    evl_metrics[i].clear()\n",
    "\n",
    "criterion = nn.BCELoss(reduction='none')# sum应该没问题吧\n",
    "optimizer = None\n",
    "loss_compute = SimpleLossCompute(criterion,optimizer)\n",
    "\n",
    "for i,batch in enumerate(loader):\n",
    "    video,audio,text,label = batch\n",
    "    inputs_dict={}\n",
    "    inputs_dict['video'] = video\n",
    "    inputs_dict['audio'] = audio\n",
    "    inputs_dict['text'] = text\n",
    "    pred_dict = model(inputs_dict)\n",
    "    for index,modal_name in enumerate(modal_name_list+['fusion']):\n",
    "        pred = pred_dict['tagging_output_'+modal_name]\n",
    "        val_label = label\n",
    "        loss = loss_compute(pred['predictions'],val_label)\n",
    "        pred = pred['predictions'].detach().cpu().numpy()\n",
    "        val_label = label.cpu().numpy()\n",
    "        #print(np.array(pred_gap))\n",
    "        #print(val_label_gap)\n",
    "        gap = train_util.calculate_gap(pred, val_label)\n",
    "        print('gap: ',gap)\n",
    "        evl_metrics[index].accumulate(pred, val_label, loss=0)\n",
    "    if(i>500):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 3\n",
    "kf = GroupKFold(n_splits = N_FOLDS)\n",
    "for fold,(train_idx,val_idx) in enumerate(kf.split(df_train)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x7f2db0fc5308>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.split(range(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The 'groups' parameter should not be None.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-4db540668e5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mval_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mBy\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelegates\u001b[0m \u001b[0mto\u001b[0m \u001b[0m_iter_test_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0mtest_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mtest_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The 'groups' parameter should not be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The 'groups' parameter should not be None."
     ]
    }
   ],
   "source": [
    "train_indices = []\n",
    "val_indices = []\n",
    "for fold,(train_idx,val_idx) in enumerate(kf.split(range(5000))):\n",
    "    print(fold)\n",
    "    train_indices.append(train_idx)\n",
    "    val_indices.append(val_idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.9 * len(full_dataset))\n",
    "validation_size = len(full_dataset) - train_size\n",
    "train_dataset, validation_dataset = random_split(full_dataset, [train_size, validation_size])\n",
    "\n",
    "#full_loader = DataLoader(full_dataset, batch_size=4,sampler = sampler_(full_dataset), pin_memory=True) \n",
    "#train_loader = DataLoader(train_dataset, batch_size=4, sampler = sampler_(train_dataset))\n",
    "#val_loader = DataLoader(validation_dataset, batch_size=1, sampler = sampler_(validation_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import dataloader.dataloader\n",
    "importlib.reload(dataloader.dataloader)\n",
    "from dataloader.dataloader import MultimodaFeaturesDataset\n",
    "full_dataset = MultimodaFeaturesDataset(config['DatasetConfig'],job='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main.py:17: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(open(config_path))\n",
      "initialization: xavier\n",
      "train (0): 100%|██████████████████████████████| 141/141 [00:21<00:00,  6.47it/s]\n",
      "epoch(0):  0.659564155880006\n",
      "train (1): 100%|██████████████████████████████| 141/141 [00:20<00:00,  6.99it/s]\n",
      "train (2): 100%|██████████████████████████████| 141/141 [00:20<00:00,  6.99it/s]\n",
      "train (3): 100%|██████████████████████████████| 141/141 [00:20<00:00,  7.04it/s]\n",
      "train (4): 100%|██████████████████████████████| 141/141 [00:20<00:00,  7.03it/s]\n",
      "train (5): 100%|██████████████████████████████| 141/141 [00:20<00:00,  6.96it/s]\n",
      "epoch(5):  0.720593742548453\n",
      "train (6): 100%|██████████████████████████████| 141/141 [00:20<00:00,  7.00it/s]\n",
      "train (7): 100%|██████████████████████████████| 141/141 [00:20<00:00,  6.96it/s]\n",
      "train (8): 100%|██████████████████████████████| 141/141 [00:20<00:00,  6.96it/s]\n",
      "train (9): 100%|██████████████████████████████| 141/141 [00:20<00:00,  6.97it/s]\n",
      "train (10): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.98it/s]\n",
      "epoch(10):  0.7252860059533054\n",
      "train (11): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.96it/s]\n",
      "train (12): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.94it/s]\n",
      "train (13): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.94it/s]\n",
      "train (14): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.97it/s]\n",
      "train (15): 100%|█████████████████████████████| 141/141 [00:20<00:00,  7.04it/s]\n",
      "epoch(15):  0.7226534714012187\n",
      "train (16): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.97it/s]\n",
      "train (17): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.95it/s]\n",
      "train (18): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.97it/s]\n",
      "train (19): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.99it/s]\n",
      "train (20): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.94it/s]\n",
      "epoch(20):  0.7152014708715304\n",
      "train (21): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.98it/s]\n",
      "train (22): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.99it/s]\n",
      "train (23): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.95it/s]\n",
      "train (24): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.92it/s]\n",
      "train (25): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.95it/s]\n",
      "epoch(25):  0.7237205410461923\n",
      "train (26): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.96it/s]\n",
      "train (27): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.97it/s]\n",
      "train (28): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.94it/s]\n",
      "train (29): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.96it/s]\n",
      "train (30): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.99it/s]\n",
      "epoch(30):  0.7225769033161213\n",
      "train (31): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.98it/s]\n",
      "train (32): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.88it/s]\n",
      "train (33): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.95it/s]\n",
      "train (34): 100%|█████████████████████████████| 141/141 [00:20<00:00,  7.01it/s]\n",
      "train (35): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.97it/s]\n",
      "epoch(35):  0.7229358495121692\n",
      "train (36): 100%|█████████████████████████████| 141/141 [00:19<00:00,  7.06it/s]\n",
      "train (37): 100%|█████████████████████████████| 141/141 [00:20<00:00,  7.02it/s]\n",
      "train (38): 100%|█████████████████████████████| 141/141 [00:20<00:00,  7.01it/s]\n",
      "train (39): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.91it/s]\n",
      "train (40): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.94it/s]\n",
      "epoch(40):  0.7228811725742703\n",
      "train (41): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.99it/s]\n",
      "train (42): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.98it/s]\n",
      "train (43): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.96it/s]\n",
      "train (44): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.99it/s]\n",
      "train (45): 100%|█████████████████████████████| 141/141 [00:20<00:00,  7.01it/s]\n",
      "epoch(45):  0.7204610544605491\n",
      "train (46): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.89it/s]\n",
      "train (47): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.93it/s]\n",
      "train (48): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.97it/s]\n",
      "train (49): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.98it/s]\n",
      "train (50): 100%|█████████████████████████████| 141/141 [00:20<00:00,  7.00it/s]\n",
      "epoch(50):  0.7189849882701334\n",
      "train (51): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.89it/s]\n",
      "train (52): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.93it/s]\n",
      "train (53): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.95it/s]\n",
      "train (54): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.97it/s]\n",
      "train (55): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.84it/s]\n",
      "epoch(55):  0.7179667961775175\n",
      "train (56): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.99it/s]\n",
      "train (57): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.90it/s]\n",
      "train (58): 100%|█████████████████████████████| 141/141 [00:20<00:00,  6.97it/s]\n",
      "train (59):   0%|                                       | 0/141 [00:00<?, ?it/s]^C\n",
      "train (59):   0%|                                       | 0/141 [00:11<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 43, in <module>\n",
      "    loss = training_loop(model, train_loader, loss_compute, epoch)\n",
      "  File \"/home/tione/notebook/baseline_torch/src/loop/run_epoch.py\", line 12, in training_loop\n",
      "    for i, batch in enumerate(tqdm(loader, desc=f'train ({epoch})')):\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/tqdm/std.py\", line 1129, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 345, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 841, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 808, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 761, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_loop(model, dataset,modal_name_list,device,epoch):\n",
    "    model.eval()\n",
    "    tagging_class_num = 82\n",
    "    evl_metrics = [train_util.EvaluationMetrics(tagging_class_num, top_k=20)\n",
    "                               for i in range(len(modal_name_list)+1)] #+1 for fusion\n",
    "    for i in range(len(evl_metrics)):\n",
    "        evl_metrics[i].clear()\n",
    "    metric_dict = {}\n",
    "    gap_dict = {}\n",
    "    for i in range(len(dataset)):\n",
    "        video,audio,text,text_mask,label = dataset[i]\n",
    "        \n",
    "        video = video.to(device)\n",
    "        audio = audio.to(device)\n",
    "        text = text.to(device)\n",
    "        text_mask = text_mask.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        inputs_dict={}\n",
    "        inputs_dict['video'] = video\n",
    "        inputs_dict['audio'] = audio\n",
    "        inputs_dict['text'] = text\n",
    "        inputs_dict['attention_mask'] = text_mask\n",
    "        \n",
    "        pred_dict = model(inputs_dict)\n",
    "        \n",
    "        pred_dict['tagging_output_fusion']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
