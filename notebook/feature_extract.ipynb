{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting albumentations\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/03/58/63fb1d742dc42d9ba2800ea741de1f2bc6bb05548d8724aa84794042eaf2/albumentations-0.5.2-py3-none-any.whl (72 kB)\n",
      "\u001b[K     |████████████████████████████████| 72 kB 6.6 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting scikit-image>=0.16.1\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/0e/ba/53e1bfbdfd0f94514d71502e3acea494a8b4b57c457adbc333ef386485da/scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 477 kB/s eta 0:00:01�███| 12.4 MB 477 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from albumentations) (1.18.5)\n",
      "Collecting imgaug>=0.4.0\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "\u001b[K     |████████████████████████████████| 948 kB 104.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from albumentations) (1.5.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from albumentations) (5.3.1)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/cc/09/3ed889f37b1bb1dff85f10d91b1f9e8b8a812a7e8413c4e906c21aab9469/opencv_python_headless-4.5.2.52-cp36-cp36m-manylinux2014_x86_64.whl (38.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 38.2 MB 451 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting imageio>=2.3.0\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/6e/57/5d899fae74c1752f52869b613a8210a2480e1a69688e65df6cb26117d45d/imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 11.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx>=2.0\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/f3/b7/c7f488101c0bb5e4178f3cde416004280fd40262433496830de8a8c21613/networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 90.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tifffile>=2019.7.26\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/42/6b/93a8ee61c6fbe20fa9c17928bd3b80484902b7fd454cecaffba42f5052cb/tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
      "\u001b[K     |████████████████████████████████| 148 kB 23.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from scikit-image>=0.16.1->albumentations) (2.2.2)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/59/bb/d2b85265ec9fa3c1922210c9393d4cdf7075cc87cce6fe671d7455f80fbc/PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 16.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n",
      "Collecting Shapely\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/9d/18/557d4f55453fe00f59807b111cc7b39ce53594e13ada88e16738fb4ff7fb/Shapely-1.7.1-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 67.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from imgaug>=0.4.0->albumentations) (1.15.0)\n",
      "Collecting opencv-python\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/ec/de/e5308044f192cfb10ebe394bf9c6f38f9d77a3f57328354e756633c068f9/opencv_python-4.5.2.52-cp36-cp36m-manylinux2014_x86_64.whl (51.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 51.0 MB 441 kB/s eta 0:00:011��████▊                     | 17.1 MB 956 kB/s eta 0:00:36\n",
      "\u001b[?25hRequirement already satisfied: decorator<5,>=4.3 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2020.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.2.0)\n",
      "Installing collected packages: imageio, networkx, tifffile, PyWavelets, scikit-image, Shapely, opencv-python, imgaug, opencv-python-headless, albumentations\n",
      "Successfully installed PyWavelets-1.1.1 Shapely-1.7.1 albumentations-0.5.2 imageio-2.9.0 imgaug-0.4.0 networkx-2.5.1 opencv-python-4.5.2.52 opencv-python-headless-4.5.2.52 scikit-image-0.17.2 tifffile-2020.9.3\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.12\n",
      "  latest version: 4.10.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda/envs/pytorch_py3\n",
      "\n",
      "  added / updated specs:\n",
      "    - ipywidgets\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    attrs-21.2.0               |     pyhd8ed1ab_0          44 KB  conda-forge\n",
      "    bleach-3.3.0               |     pyh44b312d_0         111 KB  conda-forge\n",
      "    ca-certificates-2021.5.30  |       ha878542_0         136 KB  conda-forge\n",
      "    certifi-2021.5.30          |   py36h5fab9bb_0         141 KB  conda-forge\n",
      "    defusedxml-0.7.1           |     pyhd8ed1ab_0          23 KB  conda-forge\n",
      "    importlib-metadata-4.4.0   |   py36h5fab9bb_0          31 KB  conda-forge\n",
      "    ipywidgets-7.6.3           |     pyhd3deb0d_0         101 KB  conda-forge\n",
      "    jinja2-2.11.3              |     pyh44b312d_0          93 KB  conda-forge\n",
      "    jsonschema-3.2.0           |     pyhd8ed1ab_3          45 KB  conda-forge\n",
      "    jupyterlab_widgets-1.0.0   |     pyhd8ed1ab_1         130 KB  conda-forge\n",
      "    markupsafe-1.1.1           |   py36he6145b8_2          27 KB  conda-forge\n",
      "    mistune-0.8.4              |py36h1d69622_1002          54 KB  conda-forge\n",
      "    nbconvert-5.6.1            |   py36h9f0ad1d_1         487 KB  conda-forge\n",
      "    nbformat-5.1.3             |     pyhd8ed1ab_0          47 KB  conda-forge\n",
      "    notebook-5.7.10            |   py36h9f0ad1d_0         7.6 MB  conda-forge\n",
      "    packaging-20.9             |     pyh44b312d_0          35 KB  conda-forge\n",
      "    pandoc-2.14.0.1            |       h7f98852_0        12.0 MB  conda-forge\n",
      "    pandocfilters-1.4.2        |             py_1           9 KB  conda-forge\n",
      "    prometheus_client-0.11.0   |     pyhd8ed1ab_0          46 KB  conda-forge\n",
      "    pyrsistent-0.17.3          |   py36h1d69622_1          89 KB  conda-forge\n",
      "    send2trash-1.5.0           |             py_0          12 KB  conda-forge\n",
      "    terminado-0.10.0           |   py36h5fab9bb_0          26 KB  conda-forge\n",
      "    testpath-0.5.0             |     pyhd8ed1ab_0          86 KB  conda-forge\n",
      "    typing_extensions-3.7.4.3  |             py_0          25 KB  conda-forge\n",
      "    webencodings-0.5.1         |             py_1          12 KB  conda-forge\n",
      "    widgetsnbextension-3.5.1   |   py36h5fab9bb_4         1.8 MB  conda-forge\n",
      "    zipp-3.4.1                 |     pyhd8ed1ab_0          11 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        23.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  attrs              conda-forge/noarch::attrs-21.2.0-pyhd8ed1ab_0\n",
      "  bleach             conda-forge/noarch::bleach-3.3.0-pyh44b312d_0\n",
      "  defusedxml         conda-forge/noarch::defusedxml-0.7.1-pyhd8ed1ab_0\n",
      "  importlib-metadata conda-forge/linux-64::importlib-metadata-4.4.0-py36h5fab9bb_0\n",
      "  ipywidgets         conda-forge/noarch::ipywidgets-7.6.3-pyhd3deb0d_0\n",
      "  jinja2             conda-forge/noarch::jinja2-2.11.3-pyh44b312d_0\n",
      "  jsonschema         conda-forge/noarch::jsonschema-3.2.0-pyhd8ed1ab_3\n",
      "  jupyterlab_widgets conda-forge/noarch::jupyterlab_widgets-1.0.0-pyhd8ed1ab_1\n",
      "  markupsafe         conda-forge/linux-64::markupsafe-1.1.1-py36he6145b8_2\n",
      "  mistune            conda-forge/linux-64::mistune-0.8.4-py36h1d69622_1002\n",
      "  nbconvert          conda-forge/linux-64::nbconvert-5.6.1-py36h9f0ad1d_1\n",
      "  nbformat           conda-forge/noarch::nbformat-5.1.3-pyhd8ed1ab_0\n",
      "  notebook           conda-forge/linux-64::notebook-5.7.10-py36h9f0ad1d_0\n",
      "  packaging          conda-forge/noarch::packaging-20.9-pyh44b312d_0\n",
      "  pandoc             conda-forge/linux-64::pandoc-2.14.0.1-h7f98852_0\n",
      "  pandocfilters      conda-forge/noarch::pandocfilters-1.4.2-py_1\n",
      "  prometheus_client  conda-forge/noarch::prometheus_client-0.11.0-pyhd8ed1ab_0\n",
      "  pyrsistent         conda-forge/linux-64::pyrsistent-0.17.3-py36h1d69622_1\n",
      "  send2trash         conda-forge/noarch::send2trash-1.5.0-py_0\n",
      "  terminado          conda-forge/linux-64::terminado-0.10.0-py36h5fab9bb_0\n",
      "  testpath           conda-forge/noarch::testpath-0.5.0-pyhd8ed1ab_0\n",
      "  typing_extensions  conda-forge/noarch::typing_extensions-3.7.4.3-py_0\n",
      "  webencodings       conda-forge/noarch::webencodings-0.5.1-py_1\n",
      "  widgetsnbextension conda-forge/linux-64::widgetsnbextension-3.5.1-py36h5fab9bb_4\n",
      "  zipp               conda-forge/noarch::zipp-3.4.1-pyhd8ed1ab_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2020.6.20-hecda079_0 --> 2021.5.30-ha878542_0\n",
      "  certifi                          2020.6.20-py36h9f0ad1d_0 --> 2021.5.30-py36h5fab9bb_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "zipp-3.4.1           | 11 KB     | ##################################### | 100% \n",
      "ipywidgets-7.6.3     | 101 KB    | ##################################### | 100% \n",
      "markupsafe-1.1.1     | 27 KB     | ##################################### | 100% \n",
      "notebook-5.7.10      | 7.6 MB    | ##################################### | 100% \n",
      "pandoc-2.14.0.1      | 12.0 MB   | ##################################### | 100% \n",
      "webencodings-0.5.1   | 12 KB     | ##################################### | 100% \n",
      "nbformat-5.1.3       | 47 KB     | ##################################### | 100% \n",
      "typing_extensions-3. | 25 KB     | ##################################### | 100% \n",
      "jinja2-2.11.3        | 93 KB     | ##################################### | 100% \n",
      "packaging-20.9       | 35 KB     | ##################################### | 100% \n",
      "ca-certificates-2021 | 136 KB    | ##################################### | 100% \n",
      "nbconvert-5.6.1      | 487 KB    | ##################################### | 100% \n",
      "terminado-0.10.0     | 26 KB     | ##################################### | 100% \n",
      "send2trash-1.5.0     | 12 KB     | ##################################### | 100% \n",
      "testpath-0.5.0       | 86 KB     | ##################################### | 100% \n",
      "pandocfilters-1.4.2  | 9 KB      | ##################################### | 100% \n",
      "bleach-3.3.0         | 111 KB    | ##################################### | 100% \n",
      "jsonschema-3.2.0     | 45 KB     | ##################################### | 100% \n",
      "mistune-0.8.4        | 54 KB     | ##################################### | 100% \n",
      "widgetsnbextension-3 | 1.8 MB    | ##################################### | 100% \n",
      "certifi-2021.5.30    | 141 KB    | ##################################### | 100% \n",
      "importlib-metadata-4 | 31 KB     | ##################################### | 100% \n",
      "defusedxml-0.7.1     | 23 KB     | ##################################### | 100% \n",
      "pyrsistent-0.17.3    | 89 KB     | ##################################### | 100% \n",
      "attrs-21.2.0         | 44 KB     | ##################################### | 100% \n",
      "prometheus_client-0. | 46 KB     | ##################################### | 100% \n",
      "jupyterlab_widgets-1 | 130 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: | b'Enabling notebook extension jupyter-js-widgets/extension...\\n      - Validating: \\x1b[32mOK\\x1b[0m\\n'\n",
      "done\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!conda install -y -c conda-forge ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting transformers\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 8.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/6b/38/0ed2670578d803cb14350c54adb2a79835870aa9e3ad2e732be7359cb0e8/regex-2021.4.4-cp36-cp36m-manylinux2014_x86_64.whl (722 kB)\n",
      "\u001b[K     |████████████████████████████████| 722 kB 10.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from transformers) (2.24.0)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/b0/ec/029100a156a3671a385c78898cf16896f5c29a867d310895b4e221b722f5/tokenizers-0.10.2-cp36-cp36m-manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 16.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from transformers) (4.0.1)\n",
      "Collecting huggingface-hub==0.0.8\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from transformers) (4.46.1)\n",
      "Collecting dataclasses; python_version < \"3.7\"\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/fe/ca/75fac5856ab5cfa51bbbcefa250182e50441074fdc3f803f6e76451fab43/dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Collecting filelock\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/93/83/71a2ee6158bb9f39a90c0dea1637f81d5eef866e188e1971a1b1ab01a35a/filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from requests->transformers) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: six in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from sacremoses->transformers) (0.15.1)\n",
      "Collecting click\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/76/0a/b6c5f311e32aeb3b406e03c079ade51e905ea630fc19d1262a46249c1c86/click-8.0.1-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 15.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from packaging->transformers) (2.4.7)\n",
      "Installing collected packages: regex, tokenizers, click, sacremoses, filelock, huggingface-hub, dataclasses, transformers\n",
      "Successfully installed click-8.0.1 dataclasses-0.8 filelock-3.0.12 huggingface-hub-0.0.8 regex-2021.4.4 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "def frame_iterator_list(filename, every_ms=1000, max_num_frames=300):\n",
    "    video_capture = cv2.VideoCapture()\n",
    "    if not video_capture.open(filename):\n",
    "        print(sys.stderr, 'Error: Cannot open video file ' + filename)\n",
    "        return\n",
    "    last_ts = -99999  # The timestamp of last retrieved frame.\n",
    "    num_retrieved = 0\n",
    "\n",
    "    frame_all = []\n",
    "    while num_retrieved < max_num_frames:\n",
    "        # Skip frames\n",
    "        while video_capture.get(cv2.CAP_PROP_POS_MSEC) < every_ms + last_ts:\n",
    "            if not video_capture.read()[0]:\n",
    "                return np.array(frame_all)\n",
    "\n",
    "        last_ts = video_capture.get(cv2.CAP_PROP_POS_MSEC)\n",
    "        has_frames, frame = video_capture.read()\n",
    "        if not has_frames:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_all.append(frame[:, :, ::-1])\n",
    "        num_retrieved += 1\n",
    "\n",
    "    return np.array(frame_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms as T\n",
    "import torchvision.models as models\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "transform = T.Compose([T.Resize(256), T.CenterCrop(224), T.ToTensor()])\n",
    "A_transform = A.Compose([\n",
    "            # Resize(CFG.image_size, CFG.image_size),\n",
    "            # A.RandomResizedCrop(256, 256),\n",
    "            # A.Transpose(p=0.5),\n",
    "            # A.HorizontalFlip(p=0.5),\n",
    "            # A.VerticalFlip(p=0.5),\n",
    "            # A.ShiftScaleRotate(p=0.5),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],  # mean on ImageNet\n",
    "                std=[0.229, 0.224, 0.225],  # std on ImageNet\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "video_path = '../dataset/videos/video_5k/train_5k/'\n",
    "file_names = os.listdir(video_path)\n",
    "save_path = '../dataset/frames/train_5k/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# every_ms 指的是每 every_ms 提取 1帧，every_ms=1000时，每秒提取 1帧\n",
    "frame_list = frame_iterator_list(video_path+file_names[0],every_ms=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = file_names[0][:-4]\n",
    "save_name = save_path+video_id+'.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frame_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-865943b68ec8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframe_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mvideo_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msave_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'frame_list' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for frame in frame_list:\n",
    "    video_id = file_names[0][:-4]\n",
    "    save_name = save_path+video_id+'.npy'\n",
    "    if(os.path.exists(save_name)):\n",
    "        print(f'{file_names[0]} is exit')\n",
    "        break\n",
    "    frame_list = frame_iterator_list(video_path+file_names[0],every_ms=1000)\n",
    "    #np.save(save_name,frame_list)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 92 ms, sys: 12 ms, total: 104 ms\n",
      "Wall time: 103 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "video_processed = []\n",
    "for frame in frame_list:\n",
    "    augmented = A_transform(image=frame)\n",
    "    video_processed.append(augmented['image'].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video = torch.cat(video_processed,dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([56, 3, 256, 256])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting timm\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/ee/08/1ccaf8d516935666b7fa5f6aaddf157c66208ea0c93bb847ae09f166354f/timm-0.4.9-py3-none-any.whl (346 kB)\n",
      "\u001b[K     |████████████████████████████████| 346 kB 10.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from timm) (0.5.0)\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from timm) (1.4.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from torchvision->timm) (1.15.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from torchvision->timm) (1.18.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/envs/pytorch_py3/lib/python3.6/site-packages (from torchvision->timm) (7.1.2)\n",
      "Installing collected packages: timm\n",
      "Successfully installed timm-0.4.9\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adv_inception_v3',\n",
       " 'botnet26t_256',\n",
       " 'botnet50ts_256',\n",
       " 'cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'coat_lite_mini',\n",
       " 'coat_lite_small',\n",
       " 'coat_lite_tiny',\n",
       " 'coat_mini',\n",
       " 'coat_tiny',\n",
       " 'cspdarknet53',\n",
       " 'cspdarknet53_iabn',\n",
       " 'cspresnet50',\n",
       " 'cspresnet50d',\n",
       " 'cspresnet50w',\n",
       " 'cspresnext50',\n",
       " 'cspresnext50_iabn',\n",
       " 'darknet53',\n",
       " 'densenet121',\n",
       " 'densenet121d',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenet264',\n",
       " 'densenet264d_iabn',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0',\n",
       " 'dm_nfnet_f1',\n",
       " 'dm_nfnet_f2',\n",
       " 'dm_nfnet_f3',\n",
       " 'dm_nfnet_f4',\n",
       " 'dm_nfnet_f5',\n",
       " 'dm_nfnet_f6',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_nfnet_l0',\n",
       " 'eca_nfnet_l1',\n",
       " 'eca_vovnet39b',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet200d',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'ecaresnext26t_32x4d',\n",
       " 'ecaresnext50t_32x4d',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b2a',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b3a',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_b8',\n",
       " 'efficientnet_cc_b0_4e',\n",
       " 'efficientnet_cc_b0_8e',\n",
       " 'efficientnet_cc_b1_8e',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_l2',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnet_lite1',\n",
       " 'efficientnet_lite2',\n",
       " 'efficientnet_lite3',\n",
       " 'efficientnet_lite4',\n",
       " 'efficientnetv2_l',\n",
       " 'efficientnetv2_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'efficientnetv2_s',\n",
       " 'ens_adv_inception_resnet_v2',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet19b_slim',\n",
       " 'ese_vovnet19b_slim_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'ese_vovnet39b_evos',\n",
       " 'ese_vovnet57b',\n",
       " 'ese_vovnet99b',\n",
       " 'ese_vovnet99b_iabn',\n",
       " 'fbnetc_100',\n",
       " 'gernet_l',\n",
       " 'gernet_m',\n",
       " 'gernet_s',\n",
       " 'ghostnet_050',\n",
       " 'ghostnet_100',\n",
       " 'ghostnet_130',\n",
       " 'gluon_inception_v3',\n",
       " 'gluon_resnet18_v1b',\n",
       " 'gluon_resnet34_v1b',\n",
       " 'gluon_resnet50_v1b',\n",
       " 'gluon_resnet50_v1c',\n",
       " 'gluon_resnet50_v1d',\n",
       " 'gluon_resnet50_v1s',\n",
       " 'gluon_resnet101_v1b',\n",
       " 'gluon_resnet101_v1c',\n",
       " 'gluon_resnet101_v1d',\n",
       " 'gluon_resnet101_v1s',\n",
       " 'gluon_resnet152_v1b',\n",
       " 'gluon_resnet152_v1c',\n",
       " 'gluon_resnet152_v1d',\n",
       " 'gluon_resnet152_v1s',\n",
       " 'gluon_resnext50_32x4d',\n",
       " 'gluon_resnext101_32x4d',\n",
       " 'gluon_resnext101_64x4d',\n",
       " 'gluon_senet154',\n",
       " 'gluon_seresnext50_32x4d',\n",
       " 'gluon_seresnext101_32x4d',\n",
       " 'gluon_seresnext101_64x4d',\n",
       " 'gluon_xception65',\n",
       " 'halonet26t',\n",
       " 'halonet50ts',\n",
       " 'halonet_h1',\n",
       " 'halonet_h1_c4c5',\n",
       " 'hardcorenas_a',\n",
       " 'hardcorenas_b',\n",
       " 'hardcorenas_c',\n",
       " 'hardcorenas_d',\n",
       " 'hardcorenas_e',\n",
       " 'hardcorenas_f',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w64',\n",
       " 'ig_resnext101_32x8d',\n",
       " 'ig_resnext101_32x16d',\n",
       " 'ig_resnext101_32x32d',\n",
       " 'ig_resnext101_32x48d',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'lambda_resnet26t',\n",
       " 'lambda_resnet50t',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'mixer_b16_224',\n",
       " 'mixer_b16_224_in21k',\n",
       " 'mixer_b32_224',\n",
       " 'mixer_l16_224',\n",
       " 'mixer_l16_224_in21k',\n",
       " 'mixer_l32_224',\n",
       " 'mixer_s16_224',\n",
       " 'mixer_s16_glu_224',\n",
       " 'mixer_s32_224',\n",
       " 'mixnet_l',\n",
       " 'mixnet_m',\n",
       " 'mixnet_s',\n",
       " 'mixnet_xl',\n",
       " 'mixnet_xxl',\n",
       " 'mnasnet_050',\n",
       " 'mnasnet_075',\n",
       " 'mnasnet_100',\n",
       " 'mnasnet_140',\n",
       " 'mnasnet_a1',\n",
       " 'mnasnet_b1',\n",
       " 'mnasnet_small',\n",
       " 'mobilenetv2_100',\n",
       " 'mobilenetv2_110d',\n",
       " 'mobilenetv2_120d',\n",
       " 'mobilenetv2_140',\n",
       " 'mobilenetv3_large_075',\n",
       " 'mobilenetv3_large_100',\n",
       " 'mobilenetv3_large_100_miil',\n",
       " 'mobilenetv3_large_100_miil_in21k',\n",
       " 'mobilenetv3_rw',\n",
       " 'mobilenetv3_small_075',\n",
       " 'mobilenetv3_small_100',\n",
       " 'nasnetalarge',\n",
       " 'nf_ecaresnet26',\n",
       " 'nf_ecaresnet50',\n",
       " 'nf_ecaresnet101',\n",
       " 'nf_regnet_b0',\n",
       " 'nf_regnet_b1',\n",
       " 'nf_regnet_b2',\n",
       " 'nf_regnet_b3',\n",
       " 'nf_regnet_b4',\n",
       " 'nf_regnet_b5',\n",
       " 'nf_resnet26',\n",
       " 'nf_resnet50',\n",
       " 'nf_resnet101',\n",
       " 'nf_seresnet26',\n",
       " 'nf_seresnet50',\n",
       " 'nf_seresnet101',\n",
       " 'nfnet_f0',\n",
       " 'nfnet_f0s',\n",
       " 'nfnet_f1',\n",
       " 'nfnet_f1s',\n",
       " 'nfnet_f2',\n",
       " 'nfnet_f2s',\n",
       " 'nfnet_f3',\n",
       " 'nfnet_f3s',\n",
       " 'nfnet_f4',\n",
       " 'nfnet_f4s',\n",
       " 'nfnet_f5',\n",
       " 'nfnet_f5s',\n",
       " 'nfnet_f6',\n",
       " 'nfnet_f6s',\n",
       " 'nfnet_f7',\n",
       " 'nfnet_f7s',\n",
       " 'nfnet_l0',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'pnasnet5large',\n",
       " 'regnetx_002',\n",
       " 'regnetx_004',\n",
       " 'regnetx_006',\n",
       " 'regnetx_008',\n",
       " 'regnetx_016',\n",
       " 'regnetx_032',\n",
       " 'regnetx_040',\n",
       " 'regnetx_064',\n",
       " 'regnetx_080',\n",
       " 'regnetx_120',\n",
       " 'regnetx_160',\n",
       " 'regnetx_320',\n",
       " 'regnety_002',\n",
       " 'regnety_004',\n",
       " 'regnety_006',\n",
       " 'regnety_008',\n",
       " 'regnety_016',\n",
       " 'regnety_032',\n",
       " 'regnety_040',\n",
       " 'regnety_064',\n",
       " 'regnety_080',\n",
       " 'regnety_120',\n",
       " 'regnety_160',\n",
       " 'regnety_320',\n",
       " 'repvgg_a2',\n",
       " 'repvgg_b0',\n",
       " 'repvgg_b1',\n",
       " 'repvgg_b1g4',\n",
       " 'repvgg_b2',\n",
       " 'repvgg_b2g4',\n",
       " 'repvgg_b3',\n",
       " 'repvgg_b3g4',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2next50',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet26t',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50d',\n",
       " 'resnet50t',\n",
       " 'resnet101',\n",
       " 'resnet101d',\n",
       " 'resnet152',\n",
       " 'resnet152d',\n",
       " 'resnet200',\n",
       " 'resnet200d',\n",
       " 'resnetblur18',\n",
       " 'resnetblur50',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50x1_bitm',\n",
       " 'resnetv2_50x1_bitm_in21k',\n",
       " 'resnetv2_50x3_bitm',\n",
       " 'resnetv2_50x3_bitm_in21k',\n",
       " 'resnetv2_101x1_bitm',\n",
       " 'resnetv2_101x1_bitm_in21k',\n",
       " 'resnetv2_101x3_bitm',\n",
       " 'resnetv2_101x3_bitm_in21k',\n",
       " 'resnetv2_152x2_bitm',\n",
       " 'resnetv2_152x2_bitm_in21k',\n",
       " 'resnetv2_152x4_bitm',\n",
       " 'resnetv2_152x4_bitm_in21k',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_64x4d',\n",
       " 'rexnet_100',\n",
       " 'rexnet_130',\n",
       " 'rexnet_150',\n",
       " 'rexnet_200',\n",
       " 'rexnetr_100',\n",
       " 'rexnetr_130',\n",
       " 'rexnetr_150',\n",
       " 'rexnetr_200',\n",
       " 'selecsls42',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'selecsls84',\n",
       " 'semnasnet_050',\n",
       " 'semnasnet_075',\n",
       " 'semnasnet_100',\n",
       " 'semnasnet_140',\n",
       " 'senet154',\n",
       " 'seresnet18',\n",
       " 'seresnet34',\n",
       " 'seresnet50',\n",
       " 'seresnet50t',\n",
       " 'seresnet101',\n",
       " 'seresnet152',\n",
       " 'seresnet152d',\n",
       " 'seresnet200d',\n",
       " 'seresnet269d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext26tn_32x4d',\n",
       " 'seresnext50_32x4d',\n",
       " 'seresnext101_32x4d',\n",
       " 'seresnext101_32x8d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnet50',\n",
       " 'skresnet50d',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100',\n",
       " 'ssl_resnet18',\n",
       " 'ssl_resnet50',\n",
       " 'ssl_resnext50_32x4d',\n",
       " 'ssl_resnext101_32x4d',\n",
       " 'ssl_resnext101_32x8d',\n",
       " 'ssl_resnext101_32x16d',\n",
       " 'swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window7_224_in22k',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_base_patch4_window12_384_in22k',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window7_224_in22k',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_large_patch4_window12_384_in22k',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224',\n",
       " 'swinnet26t_256',\n",
       " 'swinnet50ts_256',\n",
       " 'swsl_resnet18',\n",
       " 'swsl_resnet50',\n",
       " 'swsl_resnext50_32x4d',\n",
       " 'swsl_resnext101_32x4d',\n",
       " 'swsl_resnext101_32x8d',\n",
       " 'swsl_resnext101_32x16d',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b0_ap',\n",
       " 'tf_efficientnet_b0_ns',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b1_ap',\n",
       " 'tf_efficientnet_b1_ns',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b2_ap',\n",
       " 'tf_efficientnet_b2_ns',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b3_ap',\n",
       " 'tf_efficientnet_b3_ns',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b4_ap',\n",
       " 'tf_efficientnet_b4_ns',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b5_ap',\n",
       " 'tf_efficientnet_b5_ns',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b6_ap',\n",
       " 'tf_efficientnet_b6_ns',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b7_ap',\n",
       " 'tf_efficientnet_b7_ns',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_b8_ap',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2_ns',\n",
       " 'tf_efficientnet_l2_ns_475',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_l_in21ft1k',\n",
       " 'tf_efficientnetv2_l_in21k',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_m_in21ft1k',\n",
       " 'tf_efficientnetv2_m_in21k',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_s_in21ft1k',\n",
       " 'tf_efficientnetv2_s_in21k',\n",
       " 'tf_inception_v3',\n",
       " 'tf_mixnet_l',\n",
       " 'tf_mixnet_m',\n",
       " 'tf_mixnet_s',\n",
       " 'tf_mobilenetv3_large_075',\n",
       " 'tf_mobilenetv3_large_100',\n",
       " 'tf_mobilenetv3_large_minimal_100',\n",
       " 'tf_mobilenetv3_small_075',\n",
       " 'tf_mobilenetv3_small_100',\n",
       " 'tf_mobilenetv3_small_minimal_100',\n",
       " 'tnt_b_patch16_224',\n",
       " 'tnt_s_patch16_224',\n",
       " 'tresnet_l',\n",
       " 'tresnet_l_448',\n",
       " 'tresnet_m',\n",
       " 'tresnet_m_448',\n",
       " 'tresnet_m_miil_in21k',\n",
       " 'tresnet_xl',\n",
       " 'tresnet_xl_448',\n",
       " 'tv_densenet121',\n",
       " 'tv_resnet34',\n",
       " 'tv_resnet50',\n",
       " 'tv_resnet101',\n",
       " 'tv_resnet152',\n",
       " 'tv_resnext50_32x4d',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_in21k',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_224_miil_in21k',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_224_in21k',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_r20_s16_224',\n",
       " 'vit_base_r26_s32_224',\n",
       " 'vit_base_r50_s16_224',\n",
       " 'vit_base_r50_s16_224_in21k',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_base_resnet26d_224',\n",
       " 'vit_base_resnet50_224_in21k',\n",
       " 'vit_base_resnet50_384',\n",
       " 'vit_base_resnet50d_224',\n",
       " 'vit_deit_base_distilled_patch16_224',\n",
       " 'vit_deit_base_distilled_patch16_384',\n",
       " 'vit_deit_base_patch16_224',\n",
       " 'vit_deit_base_patch16_384',\n",
       " 'vit_deit_small_distilled_patch16_224',\n",
       " 'vit_deit_small_patch16_224',\n",
       " 'vit_deit_tiny_distilled_patch16_224',\n",
       " 'vit_deit_tiny_patch16_224',\n",
       " 'vit_huge_patch14_224_in21k',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_224_in21k',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch32_224',\n",
       " 'vit_large_patch32_224_in21k',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_r20_s16_224',\n",
       " 'vit_small_r20_s16_p2_224',\n",
       " 'vit_small_r26_s32_224',\n",
       " 'vit_small_r_s16_p8_224',\n",
       " 'vit_small_resnet26d_224',\n",
       " 'vit_small_resnet50d_s16_224',\n",
       " 'vit_tiny_r_s16_p8_224',\n",
       " 'vovnet39a',\n",
       " 'vovnet57a',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2',\n",
       " 'xception',\n",
       " 'xception41',\n",
       " 'xception65',\n",
       " 'xception71']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "timm.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用effecientnet试试\n",
    "import timm\n",
    "class CustomResNext(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomResNext, self).__init__()\n",
    "        self.model = timm.create_model('resnext50_32x4d',pretrained=True)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Identity()\n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.model = models.resnet50(pretrained=True)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.model.conv1(input)\n",
    "        output = self.model.bn1(output)\n",
    "        output = self.model.relu(output)\n",
    "        output = self.model.maxpool(output)\n",
    "        output = self.model.layer1(output)\n",
    "        output = self.model.layer2(output)\n",
    "        output = self.model.layer3(output)\n",
    "        output = self.model.layer4(output)\n",
    "        output = self.model.avgpool(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomResNext(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
       "    (fc): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomResNext()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'unsqueeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-fd1f5059ccf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#augmented = A_transform(image = frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#frame = augmented['image']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'unsqueeze'"
     ]
    }
   ],
   "source": [
    "for frame in frame_list:\n",
    "    augmented = A_transform(image = frame)\n",
    "    frame = augmented['image']\n",
    "    pred = model(frame.unsqueeze(0))\n",
    "    pred = pred.view(-1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"./a\", frame_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 854 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a = np.load('./a.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 748 ms, sys: 68 ms, total: 816 ms\n",
      "Wall time: 816 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('a.npz','rb') as f:\n",
    "    a = np.load(f)\n",
    "    b = a['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 720, 1280, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 端到端训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from transformers import BertTokenizer\n",
    "import os\n",
    "import linecache\n",
    "import re\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import cv2\n",
    "import numpy as np\n",
    "class MultimodaRawDataset(Dataset):\n",
    "\n",
    "    def __init__(self,dataset_config,job='training'):\n",
    "        \n",
    "        self.text_max_len = dataset_config['text_max_len']\n",
    "        self.device = dataset_config['device']\n",
    "        self.data_num_per_sample = 4\n",
    "        if(job=='training'):\n",
    "            self.meta_path = dataset_config['train_raw_data_path']\n",
    "        elif(job=='valdation'):\n",
    "            self.meta_path = dataset_config['val_raw_data_path']\n",
    "        else:\n",
    "            self.meta_path = dataset_config['test_data_path']\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(dataset_config['bert_path'])\n",
    "        self.label2id = {}\n",
    "        with open(dataset_config['label_id_path'],'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip('\\r\\n')\n",
    "                line = line.split('\\t')\n",
    "                self.label2id[line[0]] = int(line[1])\n",
    "        self.A_transform = A.Compose([\n",
    "                # Resize(CFG.image_size, CFG.image_size),\n",
    "                A.RandomResizedCrop(256, 256),\n",
    "                A.Transpose(p=0.5),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.ShiftScaleRotate(p=0.5),\n",
    "                A.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],  # mean on ImageNet\n",
    "                    std=[0.229, 0.224, 0.225],  # std on ImageNet\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ])\n",
    "    def __getitem__(self, index):\n",
    "        # 1. 从train.txt读取对应 idx 的path\n",
    "        data_list = [] # 存储对于index的各个模态数据的路径和样本标签\n",
    "        for line_i in range(self.data_num_per_sample*index+1,self.data_num_per_sample*(index+1)):\n",
    "            line = linecache.getline(self.meta_path,line_i)\n",
    "            line = line.strip('\\r\\n')\n",
    "            data_list.append(line)\n",
    "        #print(data_list)\n",
    "        video,text_ids,text_attention_mask,label_ids = self.preprocess(data_list)\n",
    "        return video,text_ids,text_attention_mask,label_ids\n",
    "    def __len__(self):\n",
    "        # TODO 不能固定长度\n",
    "        with open(self.meta_path,'r') as f:\n",
    "            lines = f.readlines()\n",
    "        return len(lines)//self.data_num_per_sample\n",
    "    def preprocess(self,data_list):\n",
    "        \n",
    "        video_path,text_path,label = data_list\n",
    "        \n",
    "        #--------------- video ----------------#\n",
    "        \n",
    "        frame_list = self.frame_iterator_list(video_path)\n",
    "        \n",
    "        video = []\n",
    "        for frame in frame_list:\n",
    "            augmented = self.A_transform(image=frame)\n",
    "            video.append(augmented['image'].unsqueeze(0))\n",
    "        video = torch.cat(video,dim=0)# shape(len,channel,H,W)\n",
    "        #--------------- text ----------------#\n",
    "        text = ''\n",
    "        with open(text_path,'r') as f:\n",
    "            for line in f:\n",
    "                dic = eval(line)\n",
    "           \n",
    "        for key in dic:\n",
    "            dic[key] = ''.join(re.findall('[\\u4e00-\\u9fa5]',dic[key]))\n",
    "            text += dic[key]\n",
    "        \n",
    "        # text = ''.join(re.findall('[\\u4e00-\\u9fa5]',dic['video_asr']))\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            max_length=self.text_max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        text_ids = inputs['input_ids']\n",
    "        text_attention_mask = inputs['attention_mask']\n",
    "        text_ids = torch.tensor(np.array(text_ids).astype('int64'))\n",
    "        text_attention_mask = torch.tensor(np.array(text_attention_mask).astype('int64'))\n",
    "        #--------------- label ----------------#\n",
    "        label_ids = []\n",
    "        label = label.split(',')\n",
    "        np.random.shuffle(label)\n",
    "        for i in label:\n",
    "            label_ids.append(self.label2id[i])\n",
    "        # label_ids = torch.tensor(np.array(label_ids).astype('int64'))\n",
    "        dense_label_ids = torch.zeros(82)# ,dtype=torch.int64)\n",
    "        dense_label_ids[label_ids] = 1\n",
    "        # return video,audio,label_ids\n",
    "        return video,text_ids,text_attention_mask,dense_label_ids\n",
    "    \n",
    "    def collate_fn(self,batch):\n",
    "        # 自定义dataloader 对一个batch的处理方式\n",
    "        # 需要完成的任务有：\n",
    "        # 1. 对video和audio的序列进行padding\n",
    "        # 2. 对text，label_ids同样padding\n",
    "        video_stacks = []\n",
    "        text_stacks = []\n",
    "        label_stacks = []\n",
    "        text_attention_stacks = []\n",
    "        for i in batch:\n",
    "            video_stacks.append(i[0])\n",
    "            text_stacks.append(i[1])\n",
    "            text_attention_stacks.append(i[2])\n",
    "            label_stacks.append(i[3])\n",
    "        \n",
    "        video_stacks = pad_sequence(video_stacks,batch_first=True,padding_value=0)\n",
    "        text_stacks = pad_sequence(text_stacks,batch_first=True,padding_value=0) # 实际上没有pad\n",
    "        # 实际上并没有padding，因为label变成multi-hot向量，长度都是82\n",
    "        label_stacks = pad_sequence(label_stacks,batch_first=True,padding_value=0) \n",
    "        text_attention_stacks = pad_sequence(text_attention_stacks,batch_first=True,padding_value=0) # 实际上也没有pad\n",
    "        return video_stacks,text_stacks,text_attention_stacks,label_stacks\n",
    "    \n",
    "    def frame_iterator_list(self,filename, every_ms=1000, max_num_frames=300):\n",
    "        video_capture = cv2.VideoCapture()\n",
    "        if not video_capture.open(filename):\n",
    "            print(sys.stderr, 'Error: Cannot open video file ' + filename)\n",
    "            return\n",
    "        last_ts = -99999  # The timestamp of last retrieved frame.\n",
    "        num_retrieved = 0\n",
    "\n",
    "        frame_all = []\n",
    "        while num_retrieved < max_num_frames:\n",
    "            # Skip frames\n",
    "            while video_capture.get(cv2.CAP_PROP_POS_MSEC) < every_ms + last_ts:\n",
    "                if not video_capture.read()[0]:\n",
    "                    return frame_all\n",
    "\n",
    "            last_ts = video_capture.get(cv2.CAP_PROP_POS_MSEC)\n",
    "            has_frames, frame = video_capture.read()\n",
    "            if not has_frames:\n",
    "                break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_all.append(frame[:, :, ::-1])\n",
    "            num_retrieved += 1\n",
    "\n",
    "        return frame_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/ipykernel/__main__.py:4: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "config_path = './config/config.yaml'\n",
    "config = yaml.load(open(config_path))\n",
    "train_dataset = MultimodaRawDataset(config['DatasetConfig'],job='training')\n",
    "dataloader = DataLoader(train_dataset,batch_size=4,num_workers=4,collate_fn=train_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "it = iter(dataloader)\n",
    "batch = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "video,text_ids,text_attention_mask,dense_label_ids = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from src.video_head.nextvlad import NeXtVLAD\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "class RawNeXtVLAD(nn.Module):\n",
    "    def __init__(self,feature_size, max_frames, nextvlad_cluster_size, expansion, groups):\n",
    "        super(RawNeXtVLAD,self).__init__()\n",
    "        self.nextvlad = NeXtVLAD(feature_size, max_frames, nextvlad_cluster_size, expansion, groups)\n",
    "        self.resnet50 = models.resnet50(pretrained=True)\n",
    "        self.resnet50.fc = nn.Linear(2048,1024)\n",
    "        \n",
    "    def forward(self,input,mask=None):\n",
    "        # 输入图像shape (batch,len,channel,H,W)\n",
    "        B,S,C,H,W = input.shape\n",
    "        input = input.contiguous().view(B*S,C,H,W)\n",
    "        output = self.resnet50(input)\n",
    "        output = output.contiguous().view(B,S,-1)\n",
    "        if(mask!=None):\n",
    "            output = self.nextvlad(output,mask)\n",
    "        else:\n",
    "            output = self.nextvlad(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model = RawNeXtVLAD(1024,300,128,2,16)\n",
    "pred = model(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16384])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 57, 3, 256, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def  _modal_drop( x, rate=0.0, noise_shape=None):\n",
    "    \"\"\"模态dropout\"\"\"\n",
    "    random_scale = torch.rand(noise_shape)\n",
    "    keep_mask = (random_scale >= rate).type(x.dtype).to(x.device) # >= rate的才保留\n",
    "    ret = x * keep_mask\n",
    "    probs = keep_mask.type(torch.float32) # cast将张量进行类型转换\n",
    "    return ret, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_dict, prob_dict = _modal_drop(video, 0.2, [4,1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (video != 0).type(torch.float32).sum(dim=-1).sum(dim=-1).sum(dim=-1).type(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 57])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 生成raw_train_good.txt和raw_val_good.txt\n",
    "import os\n",
    "import linecache\n",
    "train_good_path = '../dataset/tagging/GroundTruth/datafile/val_good.txt'\n",
    "raw_train_good_path = '../dataset/tagging/GroundTruth/datafile/raw_val_good.txt'\n",
    "dataset_path = '../dataset/videos/video_5k/train_5k/'\n",
    "with open(raw_train_good_path,'w') as f:\n",
    "    for index in range(4500):\n",
    "        video_i = 6*index+1\n",
    "        text_i = 6*index+4\n",
    "        label_i = 6*index+5\n",
    "        video_line = linecache.getline(train_good_path,video_i)\n",
    "        video_line = video_line.strip('\\r\\n')\n",
    "        video_id = os.path.basename(video_line)[:-4]\n",
    "        video_raw_path = dataset_path+video_id+'.mp4'+'\\r\\n'\n",
    "        text_line = linecache.getline(train_good_path,text_i)\n",
    "        label_line = linecache.getline(train_good_path,label_i)\n",
    "        f.write(video_raw_path)\n",
    "        f.write(text_line)\n",
    "        f.write(label_line)\n",
    "        f.write('\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重新提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "def frame_iterator_list(filename, every_ms=1000, max_num_frames=300):\n",
    "    video_capture = cv2.VideoCapture()\n",
    "    if not video_capture.open(filename):\n",
    "        print(sys.stderr, 'Error: Cannot open video file ' + filename)\n",
    "        return\n",
    "    last_ts = -99999  # The timestamp of last retrieved frame.\n",
    "    num_retrieved = 0\n",
    "\n",
    "    frame_all = []\n",
    "    while num_retrieved < max_num_frames:\n",
    "        # Skip frames\n",
    "        while video_capture.get(cv2.CAP_PROP_POS_MSEC) < every_ms + last_ts:\n",
    "            if not video_capture.read()[0]:\n",
    "                return np.array(frame_all)\n",
    "\n",
    "        last_ts = video_capture.get(cv2.CAP_PROP_POS_MSEC)\n",
    "        has_frames, frame = video_capture.read()\n",
    "        if not has_frames:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_all.append(frame[:, :, ::-1])\n",
    "        num_retrieved += 1\n",
    "\n",
    "    return np.array(frame_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_py3",
   "language": "python",
   "name": "conda_pytorch_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
