{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "config_path = './config/config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/ipykernel/__main__.py:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "config = yaml.load(open(config_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset和dataloader 定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import dataloader.dataloader\n",
    "importlib.reload(dataloader.dataloader)\n",
    "from dataloader.dataloader import MultimodaFeaturesDataset\n",
    "dataset = MultimodaFeaturesDataset(config['DatasetConfig'],job='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(dataset,num_workers=0,batch_size=config['DatasetConfig']['batch_size'],collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteor = iter(loader)\n",
    "batch = next(iteor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "video,audio,text,label = batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization: xavier\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import src.model.baseline_model\n",
    "importlib.reload(src.model.baseline_model)\n",
    "from src.model.baseline_model import Baseline\n",
    "model = Baseline(config['ModelConfig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.loss.loss_compute\n",
    "importlib.reload(src.loss.loss_compute)\n",
    "from src.loss.loss_compute import SimpleLossCompute\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "criterion = nn.BCELoss(reduction='sum')# sum应该没问题吧\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_compute = SimpleLossCompute(criterion,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (1):   0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video\n",
      "after nextvlad shape:  torch.Size([32, 16384])\n",
      "after SE shape:  torch.Size([32, 1024])\n",
      "audio\n",
      "after nextvlad shape:  torch.Size([32, 1024])\n",
      "after SE shape:  torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (1):   0%|          | 0/157 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import src.loop.run_epoch\n",
    "importlib.reload(src.loop.run_epoch)\n",
    "from src.loop.run_epoch import training_loop\n",
    "training_loop(model, loader, loss_compute, epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "for batch in loader:\n",
    "    video,audio,text,label = batch\n",
    "    inputs_dict={}\n",
    "    inputs_dict['video'] = video\n",
    "    inputs_dict['audio'] = audio\n",
    "    inputs_dict['text'] = text\n",
    "    inputs_dict['label'] = label\n",
    "    # 预测\n",
    "    pred = model(inputs_dict)\n",
    "    # 计算损失\n",
    "    #loss = loss_compute(pred['tagging_output_fusion']['predictions'],label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 1])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred['video_loss_weight'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ultis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '/Users/mafp/code/datasets/tagging_dataset_train_5k/train_full.txt'\n",
    "with open(train_data_path,'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file = './mac_train.txt'\n",
    "with open(new_file,'a') as f:\n",
    "    for line in lines:\n",
    "        path = line.rstrip('\\n')\n",
    "        new_path = path.replace('../dataset/tagging/','/Users/mafp/code/datasets/')\n",
    "        # print(new_path)\n",
    "        f.write(new_path+'\\n')\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)//6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/ipykernel/__main__.py:16: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization: xavier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train (0): 100%|██████████| 141/141 [00:16<00:00,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.27587278329643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "# from munch import Munch\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3,4,5,6,7'\n",
    "\n",
    "from dataloader.dataloader import MultimodaFeaturesDataset\n",
    "from src.loss.loss_compute import SimpleLossCompute\n",
    "from src.model.baseline_model import Baseline\n",
    "from src.loop.run_epoch import training_loop,validating_loop\n",
    "\n",
    "#torch.multiprocessing.set_start_method('spawn')\n",
    "config_path = './config/config.yaml'\n",
    "config = yaml.load(open(config_path))\n",
    "# 定义数据集并封装dataloader\n",
    "dataset = MultimodaFeaturesDataset(config['DatasetConfig'],job='training')\n",
    "loader = DataLoader(dataset,num_workers=8,batch_size=config['DatasetConfig']['batch_size'],collate_fn=dataset.collate_fn)\n",
    "# 定义模型\n",
    "model = Baseline(config['ModelConfig'])\n",
    "# model = torch.nn.DataParallel(model,[0,1])\n",
    "model.to(dataset.device)\n",
    "# 定义loss函数和优化器\n",
    "criterion = nn.BCELoss(reduction='none')# sum应该没问题吧\n",
    "# 不同部件采用不同的学习率\n",
    "\n",
    "classifier_params = list(map(id, model.classifier_dict.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in classifier_params,\n",
    "                     model.parameters())\n",
    "optimizer = torch.optim.Adam([\n",
    "            {'params': base_params},\n",
    "            {'params': model.classifier_dict.parameters(), 'lr': 1e-2}],lr=1e-4)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "loss_compute = SimpleLossCompute(criterion,optimizer)\n",
    "\n",
    "\n",
    "epoch_num=100\n",
    "loss_epoch = []\n",
    "for epoch in range(epoch_num):\n",
    "    loss = training_loop(model, loader, loss_compute, epoch)\n",
    "    loss_epoch.append(loss)\n",
    "    print(sum(loss_epoch[epoch])/157)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-b9da430cc202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'keys'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2e8481db70>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_mean_epoch = []\n",
    "for epoch in range(epoch_num):\n",
    "    loss_mean_epoch.append(sum(loss_epoch[epoch])/157)\n",
    "plt.plot(loss_mean_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'./checkpoint/temp.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gap:  0.9947396877274343\n",
      "gap:  0.9824204769295231\n",
      "gap:  0.9947389925049824\n",
      "gap:  0.9849995300545505\n",
      "gap:  0.9743947073137559\n",
      "gap:  0.9849504304974611\n",
      "gap:  0.9999030963690078\n",
      "gap:  0.9903641571057922\n",
      "gap:  0.9999239971563098\n",
      "gap:  0.9950859950859898\n",
      "gap:  0.9780105008492771\n",
      "gap:  0.9950555862671162\n",
      "gap:  0.9973495842419039\n",
      "gap:  0.9890720336062035\n",
      "gap:  0.9974100150560822\n",
      "gap:  0.9998819309566224\n",
      "gap:  0.9873112850150898\n",
      "gap:  1.0000000000000042\n",
      "gap:  0.9753570341275639\n",
      "gap:  0.9599348685717313\n",
      "gap:  0.97536325396137\n",
      "gap:  0.997566909975668\n",
      "gap:  0.9910614971280045\n",
      "gap:  0.997566909975668\n",
      "gap:  0.9973545157719649\n",
      "gap:  0.9884101056732897\n",
      "gap:  0.9973545157719649\n",
      "gap:  1.0000000000000075\n",
      "gap:  0.9866552715727663\n",
      "gap:  1.0000000000000075\n",
      "gap:  0.9799670391477386\n",
      "gap:  0.9719914960571758\n",
      "gap:  0.9800372004979281\n",
      "gap:  0.9997580394223576\n",
      "gap:  0.9866161166897337\n",
      "gap:  0.9998618080992486\n",
      "gap:  0.9999999999999989\n",
      "gap:  0.9909164478691321\n",
      "gap:  0.9999940944416874\n",
      "gap:  0.9898121371334503\n",
      "gap:  0.9792881670866114\n",
      "gap:  0.9898175013363163\n",
      "gap:  0.994974874371852\n",
      "gap:  0.9756920230552365\n",
      "gap:  0.994974874371852\n",
      "gap:  0.992366412213736\n",
      "gap:  0.9826565422631873\n",
      "gap:  0.992366412213736\n",
      "gap:  1.0000000000000075\n",
      "gap:  0.9863839017969807\n",
      "gap:  1.0000000000000075\n",
      "gap:  0.9944444444444415\n",
      "gap:  0.9805423155459064\n",
      "gap:  0.9944444444444415\n",
      "gap:  0.9999364336117395\n",
      "gap:  0.9870079283768259\n",
      "gap:  0.9999884569045917\n",
      "gap:  0.992457419133487\n",
      "gap:  0.9839404474981785\n",
      "gap:  0.9925560713063648\n",
      "gap:  0.9999933057530388\n",
      "gap:  0.9840487857782609\n",
      "gap:  1.0000000000000029\n",
      "gap:  0.9999522057250886\n",
      "gap:  0.9891249289334432\n",
      "gap:  0.9999727306813861\n",
      "gap:  0.9929035404944827\n",
      "gap:  0.9773491040808663\n",
      "gap:  0.9935299226359822\n",
      "gap:  0.9944674647608353\n",
      "gap:  0.9805548865274119\n",
      "gap:  0.9944903581267293\n",
      "gap:  0.99955504050858\n",
      "gap:  0.9627931680134849\n",
      "gap:  0.9997019360612374\n",
      "gap:  0.999999999999994\n",
      "gap:  0.9911018521369983\n",
      "gap:  0.999999999999994\n",
      "gap:  0.9948186528497439\n",
      "gap:  0.9850432180524911\n",
      "gap:  0.9948186528497439\n",
      "gap:  0.9939931604663218\n",
      "gap:  0.9784408658334668\n",
      "gap:  0.996455807197489\n",
      "gap:  0.9972146968923397\n",
      "gap:  0.9833899264342317\n",
      "gap:  0.9971383604828314\n",
      "gap:  0.9949874686716682\n",
      "gap:  0.9876085253287028\n",
      "gap:  0.9949874686716682\n",
      "gap:  1.0000000000000067\n",
      "gap:  0.9892980400455509\n",
      "gap:  1.0000000000000067\n",
      "gap:  1.0000000000000009\n",
      "gap:  0.9804532216490316\n",
      "gap:  1.0000000000000009\n",
      "gap:  0.99706648985477\n",
      "gap:  0.9903044413375639\n",
      "gap:  0.9971769823326584\n",
      "gap:  0.9999789479593497\n",
      "gap:  0.9962787143041402\n",
      "gap:  0.9999999999999941\n",
      "gap:  0.9999999999999931\n",
      "gap:  0.9836016479793808\n",
      "gap:  0.9999999999999931\n",
      "gap:  0.9951100244498704\n",
      "gap:  0.985283388833214\n",
      "gap:  0.9951100244498704\n",
      "gap:  0.9998889645895177\n",
      "gap:  0.9946069892434118\n",
      "gap:  0.9999756583006341\n",
      "gap:  1.0000000000000062\n",
      "gap:  0.9930495218392005\n",
      "gap:  1.0000000000000062\n",
      "gap:  0.999999999999997\n",
      "gap:  0.9925398343797645\n",
      "gap:  0.999999999999997\n",
      "gap:  0.9975062344139578\n",
      "gap:  0.9924334614661592\n",
      "gap:  0.9975062344139578\n",
      "gap:  0.9948979591836664\n",
      "gap:  0.9878276661811928\n",
      "gap:  0.9948717610688804\n",
      "gap:  0.9995555083574964\n",
      "gap:  0.9892216844856329\n",
      "gap:  0.9995658888647749\n",
      "gap:  0.9975490196078401\n",
      "gap:  0.9878499305086168\n",
      "gap:  0.9975490196078401\n",
      "gap:  0.997109826589602\n",
      "gap:  0.9822899390050175\n",
      "gap:  0.997109826589602\n",
      "gap:  0.9974619289340017\n",
      "gap:  0.9769576982748892\n",
      "gap:  0.9974619289340017\n",
      "gap:  0.9998281701605402\n",
      "gap:  0.9912960228332611\n",
      "gap:  0.9997830476145516\n",
      "gap:  0.9975369458128179\n",
      "gap:  0.9819827429316732\n",
      "gap:  0.9975369458128179\n",
      "gap:  0.9944598337950069\n",
      "gap:  0.981843388967168\n",
      "gap:  0.9944521391197222\n",
      "gap:  0.999999999999997\n",
      "gap:  0.9897204752518387\n",
      "gap:  0.9998749447928171\n",
      "gap:  0.9951296491345605\n",
      "gap:  0.9814689608435688\n",
      "gap:  0.9951695098310297\n",
      "gap:  0.9852155325970885\n",
      "gap:  0.9776419172302817\n",
      "gap:  0.9852216748768571\n",
      "gap:  1.0000000000000047\n",
      "gap:  0.9905311185666205\n",
      "gap:  0.9999872461180418\n",
      "gap:  0.9999999999999936\n",
      "gap:  0.98188238422005\n",
      "gap:  0.9999999999999936\n",
      "gap:  0.999999999999997\n",
      "gap:  0.9926713168720404\n",
      "gap:  0.999999999999997\n",
      "gap:  1.0000000000000033\n",
      "gap:  0.9936364880956657\n",
      "gap:  1.0000000000000033\n",
      "gap:  0.9998885607622399\n",
      "gap:  0.9892634572149203\n",
      "gap:  0.9999935418038988\n",
      "gap:  0.9999027139549775\n",
      "gap:  0.9896908076780925\n",
      "gap:  0.999944524095636\n",
      "gap:  0.9974160206718303\n",
      "gap:  0.9858355809114303\n",
      "gap:  0.9974160206718303\n",
      "gap:  0.9998211520483179\n",
      "gap:  0.9806977329164644\n",
      "gap:  0.9989011860988474\n",
      "gap:  0.9972602739725993\n",
      "gap:  0.9881501559265263\n",
      "gap:  0.9972376936994177\n",
      "gap:  0.9999933744997718\n",
      "gap:  0.9975272460392952\n",
      "gap:  0.9999342153253938\n",
      "gap:  0.9923273657289071\n",
      "gap:  0.9863278619950305\n",
      "gap:  0.9923273657289071\n",
      "gap:  0.9946524064171156\n",
      "gap:  0.9825523727317954\n",
      "gap:  0.9946524064171156\n",
      "gap:  0.9874056210701678\n",
      "gap:  0.9721726591324964\n",
      "gap:  0.987437185929641\n",
      "gap:  0.9999999999999927\n",
      "gap:  0.9932849421158437\n",
      "gap:  0.9999999999999927\n",
      "gap:  0.9999028462836212\n",
      "gap:  0.9896897524376609\n",
      "gap:  0.9999508084107807\n",
      "gap:  0.999999999999997\n",
      "gap:  0.9952349041042318\n",
      "gap:  0.9999934421929277\n",
      "gap:  0.9999999999999923\n",
      "gap:  0.9918351230765499\n",
      "gap:  0.9999782624447427\n",
      "gap:  0.9953649871089445\n",
      "gap:  0.9848979405406574\n",
      "gap:  0.9953107576053221\n",
      "gap:  0.9999999999999929\n",
      "gap:  0.9942333459462507\n",
      "gap:  0.9999999999999929\n",
      "gap:  1.0000000000000024\n",
      "gap:  0.9922114868236317\n",
      "gap:  1.0000000000000024\n",
      "gap:  1.0000000000000067\n",
      "gap:  0.9935613884710599\n",
      "gap:  1.0000000000000067\n",
      "gap:  0.9864130434782546\n",
      "gap:  0.9787709799662968\n",
      "gap:  0.9864130434782546\n",
      "gap:  0.9950980392156833\n",
      "gap:  0.9895123987307853\n",
      "gap:  0.9950980392156833\n",
      "gap:  0.9756610329282491\n",
      "gap:  0.9669038488999047\n",
      "gap:  0.9757382004466273\n",
      "gap:  0.9946380697050944\n",
      "gap:  0.9901245186521969\n",
      "gap:  0.9946380697050944\n",
      "gap:  0.9999576156687792\n",
      "gap:  0.9793074503853952\n",
      "gap:  0.9999999999999941\n",
      "gap:  0.9953810623556534\n",
      "gap:  0.9868181138023105\n",
      "gap:  0.9953810623556534\n",
      "gap:  0.9974875930511532\n",
      "gap:  0.99172678308841\n",
      "gap:  0.9974875930511532\n",
      "gap:  0.9971671388102062\n",
      "gap:  0.9919743231021005\n",
      "gap:  0.997102776967584\n",
      "gap:  0.9976020542174516\n",
      "gap:  0.9928629321550821\n",
      "gap:  0.997607696220888\n",
      "gap:  0.9949494949494884\n",
      "gap:  0.9813167621273237\n",
      "gap:  0.9949494949494884\n",
      "gap:  0.999999999999997\n",
      "gap:  0.9877223652307616\n",
      "gap:  0.999999999999997\n",
      "gap:  0.9838709677419347\n",
      "gap:  0.9771245243137745\n",
      "gap:  0.9838709677419347\n",
      "gap:  0.9949238904021838\n",
      "gap:  0.9828840553386373\n",
      "gap:  0.9949367088607641\n",
      "gap:  0.9999999999999954\n",
      "gap:  0.9946292736118214\n",
      "gap:  0.9999999999999954\n",
      "gap:  0.9948120618545615\n",
      "gap:  0.9897781931969136\n",
      "gap:  0.9947186525941633\n",
      "gap:  0.9999999999999942\n",
      "gap:  0.9844077553180037\n",
      "gap:  0.9999999999999942\n",
      "gap:  0.9998470921387783\n",
      "gap:  0.9935506457761988\n",
      "gap:  0.9999054931985197\n",
      "gap:  0.9891008979205987\n",
      "gap:  0.973777415805538\n",
      "gap:  0.9890861484014922\n",
      "gap:  1.0000000000000042\n",
      "gap:  0.9900054952052075\n",
      "gap:  0.9999795484757974\n",
      "gap:  0.9999592061320893\n",
      "gap:  0.9907717848669217\n",
      "gap:  1.0000000000000044\n",
      "gap:  0.9999999999999931\n",
      "gap:  0.9927236204709069\n",
      "gap:  0.9999999999999931\n",
      "gap:  0.9998958041628934\n",
      "gap:  0.9925749726718532\n",
      "gap:  0.9999120023970891\n",
      "gap:  0.9996616386149475\n",
      "gap:  0.9783048619647349\n",
      "gap:  0.99970440106809\n",
      "gap:  0.9920634920634998\n",
      "gap:  0.9803030750566082\n",
      "gap:  0.9920634920634998\n",
      "gap:  0.9999876853357049\n",
      "gap:  0.9931477169406195\n",
      "gap:  0.9999570950461729\n",
      "gap:  0.9813261065944053\n",
      "gap:  0.9734228126344701\n",
      "gap:  0.9813333333333394\n",
      "gap:  0.9976076555023853\n",
      "gap:  0.9885300698595255\n",
      "gap:  0.9976019321901901\n",
      "gap:  0.9856799862307927\n",
      "gap:  0.9786313282509003\n",
      "gap:  0.9857142857142828\n",
      "gap:  1.0000000000000075\n",
      "gap:  0.9879959004804713\n",
      "gap:  1.0000000000000075\n",
      "gap:  0.997340425531909\n",
      "gap:  0.9865914858102548\n",
      "gap:  0.997340425531909\n",
      "gap:  0.9999999999999954\n",
      "gap:  0.9949406679437011\n",
      "gap:  0.9999999999999954\n",
      "gap:  0.9951690821256076\n",
      "gap:  0.9854880203176413\n",
      "gap:  0.9951690821256076\n",
      "gap:  0.9995878380602078\n",
      "gap:  0.9904934685302197\n",
      "gap:  0.9999046406271973\n",
      "gap:  0.9948849104859404\n",
      "gap:  0.9757340037250205\n",
      "gap:  0.9948849104859404\n",
      "gap:  0.9999999999999927\n",
      "gap:  0.998603094034307\n",
      "gap:  0.9999999999999927\n",
      "gap:  0.9918526262422904\n",
      "gap:  0.9866105426522546\n",
      "gap:  0.991974310599427\n",
      "gap:  0.9999817549322507\n",
      "gap:  0.9953966494068772\n",
      "gap:  0.9999513747523314\n",
      "gap:  0.9999933402594592\n",
      "gap:  0.9888379856446167\n",
      "gap:  0.9999866633102908\n",
      "gap:  0.997180865729252\n",
      "gap:  0.9810642791552594\n",
      "gap:  0.9973118279569885\n",
      "gap:  0.9874565020057382\n",
      "gap:  0.9788810903401175\n",
      "gap:  0.9873526666261534\n",
      "gap:  0.9972752043596795\n",
      "gap:  0.9845147108570385\n",
      "gap:  0.997267779848398\n",
      "gap:  0.9927536231884095\n",
      "gap:  0.9810819816856979\n",
      "gap:  0.9927536231884095\n",
      "gap:  1.00000000000001\n",
      "gap:  0.9886905893357454\n",
      "gap:  1.00000000000001\n",
      "gap:  0.9999999999999933\n",
      "gap:  0.9958289260005375\n",
      "gap:  0.9999999999999933\n",
      "gap:  1.0000000000000016\n",
      "gap:  0.9927246007924468\n",
      "gap:  1.0000000000000016\n",
      "gap:  1.0000000000000078\n",
      "gap:  0.9963959606439489\n",
      "gap:  1.0000000000000078\n",
      "gap:  0.9948717948717919\n",
      "gap:  0.9886249167616357\n",
      "gap:  0.9948717948717919\n",
      "gap:  0.999999999999997\n",
      "gap:  0.9962427650266366\n",
      "gap:  0.9999921756412032\n",
      "gap:  1.0000000000000075\n",
      "gap:  0.9933987033721036\n",
      "gap:  1.0000000000000075\n",
      "gap:  0.9922511457432527\n",
      "gap:  0.9832075912042115\n",
      "gap:  0.9922186178081132\n",
      "gap:  0.9975903614457772\n",
      "gap:  0.9931543381899904\n",
      "gap:  0.9975787347048342\n",
      "gap:  0.9926108374384336\n",
      "gap:  0.9842720569425402\n",
      "gap:  0.9926108374384336\n",
      "gap:  0.999840544985424\n",
      "gap:  0.9909478468064462\n",
      "gap:  0.9996970556778564\n",
      "gap:  0.9947042146578688\n",
      "gap:  0.980911500470668\n",
      "gap:  0.9946703079840362\n",
      "gap:  1.00000000000001\n",
      "gap:  0.9817370598113481\n",
      "gap:  1.00000000000001\n",
      "gap:  0.984320425470357\n",
      "gap:  0.9799940867311371\n",
      "gap:  0.9842648903373181\n",
      "gap:  0.9999567885230207\n",
      "gap:  0.9806664606736223\n",
      "gap:  0.9999505071554414\n",
      "gap:  0.9975062344139578\n",
      "gap:  0.995117389107914\n",
      "gap:  0.9975062344139578\n",
      "gap:  0.9927249525910655\n",
      "gap:  0.9856317753564222\n",
      "gap:  0.9927536230528938\n",
      "gap:  0.9928229665071701\n",
      "gap:  0.9908855255629032\n",
      "gap:  0.9928229665071701\n",
      "gap:  0.9999791692705156\n",
      "gap:  0.9953646547202866\n",
      "gap:  0.9999721705862682\n",
      "gap:  0.9974424552429737\n",
      "gap:  0.9896686201552307\n",
      "gap:  0.9974424552429737\n",
      "gap:  0.9922693014324135\n",
      "gap:  0.9868374348699458\n",
      "gap:  0.9923338062161395\n",
      "gap:  0.9923403642812479\n",
      "gap:  0.9883091395858075\n",
      "gap:  0.9923337057498066\n",
      "gap:  0.9974293059126036\n",
      "gap:  0.9908769776079647\n",
      "gap:  0.9974293059126036\n",
      "gap:  0.9999926756024351\n",
      "gap:  0.9879356405170303\n",
      "gap:  1.0000000000000033\n",
      "gap:  0.9825814274099346\n",
      "gap:  0.9695278302427531\n",
      "gap:  0.9825249204809849\n",
      "gap:  1.0000000000000007\n",
      "gap:  0.9915184046632766\n",
      "gap:  1.0000000000000007\n",
      "gap:  1.00000000000001\n",
      "gap:  0.9958839704371423\n",
      "gap:  1.00000000000001\n",
      "gap:  0.9797081843656438\n",
      "gap:  0.9711809911387146\n",
      "gap:  0.9797016426458256\n",
      "gap:  0.999899216072794\n",
      "gap:  0.9950001015463977\n",
      "gap:  0.9998652917313497\n",
      "gap:  0.9950859950859898\n",
      "gap:  0.9921740314087646\n",
      "gap:  0.9950859950859898\n",
      "gap:  0.9999999999999942\n",
      "gap:  0.9898994250032637\n",
      "gap:  0.9999999999999942\n",
      "gap:  0.98247591775559\n",
      "gap:  0.9711472085261778\n",
      "gap:  0.9800930858442698\n",
      "gap:  0.9974358974358944\n",
      "gap:  0.9898759284563614\n",
      "gap:  0.9974358974358944\n",
      "gap:  1.0000000000000047\n",
      "gap:  0.9919953414600273\n",
      "gap:  1.0000000000000047\n",
      "gap:  0.9999124979807282\n",
      "gap:  0.9939550988252398\n",
      "gap:  1.0000000000000056\n",
      "gap:  0.994565217391298\n",
      "gap:  0.9843799863808361\n",
      "gap:  0.994565217391298\n",
      "gap:  0.9999613469306311\n",
      "gap:  0.9972445145066849\n",
      "gap:  0.9999613469306311\n",
      "gap:  0.9950495049504958\n",
      "gap:  0.9901199101168606\n",
      "gap:  0.9950495049504958\n",
      "gap:  0.9999999999999947\n",
      "gap:  0.9927680787237309\n",
      "gap:  0.9999999999999947\n",
      "gap:  0.9999999999999941\n",
      "gap:  0.9940952890045907\n",
      "gap:  0.9999999999999941\n",
      "gap:  0.9975430854552971\n",
      "gap:  0.9862088683519169\n",
      "gap:  0.9975490342597113\n",
      "gap:  0.987437185929641\n",
      "gap:  0.9756021554242899\n",
      "gap:  0.987437185929641\n",
      "gap:  0.9999999999999988\n",
      "gap:  0.9999999999999988\n",
      "gap:  0.9999999999999988\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import utils.train_util as train_util\n",
    "model.eval()\n",
    "modal_name_list=['video','audio']\n",
    "tagging_class_num = 82\n",
    "evl_metrics = [train_util.EvaluationMetrics(tagging_class_num, top_k=20)\n",
    "                           for i in range(len(modal_name_list)+1)] #+1 for fusion\n",
    "for i in range(len(evl_metrics)):\n",
    "    evl_metrics[i].clear()\n",
    "\n",
    "criterion = nn.BCELoss(reduction='none')# sum应该没问题吧\n",
    "optimizer = None\n",
    "loss_compute = SimpleLossCompute(criterion,optimizer)\n",
    "\n",
    "for i,batch in enumerate(loader):\n",
    "    video,audio,text,label = batch\n",
    "    inputs_dict={}\n",
    "    inputs_dict['video'] = video\n",
    "    inputs_dict['audio'] = audio\n",
    "    inputs_dict['text'] = text\n",
    "    pred_dict = model(inputs_dict)\n",
    "    for index,modal_name in enumerate(modal_name_list+['fusion']):\n",
    "        pred = pred_dict['tagging_output_'+modal_name]\n",
    "        val_label = label\n",
    "        loss = loss_compute(pred['predictions'],val_label)\n",
    "        pred = pred['predictions'].detach().cpu().numpy()\n",
    "        val_label = label.cpu().numpy()\n",
    "        #print(np.array(pred_gap))\n",
    "        #print(val_label_gap)\n",
    "        gap = train_util.calculate_gap(pred, val_label)\n",
    "        print('gap: ',gap)\n",
    "        evl_metrics[index].accumulate(pred, val_label, loss=0)\n",
    "    if(i>500):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 3\n",
    "kf = GroupKFold(n_splits = N_FOLDS)\n",
    "for fold,(train_idx,val_idx) in enumerate(kf.split(df_train)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x7f2db0fc5308>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.split(range(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The 'groups' parameter should not be None.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-4db540668e5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mval_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mBy\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelegates\u001b[0m \u001b[0mto\u001b[0m \u001b[0m_iter_test_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0mtest_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mtest_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The 'groups' parameter should not be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The 'groups' parameter should not be None."
     ]
    }
   ],
   "source": [
    "train_indices = []\n",
    "val_indices = []\n",
    "for fold,(train_idx,val_idx) in enumerate(kf.split(range(5000))):\n",
    "    print(fold)\n",
    "    train_indices.append(train_idx)\n",
    "    val_indices.append(val_idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.9 * len(full_dataset))\n",
    "validation_size = len(full_dataset) - train_size\n",
    "train_dataset, validation_dataset = random_split(full_dataset, [train_size, validation_size])\n",
    "\n",
    "#full_loader = DataLoader(full_dataset, batch_size=4,sampler = sampler_(full_dataset), pin_memory=True) \n",
    "#train_loader = DataLoader(train_dataset, batch_size=4, sampler = sampler_(train_dataset))\n",
    "#val_loader = DataLoader(validation_dataset, batch_size=1, sampler = sampler_(validation_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import dataloader.dataloader\n",
    "importlib.reload(dataloader.dataloader)\n",
    "from dataloader.dataloader import MultimodaFeaturesDataset\n",
    "full_dataset = MultimodaFeaturesDataset(config['DatasetConfig'],job='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!./setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization: Kaiming\n",
      "train (0): 100%|██████████████████████████████| 141/141 [00:25<00:00,  5.57it/s]\n",
      "epoch(0)(video):  0.5122225717977138\n",
      "epoch(0)(fusion):  0.5163583389255177\n",
      "train (1): 100%|██████████████████████████████| 141/141 [00:23<00:00,  6.05it/s]\n",
      "train (2): 100%|██████████████████████████████| 141/141 [00:23<00:00,  6.00it/s]\n",
      "epoch(2)(video):  0.6485075505637847\n",
      "epoch(2)(fusion):  0.650922732256925\n",
      "train (3): 100%|██████████████████████████████| 141/141 [00:22<00:00,  6.23it/s]\n",
      "train (4): 100%|██████████████████████████████| 141/141 [00:23<00:00,  6.12it/s]\n",
      "epoch(4)(video):  0.6846402185257286\n",
      "epoch(4)(fusion):  0.6717679303888603\n",
      "train (5): 100%|██████████████████████████████| 141/141 [00:23<00:00,  6.06it/s]\n",
      "train (6): 100%|██████████████████████████████| 141/141 [00:22<00:00,  6.24it/s]\n",
      "epoch(6)(video):  0.6948710702830856\n",
      "epoch(6)(fusion):  0.6935592059455046\n",
      "train (7): 100%|██████████████████████████████| 141/141 [00:23<00:00,  6.02it/s]\n",
      "train (8): 100%|██████████████████████████████| 141/141 [00:24<00:00,  5.71it/s]\n",
      "epoch(8)(video):  0.7011356291544437\n",
      "epoch(8)(fusion):  0.6998639782814189\n",
      "train (9): 100%|██████████████████████████████| 141/141 [00:22<00:00,  6.14it/s]\n",
      "train (10): 100%|█████████████████████████████| 141/141 [00:24<00:00,  5.77it/s]\n",
      "epoch(10)(video):  0.7097102736614402\n",
      "epoch(10)(fusion):  0.7099776392103077\n",
      "train (11): 100%|█████████████████████████████| 141/141 [00:22<00:00,  6.24it/s]\n",
      "train (12): 100%|█████████████████████████████| 141/141 [00:23<00:00,  6.02it/s]\n",
      "epoch(12)(video):  0.7083539780888606\n",
      "epoch(12)(fusion):  0.708250261399148\n",
      "train (13): 100%|█████████████████████████████| 141/141 [00:24<00:00,  5.73it/s]\n",
      "train (14): 100%|█████████████████████████████| 141/141 [00:22<00:00,  6.17it/s]\n",
      "epoch(14)(video):  0.71697578831246\n",
      "epoch(14)(fusion):  0.7149114382865365\n",
      "train (15): 100%|█████████████████████████████| 141/141 [00:23<00:00,  6.06it/s]\n",
      "train (16): 100%|█████████████████████████████| 141/141 [00:23<00:00,  6.07it/s]\n",
      "epoch(16)(video):  0.7153851734869563\n",
      "epoch(16)(fusion):  0.7146565576081281\n",
      "train (17): 100%|█████████████████████████████| 141/141 [00:22<00:00,  6.14it/s]\n",
      "train (18): 100%|█████████████████████████████| 141/141 [00:23<00:00,  5.89it/s]\n",
      "epoch(18)(video):  0.7131830805258519\n",
      "epoch(18)(fusion):  0.7140667298419962\n",
      "train (19): 100%|█████████████████████████████| 141/141 [00:23<00:00,  6.05it/s]\n",
      "train (20): 100%|█████████████████████████████| 141/141 [00:23<00:00,  6.00it/s]\n",
      "epoch(20)(video):  0.7183806905427572\n",
      "epoch(20)(fusion):  0.7189081201887901\n",
      "train (21): 100%|█████████████████████████████| 141/141 [00:23<00:00,  6.03it/s]\n",
      "train (22): 100%|█████████████████████████████| 141/141 [00:23<00:00,  6.00it/s]\n",
      "epoch(22)(video):  0.7191182542450839\n",
      "epoch(22)(fusion):  0.7197486896881551\n",
      "train (23): 100%|█████████████████████████████| 141/141 [00:23<00:00,  5.97it/s]\n",
      "train (24): 100%|█████████████████████████████| 141/141 [00:23<00:00,  5.88it/s]\n",
      "epoch(24)(video):  0.713755928538971\n",
      "epoch(24)(fusion):  0.7118603453724398\n",
      "train (25): 100%|█████████████████████████████| 141/141 [00:24<00:00,  5.81it/s]\n",
      "train (26): 100%|█████████████████████████████| 141/141 [00:23<00:00,  6.01it/s]\n",
      "epoch(26)(video):  0.7143783261081459\n",
      "epoch(26)(fusion):  0.7130036524636436\n",
      "train (27): 100%|█████████████████████████████| 141/141 [00:22<00:00,  6.14it/s]\n",
      "train (28): 100%|█████████████████████████████| 141/141 [00:23<00:00,  6.05it/s]\n",
      "epoch(28)(video):  0.7160106207444584\n",
      "epoch(28)(fusion):  0.7130335043305516\n",
      "train (29): 100%|█████████████████████████████| 141/141 [00:22<00:00,  6.22it/s]\n",
      "train (30): 100%|█████████████████████████████| 141/141 [00:23<00:00,  6.02it/s]\n",
      "epoch(30)(video):  0.7114377387878549\n",
      "epoch(30)(fusion):  0.7123355619722248\n",
      "train (31): 100%|█████████████████████████████| 141/141 [00:23<00:00,  6.09it/s]\n",
      "train (32): 100%|█████████████████████████████| 141/141 [00:23<00:00,  6.01it/s]\n",
      "epoch(32)(video):  0.7091009855069947\n",
      "epoch(32)(fusion):  0.7075539284323508\n",
      "train (33): 100%|█████████████████████████████| 141/141 [00:23<00:00,  6.05it/s]\n",
      "train (34): 100%|█████████████████████████████| 141/141 [00:24<00:00,  5.87it/s]\n",
      "epoch(34)(video):  0.7136421599847178\n",
      "epoch(34)(fusion):  0.7100062868216137\n",
      "train (35): 100%|█████████████████████████████| 141/141 [00:23<00:00,  5.96it/s]\n",
      "train (36): 100%|█████████████████████████████| 141/141 [00:22<00:00,  6.26it/s]\n",
      "epoch(36)(video):  0.7145526636154869\n",
      "epoch(36)(fusion):  0.7166239370706196\n",
      "train (37): 100%|█████████████████████████████| 141/141 [00:23<00:00,  6.13it/s]\n",
      "train (38): 100%|█████████████████████████████| 141/141 [00:22<00:00,  6.18it/s]\n",
      "epoch(38)(video):  0.7125824322758335\n",
      "epoch(38)(fusion):  0.7129926512429595\n",
      "train (39): 100%|█████████████████████████████| 141/141 [00:25<00:00,  5.49it/s]\n",
      "train (40): 100%|█████████████████████████████| 141/141 [00:23<00:00,  6.11it/s]\n",
      "epoch(40)(video):  0.7103576659222747\n",
      "epoch(40)(fusion):  0.711369884424841\n",
      "train (41): 100%|█████████████████████████████| 141/141 [00:24<00:00,  5.87it/s]\n",
      "train (42):   0%|                                       | 0/141 [00:00<?, ?it/s]^C\n",
      "train (42):   0%|                                       | 0/141 [00:04<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 81, in <module>\n",
      "    loss = training_loop(model, train_loader, loss_compute, modal_name_list,train_dataset.device, epoch,TBoard)\n",
      "  File \"/home/tione/notebook/TAAC-2021/src/loop/run_epoch.py\", line 15, in training_loop\n",
      "    for i, batch in enumerate(tqdm(loader, desc=f'train ({epoch})')):\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/tqdm/std.py\", line 1129, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 279, in __iter__\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 719, in __init__\n",
      "    w.start()\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/context.py\", line 223, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/context.py\", line 284, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\n",
      "    super().__init__(process_obj)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 62, in _launch\n",
      "    f.write(fp.getbuffer())\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -W ignore main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import tensorboard as tensorboard\n",
    "TBoard = tensorboard.SummaryWriter(log_dir='./results/log')\n",
    "for i in range(10):\n",
    "    TBoard.add_scalar('debug/param_number', i, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "initialization: Kaiming\n",
      "train (0):   6%|█▌                          | 63/1125 [07:26<2:05:28,  7.09s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"end2end_main.py\", line 74, in <module>\n",
      "    loss = raw_training_loop(model, train_loader, loss_compute, modal_name_list,train_dataset.device, epoch)\n",
      "  File \"/home/tione/notebook/TAAC-2021/src/loop/run_epoch.py\", line 126, in raw_training_loop\n",
      "    loss.backward()\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/torch/tensor.py\", line 195, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 99, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 248.00 MiB (GPU 0; 31.72 GiB total capacity; 27.67 GiB already allocated; 242.88 MiB free; 30.45 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "!python -W ignore end2end_main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_loop(model, dataset,modal_name_list,device,epoch):\n",
    "    model.eval()\n",
    "    tagging_class_num = 82\n",
    "    evl_metrics = [train_util.EvaluationMetrics(tagging_class_num, top_k=20)\n",
    "                               for i in range(len(modal_name_list)+1)] #+1 for fusion\n",
    "    for i in range(len(evl_metrics)):\n",
    "        evl_metrics[i].clear()\n",
    "    metric_dict = {}\n",
    "    gap_dict = {}\n",
    "    for i in range(len(dataset)):\n",
    "        video,audio,text,text_mask,label = dataset[i]\n",
    "        \n",
    "        video = video.to(device)\n",
    "        audio = audio.to(device)\n",
    "        text = text.to(device)\n",
    "        text_mask = text_mask.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        inputs_dict={}\n",
    "        inputs_dict['video'] = video\n",
    "        inputs_dict['audio'] = audio\n",
    "        inputs_dict['text'] = text\n",
    "        inputs_dict['attention_mask'] = text_mask\n",
    "        \n",
    "        pred_dict = model(inputs_dict)\n",
    "        \n",
    "        pred_dict['tagging_output_fusion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "warm_up_epochs = 5\n",
    "max_num_epochs = 50\n",
    "warm_up_with_cosine_lr = lambda epoch: (epoch+1) / warm_up_epochs if epoch < warm_up_epochs \\\n",
    "    else 0.5 * ( math.cos((epoch - warm_up_epochs) /(max_num_epochs - warm_up_epochs) * math.pi) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = []\n",
    "for epoch in range(35):\n",
    "    lr.append(warm_up_with_cosine_lr(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl4lOX59vHvNZN9Yc0CBMIikRARQcLqLraFWgUrIqi4VGRRqlb9tfZta63WLtZWbYsCbqBVAXdscamKG4sSBCwwEzZBQmZIWGcgZL/fP2agaQjJJEzyzHJ9joODmcnD5HQOOfPwLNctxhiUUkpFFpvVAZRSSgWflrtSSkUgLXellIpAWu5KKRWBtNyVUioCabkrpVQE0nJXSqkIpOWulFIRSMtdKaUiUIxV3zgtLc306tXLqm+vlFJhac2aNXuNMelNbWdZuffq1YuCggKrvr1SSoUlEdkZyHZ6WEYppSKQlrtSSkUgLXellIpAWu5KKRWBtNyVUioCNVnuIvKsiJSIyIaTfF1E5K8islVEvhaRs4MfUymlVHMEsuc+HxjTyNfHAjn+X9OAJ089llJKqVPR5HXuxphPRaRXI5uMA543vvX6VolIBxHpaoxxBSljSNtYfIj3Nrib3M5mExJi7cTH2EiItZMQayM+xvd7Qoyd+Fgb7RNjyWiXQGp8DCLSBumVUpEqGDcxZQG76jwv8r92QrmLyDR8e/dkZ2cH4Vtb75H3CllWWEpTXdycpWoTYm1ktksgMzWBjHbxZLZLICPV93uPTonkZKbSLiH21IIrpSJaMMq9oVprsMqMMfOAeQD5+fkRsTK3w+Xlh4Oz+MvVgxrdrqbWUFldS3lVDeXVNVRU1VJeXUN5VS0VVTWUV9dysKySEk8FJd5y9ngq2OMpZ2Oxhw8dJRytqvmf9+vSLoGczBRyMlI5PTOFnMxUcjJTtPSVUkBwyr0I6FHneXegOAjvG/IOHKnE7Sknt2tqk9vabUJinJ3EOHuzv48xhsMV1ezxVLBz3xE27znMlj1eNpd4eenLnZRX1R7ftmv7BM7o1p6hvTqS36sjA7LaEx/T/O+plApvwSj3JcAsEVkIDAcORcvxdofbA0D/ru1a9fuICKkJsaQmxNI3I4XR/TOPf62m1rD7wFE2+8t+s9vL+qJDfODYA0BcjI1B3TuQ7y/7IdmdaJ+ke/dKRbomy11EXgYuBNJEpAj4NRALYIyZAywFvg9sBcqAm1orbKhxurwA5HZp3XJvjN0mZHdOIrtzEpfk/bf0S70VrNl5gIId+ynYeYB5n27niY99R8JOz0zhnL5pjM7NZFjvTsTF6O0OSkWaQK6WmdzE1w1wW9AShRGHy0NaShzpqfFWRzlBemo8YwZ0YcyALgAcraxhfdFBCnbs58sdB3jpi295bvkOUuJjOC8njYtzM7goN4O0lND7b1FKNZ9lI38jgdPtbfVDMsGSGGdnRJ/OjOjTGfCV/Ypte/nAUcJHzj28s8GNCAzq0YHRuRlcnJtJ/66pekmmUmFKy72Fqmtq2bzHy/Uje1odpUUS4+yM7p/J6P6ZGDOAjcUePnKW8KGzhEfe38wj72+mV+ckxg/OYvygLHqlJVsdWSnVDFruLbRj3xEqqmstPd4eLCLCgKz2DMhqz+2jcyjxlvORo4Ql64t5/MMtPPbBFgZnd+CHg7O4dGA3OiXHWR1ZKdUELfcWcvhPpobLYZnmyEhNYNKwbCYNy6b44FGWrC/mja9286u3NvKbtzdxYb8Mrhicxej+GSTE6mWWSoUiLfcWcrg8xNiE0zIi+3BFtw6JzLjgNKaf3weHy8ub63bz5trdfODYQ2p8DOMHZ3H9yJ7kZDZ9rb9Squ1oubeQ0+2lb0ZK1NwgJCLkdWtHXrd2/GxMLiu37eO1r4pYtHoXL6zayajTOnPDqF6Mzs0gxq6XViplNS33FnK6PAzr3cnqGJaw24Rzc9I4NyeNX17an4Wrd/Hiqp1Mf2ENWR0SuXZENpOGZuuxeaUspLtYLXCwrJLiQ+XkRuDx9ubqnBLPbRf15dOfXsSc64bQs3MSD79byIjff8jdi9fzddFBqyMqFZV0z70FnO7IPZnaUjF22/Gbprbs8fL8yp289lURr31VxLDenZh1UV/Oy0nT6+aVaiO6594CDpd/pkwXPYnYkJzMVB4cP4BV/280v/pBHt/uK+P6Z79k/OzlvL/RTW1tRAwEVSqkabm3gNPlpVNyaI4dCCXtEmK5+dzefPLTC/n9D8/kQFkV015Yw/f/+hlL1hdToyWvVKvRcm8Bp9ujt+Y3Q3yMncnDsvno7gt49OqzqK413P7yWi75yycsXr2Lyurapt9EKdUsWu7NVFNrKNzjjYg7U9tajN3GFYO78/6d5zPnurNJirPz09e+5qJHPmbhl99SXaMlr1SwaLk30459RyivqiVXj7e3mM0mjBnQlX/++Fyeu2koGe3iuff1/zDm8c94f6Mb05w1CZVSDdJybyZnBI8daGsiwkX9Mnh95ijmThmCMYZpL6xhwpyVrN6x3+p4SoW1gMpdRMaISKGIbBWRexv4ek8R+VBEvhaRj0Wke/CjhgaHy4PdJvTNSLE6SsQQEb53Rhfeu/N8/vDDMyk6UMZVc1YydUEBm/d4rY6nVFhqstxFxA7MBsYCecBkEcmrt9kjwPPGmIHAA8Dvgx00VDjdHk5LT9aBWa0gxm5j0rBsPr7nIn46ph9ffLOPMY99yk9fXU/xwaNWx1MqrASy5z4M2GqM2W6MqQQWAuPqbZMHfOh/vKyBr0cMh0tPpra2xDg7t17Yl0//7yJuPrc3b64t5qJHPubP7xdytLLG6nhKhYVAyj0L2FXneZH/tbrWA1f6H18BpIpI51OPF1oOHa1i98Gj5HbVk6ltoWNyHL+4NI+P7rmAsQO68LePtnLJXz7hnf+49KSrUk0IpNwbupi7/t+se4ALRGQtcAGwG6g+4Y1EpolIgYgUlJaWNjus1Qp17IAlundM4rFJg1k8fSSpCTHMfPErpjzzJVtL9Hi8UicTSLkXAT3qPO8OFNfdwBhTbIz5oTFmMPAL/2uH6r+RMWaeMSbfGJOfnp5+CrGt8d+xA1ruVhjWuxP//PG5/ObyM/i66CBjHvuM3y114C2vsjqaUiEnkHJfDeSISG8RiQMmAUvqbiAiaSJy7L1+Djwb3Jihwen20CEplsx2OnbAKjF2GzeM6sWyey5kwpDuPPXZdi7+8ye8sbZID9UoVUeT5W6MqQZmAe8BDmCxMWajiDwgIpf7N7sQKBSRzUAm8FAr5bWUw+Wlf5d2OnYgBHROiecPVw7kzVvPoVuHRH6yaD0T5648fuhMqWgnVu3t5Ofnm4KCAku+d0vU1BoG/Po9Jg3rwa8vO8PqOKqO2lrDq2uK+MO7TrzlVcy8sC+3XXRa1KySpaKLiKwxxuQ3tZ3eoRqgb/eXcbSqRk+mhiCbTZg4tAcf3HUBl57Zlb9+uIUf/PVz1uw8YHU0pSyj5R4gPZka+jolx/HYpME8d9NQjlRUM2HOCu5fspEjFSdcuKVUxNNyD5DT5cEmkJOpYwdC3UX9Mnj/rgu4fkRPFqzcwXcf/ZSPC0usjqVUm9JyD5DD7aVPeoqOHQgTKfEx/GbcAF6dMZKEWBs3Preanyxax/4jlVZHU6pNaLkHyOHy6JjfMDSkZyeW3nEet1/cl7fXFx+/w1WpSKflHgBPeRVFB47qydQwFR9j567v9uOft59Ltw4JzHzxK+5avA6P3vykIpiWewA2Hx87oHvu4Sy3Szten3kOP764L2+u3c3Yxz5j5bZ9VsdSqlVouQfg2JUyOg0y/MXF2Lj7u/14deYoYu3CNU+v4qF/baK8SqdNqsii5R4Ah9tLu4QYurZPsDqKCpKzszuy9I7zuHZ4Nk999g3j/r6cjcUnjENSKmxpuQfA4fLQv6uOHYg0SXEx/Hb8mTx301D2l1UyfvZynvh4KzW1OqNGhT8t9ybU1hoK3V49mRrBLuqXwft3ns9387rw8LuFXD13JUUHyqyOpdQp0XJvwq4DZZRV1ujJ1AjXMTmOv18zmMeuHkSh28v3H/+MdzfoJZMqfGm5N0FPpkYPEWH84Cz+dft59E5LZsY/vuK+tzboyVYVlrTcm+BwebEJnJ6pe+7RIrtzEq/MGMUt5/Xm+ZU7ueKJFWwrPWx1LKWaRcu9CQ6Xh15pySTG6diBaBIXY+MXl+bx7I35uA8d5bK/fc5ra4qsjqVUwLTcm+B0e3USZBS7ODeTd+44nwFZ7bn7lfXctXidTplUYSGgcheRMSJSKCJbReTeBr6eLSLLRGStiHwtIt8PftS2d7iimm/3l+lMmSjXpX0CL98ygjtG5/DG2t1c9vfP2VTssTqWUo1qstxFxA7MBsYCecBkEcmrt9kv8S2/NxjfGqtPBDuoFQrd/hnuehlk1LPbhJ9853RemjqCw+XVjH9iOQu//NbqWEqdVCB77sOArcaY7caYSmAhMK7eNgY41oDtgeLgRbSOw+WbKZOrl0Eqv5GndeadO85jeO9O3Pv6f/jZq1/r1TQqJAVS7lnArjrPi/yv1XU/cJ2IFAFLgR8HJZ3FnG4PqQkxZHVItDqKCiGdU+KZf9MwZl3Ul0UFu5gwZwW79utNTyq0BFLuDd1zX//+7MnAfGNMd+D7wAsicsJ7i8g0ESkQkYLS0tLmp21jDpfvZKqOHVD12W3CPd/rx9PX57NzXxmX/f1zXe1JhZRAyr0I6FHneXdOPOxyM7AYwBizEkgA0uq/kTFmnjEm3xiTn56e3rLEbeTY2AE9JKMac0leJm/POpcu7RK4af5qHv9gC7U6m0aFgEDKfTWQIyK9RSQO3wnTJfW2+RYYDSAi/fGVe+jvmjei6MBRDldU68lU1aReacm8ces5XDEoi0c/2MzNC1ZzqEwXAlHWarLcjTHVwCzgPcCB76qYjSLygIhc7t/sbuAWEVkPvAzcaIwJ690Xh/vY2AHdc1dNS4yz8+eJZ/Hg+AF8vnUvP/j7Z2zYrSOElXViAtnIGLMU34nSuq/dV+fxJuCc4EazltPlRQT6abmrAIkIU0b05Ixu7bjtxa+48skV/PHKgYwfXP/6A6Van96hehIOl4denZNJigvo559Sx52d3ZG3f3wuZ/XowJ2L1vH7dxw6I161OS33k3C6PXpIRrVYWko8/7h5ONcOz2buJ9uZumC1Lsit2pSWewOOVFSzc3+ZnkxVpyQuxsZDV5zJb8cP4LMtexk/eznbdbqkaiNa7g0o3OPFGD2ZqoLjuhE9+cfU4Rwsq2Lc7OV6PbxqE1ruDXD6xw7onrsKlhF9OvPWbeeQ1SGRH81fzVOfbifMLyhTIU7LvQEOl4eU+Bi6d9SxAyp4enRK4vVbR/G9M7rw0FIHdy9er3NpVKvRcm/AsZOpOnZABVtSXAyzrzmbn1xyOq+v3c3V81ZR4im3OpaKQFru9RhjcLp07IBqPTabcMclOcy5bgib3V7Gz15+fK1epYJFy72eogNH8erYAdUGxgzowiszRlJjDBOeXMEyp55oVcGj5V6P0+2f4a5L66k2MCCrPW/ddi690pK5ecFq5i//xupIKkJoudfjdOlMGdW2urRPYPH0kVycm8n9b2/i129toLqm1upYKsxpudfjcHvo2TmJ5HgdO6DaTnJ8DHOnDOGW83qzYOVOpj5fgFfvaFWnQMu9HqfLq3vtyhJ2m/CLS/P43RVn8tmWvVw1ZyW7Dx61OpYKU1rudZRVVvPNviN6MlVZ6prh2cy/aSi7Dx5l3N+Xs27XQasjqTCk5V7H5j2H/WMHtNyVtc7LSef1maNIjLNx9dyVvL/RbXUkFWa03Os4djI1T/fcVQjIyUzljVvPIbdrO6b/Yw3Pr9xhdSQVRgIqdxEZIyKFIrJVRO5t4OuPisg6/6/NIhKW/450uDwkx9l17IAKGWkp8bx8y3BG52Zw31sb+f1Sh67RqgLSZLmLiB2YDYwF8oDJIpJXdxtjzE+MMYOMMYOAvwGvt0bY1uZwe+nXJRWbTccOqNCRFBfD3Cn5XDcim7mfbueOReuoqNaZNKpxgey5DwO2GmO2G2MqgYXAuEa2n4xvHdWwYozB4fLoyVQVkuw24cFxA/jZmFzeXl/MlGe+1EW4VaMCKfcsYFed50X+104gIj2B3sBHJ/n6NBEpEJGC0tLS5mZtVcWHyvGWV5Or5a5ClIgw88LTeHzSINZ+e4Ar56yg6ECZ1bFUiAqk3Bs6RnGyg36TgFeNMQ3+m9EYM88Yk2+MyU9PTw80Y5s4djK1v17jrkLcuEFZPP+j4ezxlHPFEyvYsPuQ1ZFUCAqk3IuAHnWedweKT7LtJMLwkAxwfCpfPy13FQZGntaZ12aOItYmXD13JZ9sDq1/CSvrBVLuq4EcEektInH4CnxJ/Y1EpB/QEVgZ3Ihtw+H20qNTIqkJsVZHUSogp2em8sZt55DdOZmb56/mtTVFVkdSIaTJcjfGVAOzgPcAB7DYGLNRRB4QkcvrbDoZWGjCdO0wp8tDf715SYWZzHYJLJ4+guF9OnH3K+uZ9+k2qyOpEBHQdCxjzFJgab3X7qv3/P7gxWpb5VU1fLP3CJcO7GZ1FKWaLTUhlmdvHMpdi9fzu6VOSr0V/Hxsf72kN8rp6ENg8x4vtUZPpqrwFR9j52+TBpOWHMdTn33D3sOVPDxhILF2vQk9Wmm589+TqXqNuwpnNptw/+VnkNEugT+9V8i+I5U8ee3ZOr46SumPdcDh8pIYaye7U5LVUZQ6JSLCbRf15Y9XnsnnW0q55qlV7DtcYXUsZQEtd8Dp9ujYARVRrh6azdwp+TjdXq6as5Jd+/Vmp2gT9eXuGzvg1UMyKuJ8Jy+TF6cOZ+/hCq58csXxw48qOkR9ubs95Rw6WkX/rnoyVUWe/F6deHXmKGwiTJy7ktU79lsdSbWRqC93p8sL6MlUFblOz0zltVtHkZ4az5RnvmCZs8TqSKoNRH25b9KxAyoKZHVI5JXpI+mbkcItzxfw1rrdVkdSrSzqy93p9pLVIZF2OnZARbjOKfG8fMsIhvTsyJ2L1unKThEu6stdZ7iraJKaEMuCHw1jdG4m9721kcc/2EKYTgxRTYjqci+vqmF76WE9maqiSkKsnTnXnc2VZ3fn0Q8285u3N+nSfREoqm9d21pymFoDuTowTEWZGLuNP00YSPvEWJ5d/g2eo1X8UccVRJSoLvdNx8cO6J67ij42m/CrH/SnU3Isj7y/GU95FX+/5mwSYu1WR1NBENU/pp0uLwmxNnp2TrY6ilKWEBFmXZzDg+MH8KGzhOuf/RJvua7NGgmiutwdLg/9urTDrmMHVJSbMqInj109iK92HuDap7/gwJFKqyOpUxRQuYvIGBEpFJGtInLvSbaZKCKbRGSjiLwU3JjBZ4zB6fbomF+l/MYNymLulCE43V4mzl3JHk+51ZHUKWiy3EXEDswGxgJ5wGQRyau3TQ7wc+AcY8wZwJ2tkDWoSrwVHCirIlfLXanjRvfPZP5NQyk+eFQHjoW5QPbchwFbjTHbjTGVwEJgXL1tbgFmG2MOABhjQv7+5k06w12pBo06LY0XbxnBoaNVTJizgq0lXqsjqRYIpNyzgF11nhf5X6vrdOB0EVkuIqtEZEywAraWYzNl9DJIpU40qEcHFk0fQU0tTJy7ig27D1kdSTVTIOXe0NnG+nc8xAA5wIX4Fsp+WkQ6nPBGItNEpEBECkpLS5ubNaicbg/d2ifQPknHDijVkNwu7Xh1xkgSY+1MnrdKJ0qGmUDKvQjoUed5d6C4gW3eMsZUGWO+AQrxlf3/MMbMM8bkG2Py09PTW5o5KHTsgFJN65WWzCszRpLezjdR8pPN1u6UqcAFUu6rgRwR6S0iccAkYEm9bd4ELgIQkTR8h2m2BzNoMFVU17Ct9Ai5evOSUk3q1iGRxdNH0icthakLVvPuBpfVkVQAmix3Y0w1MAt4D3AAi40xG0XkARG53L/Ze8A+EdkELAP+zxizr7VCn6qtJYepqTW6565UgNJS4nl52ggGdu/ArS9+xetfFVkdSTUhoPEDxpilwNJ6r91X57EB7vL/CnkOPZmqVLO1T4zlhZuHccvzBdz9ynqOVtVw7fCeVsdSJxGVd6g6XR7iY2z06pxkdRSlwkpSXAzP3DCUi/tl8Is3NvD0ZyF79DXqRWW5O9we+nVJJUYn4CnVbAmxduZMGcKlA7vy2385dCZ8iIq6qZDGGBwuL5f0z7A6ilJhK9Zu46+TBpMYa+fRDzZTVlnNvWNzEdE5TaEi6sq99HAF+49U6vF2pU6R3SY8fOVAEmPtzP10O0cqq3ng8gHYdBBfSIi6cj92MlWvlFHq1NlswgPjziAp3s7cT7ZTVlnDw1cO1EOeISDqyt3pnymjA8OUCg4R4d4xuSTHxfCXf2+moqqWR68eRFyMFryVoq/c3V66tEugY3Kc1VGUihgiwu2jc0iKs/Pbfzk4WlXDE9fqqk5Wirofrb6xA7rXrlRrmHpeHx66YgDLCkuYuqCAsspqqyNFragq98rqWraWHCZXj7cr1WquHd6TRyacxYpte7lBl+2zTFSV+7bSw1Tr2AGlWt2VQ7rzt8lns/bbg1z39BccLNNl+9paVJW749gCHXoyValWd+nArsy5bggOl5dJ81ax93CF1ZGiSlSVu9PtJS7GRu+0ZKujKBUVLsnL5Jkb89mx7whX67qsbSqqyt3h8nB6Zopeg6tUGzovJ535Nw3DfaiciXNXUnRA12VtC1HVcg6XV+9MVcoCI/p05oWpwzlwpJKJc1ayY+8RqyNFvKgp91JvBXsPV+jNS0pZ5Ozsjrx0ywiOVtUwce5KtuzRhbdbU9SUu9PtO5map1fKKGWZAVntWTR9JLUGrp63io3FuvB2awmo3EVkjIgUishWEbm3ga/fKCKlIrLO/2tq8KOeGqd/pkw/3XNXylKnZ6byyoyRxMfYmDxvFet2HbQ6UkRqstxFxA7MBsYCecBkEclrYNNFxphB/l9PBznnKXO4PWSkxtM5Jd7qKEpFvd5pySyePpL2SbFc9/QXrN6x3+pIESeQPfdhwFZjzHZjTCWwEBjXurGCz+Hy6s1LSoWQHp2SWDx9JBmp8Vz/zJes2LrX6kgRJZByzwJ21Xle5H+tvitF5GsReVVEegQlXZBU1dSytcRLrs6UUSqkdG2fyKLpI8nulMSN81ezzFlidaSIEUi5NzR5v/6aWm8DvYwxA4EPgAUNvpHINBEpEJGC0tLS5iU9BdtLj1BVY/RkqlIhKD01npenjeD0zBSmvVDAuxvcVkeKCIGUexFQd0+8O1BcdwNjzD5jzLF7i58ChjT0RsaYecaYfGNMfnp6ekvytojj+Ax3LXelQlGn5DhenDqCAVntue2lr3hr3W6rI4W9QMp9NZAjIr1FJA6YBCypu4GIdK3z9HLAEbyIp87h9hBnt9EnXccOKBWq2ifG8sLNwxnSsyN3LlrH4oJdTf8hdVJNlrsxphqYBbyHr7QXG2M2isgDInK5f7PbRWSjiKwHbgdubK3ALeF0eembkUKsjh1QKqSlxMew4KZhnNs3jZ+++jUvrNxhdaSwFdBKTMaYpcDSeq/dV+fxz4GfBzda8DhcHs7NSbM6hlIqAIlxdp66Pp9ZL33Fr97aSHlVLbec38fqWGEn4ndl9x2uoMRbQX893q5U2EiItfPkdUO49MyuPLTUwV8/3IIx9a/jUI2J+DVUnW7fnal6jbtS4SXWbuPxSYOIj7Xxl39v5mhVDT/9Xj9EGrqAT9UX8eV+/EoZvcZdqbATY7fxyISzfHvyH2/jaGUNv74sTws+ABFf7k63l7SUeNJ07IBSYclmEx4aP4CEGDvPLv+GiuoaHhp/JjabFnxjIr7cHS4P/XWvXamwJiL86gf9SYyzMXvZNsqravnThIG68E4jIrrcq2tq2bLnMDee08vqKEqpUyQi/N/3ckmMtfPI+5spr6rh8UmDiYvRgm9IRH8q3+w9QmVNrS7QoVQEmXVxDr+8tD/vbHAz4x9rKK+qsTpSSIroct/kP5mqV8ooFVmmnteH344fwEfOEm5esJqyymqrI4WciC53p9tLrF04LT3F6ihKqSC7bkRPHrnqLFZu28f1z3yJp7zK6kghJbLL3eXhtPQUPSanVISaMKQ7f5t8Nut2HeTap77gwJFKqyOFjIhuPV2gQ6nId+nArsy7fgiFe7xMmreKEm+51ZFCQsSW+4Ejlbg95XoyVakocHFuJvNvHMquA2VMnLOS3QePWh3JchFb7g63nkxVKpqM6pvGCzcPY9+RSibOWcmOvUesjmSpiC13p8s3U0bHDigVPYb07MTLt4ygrLKaiXNXsmWP1+pIlonccnd76JwcR7qOHVAqqgzIas+i6SMxwMS5K9mw+5DVkSwRseV+7GSqDhhSKvqcnpnKK9NHkhQXw+SnVrFm5wGrI7W5gMpdRMaISKGIbBWRexvZboKIGBHJD17E5quuqWXzHq+eTFUqivVKS2bxjJF0To5jyjNf8PmWvVZHalNNlruI2IHZwFggD5gsInkNbJeKb4m9L4Idsrl27CujorqWXD2ZqlRUy+qQyOIZI8nulMSP5q/m/Y1uqyO1mUD23IcBW40x240xlcBCYFwD2z0IPAxYfpGp4/jYAd1zVyraZaQmsHDaCPp3a8fMF7/ijbVFVkdqE4GUexZQdxnyIv9rx4nIYKCHMeafjb2RiEwTkQIRKSgtLW122EA53R7sNqFvho4dUEpBh6Q4Xpw6nGG9OnHX4vW8sGqn1ZFaXSDl3tAZyeOLGYqIDXgUuLupNzLGzDPG5Btj8tPT0wNP2UxOl5e+6SnEx9hb7XsopcJLSnwMz900lIv7ZfCrNzfwxMdbrY7UqgIp9yKgR53n3YHiOs9TgQHAxyKyAxgBLLHypKrD5dHr25VSJ0iItTNnyhAuO6sbD79byMPvOiN24e1AFutYDeSISG9gNzAJuObYF40xh4C0Y89F5GPgHmNMQXCjBuZQWRXFh8rJ7aInU5VSJ4q123js6kGkxMfwxMfbOFxRzf2XnRFxy/Y1We7GmGoRmQW8B9iBZ40xG0XkAaDAGLOktUMEth6/AAALUUlEQVQ2x3/HDuieu1KqYXab8LsrBpCaEMO8T7dzuLyahyNs2b6AltkzxiwFltZ77b6TbHvhqcdqOacu0KGUCoCI8POxuaTGx/Dnf2/mcEU1f508mITYyDhXFzk/pvycbi8dk2LJSNWxA0qpxokIPx6dw/2X5fH+pj3c9NxqvBGy6EfElbvD5dGxA0qpZrnxnN48dvUgvtyxn2ue+oJ9hyusjnTKIqrca2oNhXu8ejJVKdVs4wdnMW/KEDbv8TJx7kqKw3wmfESV+859RyivqtWTqUqpFhndP5PnfzSMEk8FE55cwbbSw1ZHarGIKneHf4a7nkxVSrXU8D6deXnaCCprarlqTviODI6octexA0qpYBiQ1Z5XZowiMdbOpHmrWLltn9WRmi2iyt3h8tAnLTliLmVSSlmnd1oyr80cRdf2Cdzw3Jf8e9MeqyM1S4SVu1fH/CqlgqZL+wQWTx9J/67tmPGPNby6JnwmSkZMuXvKq9h98Kgu0KGUCqqOyXG8NHU4I/t05p5X1jPnk21hMY8mYsr92ILYebrnrpQKsuT4GJ69cSiXndWNP7zj5MF/OqitDe2CD2j8QDhw+mfK6DRIpVRriIux8fjVg0hLiePZ5d+w93AFj1x1FnExobmPHDHl7nB56ZAUS5d2CVZHUUpFKJtNuO8HeWSkJvDHd50cKKvkyeuGkBIfelUamj9yWsDh8pDbJVXHDiilWpWIMPPC0/jThIGs2LaPa55axd4QHFcQEeVeW2sodOvYAaVU27kqvwdPXe8bVzDhyRXs2l9mdaT/ERHlvnN/GUeravRkqlKqTV2cm8mLU0dw8GgVP3xyBRuLQ+du1ogo92Mz3PVkqlKqrQ3p2ZFXZ4wk1iZMmruKFdv2Wh0JCLDcRWSMiBSKyFYRubeBr88Qkf+IyDoR+VxE8oIf9eQcbi82gdMztdyVUm2vb0Yqr906iq4dErjh2S95c+1uqyM1Xe4iYgdmA2OBPGByA+X9kjHmTGPMIOBh4C9BT9oIh8tDbx07oJSyUNf2ibwyYxRDenbkzkXrmL1sq6U3OwWy5z4M2GqM2W6MqQQWAuPqbmCM8dR5mgy06X+R0+3RsQNKKcu1T4xlwY+GMW5QN/70XiG/fHMD1TW1lmQJ5OLMLGBXnedFwPD6G4nIbcBdQBxwcUNvJCLTgGkA2dnZzc3aIG95Fbv2H2XS0OC8n1JKnYr4GDuPThxEtw6JPPnxNtyHyvnbNYNJimvba+ED2XNv6MLxE/bMjTGzjTGnAT8DftnQGxlj5hlj8o0x+enp6c1LehKFbt/YAZ0po5QKFTab8LMxuTw47gyWFZYwed4qSr1tey18IOVeBPSo87w7UNzI9guB8acSqjkcx8pdD8sopULMlJG9mDsln8I9Xn745HK2t+HKToGU+2ogR0R6i0gcMAlYUncDEcmp8/RSYEvwIjbO4fLQLiGGbu117IBSKvR8Jy+Tl28ZQVlFDVc+uYI1O/e3yfdtstyNMdXALOA9wAEsNsZsFJEHRORy/2azRGSjiKzDd9z9hlZLXI/T5TuZqmMHlFKhanB2R16bOYr2ibFc89QXvL/R3erfM6Aj/MaYpcDSeq/dV+fxHUHOFZBjYwcmDOluxbdXSqmA9fKv7HT7wrVktMGAw9AbZdYMuw6UcaSyRhfEVkqFhc4p8fzj5uFtcqQhrMcPOFx6MlUpFV7a6hByWJe70+1BBPrp2AGllPofYV3uDpeH3p2TSYzTsQNKKVVXWJe70+3VSZBKKdWAsC33wxXV7NxXRn9doEMppU4QtuVeqHemKqXUSYVtuTvd/gU6dKaMUkqdIGzL3eHykBofQ/eOiVZHUUqpkBO25e50+U6m6tgBpZQ6UViWuzEGp9urd6YqpdRJhGW5Fx04yuGKanL1ShmllGpQWJa7w+U/marXuCulVIPCtNy9OnZAKaUaEZbl7nR76NkpieT4sB5qqZRSrSagcheRMSJSKCJbReTeBr5+l4hsEpGvReRDEekZ/Kj/5XR79Xi7Uko1oslyFxE7MBsYC+QBk0Ukr95ma4F8Y8xA4FXg4WAHPaasspod+47olTJKKdWIQPbchwFbjTHbjTGV+BbAHld3A2PMMmNMmf/pKnyLaLeKQrcXY/RkqlJKNSaQcs8CdtV5XuR/7WRuBt45lVCNcfpnyuTpnrtSSp1UIGckG7oF1DS4och1QD5wwUm+Pg2YBpCdnR1gxP/VOTmO7+RlktVBxw4opdTJBFLuRUCPOs+7A8X1NxKRS4BfABcYYyoaeiNjzDxgHkB+fn6DPyCa8t0zuvDdM7q05I8qpVTUCOSwzGogR0R6i0gcMAlYUncDERkMzAUuN8aUBD+mUkqp5miy3I0x1cAs4D3AASw2xmwUkQdE5HL/Zn8CUoBXRGSdiCw5ydsppZRqAwHdBWSMWQosrffafXUeXxLkXEoppU5BWN6hqpRSqnFa7kopFYG03JVSKgJpuSulVATScldKqQgkxrToXqJT/8YipcDOFv7xNGBvEOO0Bc3cNsItc7jlBc3cVk6WuacxJr2pP2xZuZ8KESkwxuRbnaM5NHPbCLfM4ZYXNHNbOdXMelhGKaUikJa7UkpFoHAt93lWB2gBzdw2wi1zuOUFzdxWTilzWB5zV0op1bhw3XNXSinViLAr96YW6w5FIrJDRP7jn5hZYHWehojIsyJSIiIb6rzWSUT+LSJb/L93tDJjXSfJe7+I7PZ/zutE5PtWZqxPRHqIyDIRcYjIRhG5w/96SH7OjeQN2c9ZRBJE5EsRWe/P/Bv/671F5Av/Z7zIP748JDSSeb6IfFPncx7UrDc2xoTNL8AObAP6AHHAeiDP6lwB5N4BpFmdo4mM5wNnAxvqvPYwcK//8b3AH63O2UTe+4F7rM7WSOauwNn+x6nAZnyLzofk59xI3pD9nPGtHJfifxwLfAGMABYDk/yvzwFmWp01gMzzgQktfd9w23NvcrFu1TLGmE+B/fVeHgcs8D9eAIxv01CNOEnekGaMcRljvvI/9uJbHyGLEP2cG8kbsozPYf/TWP8vA1wMvOp/PWQ+Y2g08ykJt3Jv7mLdocIA74vIGv86suEi0xjjAt9fdCDD4jyBmCUiX/sP24TE4Y2GiEgvYDC+vbSQ/5zr5YUQ/pxFxC4i64AS4N/4/rV/0PgWHoIQ7I36mY0xxz7nh/yf86MiEt+c9wy3cg94se4Qc44x5mxgLHCbiJxvdaAI9SRwGjAIcAF/tjZOw0QkBXgNuNMY47E6T1MayBvSn7MxpsYYMwjfes/DgP4Nbda2qRpXP7OIDAB+DuQCQ4FOwM+a857hVu4BLdYdaowxxf7fS4A38P0PFw72iEhXAP/vIb0+rjFmj/8vSS3wFCH4OYtILL6ifNEY87r/5ZD9nBvKGw6fM4Ax5iDwMb7j1x1E5NjKcyHbG3Uyj/EfFjPGmArgOZr5OYdbuTe5WHeoEZFkEUk99hj4LrCh8T8VMpYAN/gf3wC8ZWGWJh0rSL8rCLHPWUQEeAZwGGP+UudLIfk5nyxvKH/OIpIuIh38jxOBS/CdK1gGTPBvFjKfMZw0s7POD3zBd46gWZ9z2N3E5L/s6jF8V848a4x5yOJIjRKRPvj21sG3Zu1LoZhZRF4GLsQ3iW4P8GvgTXxXGWQD3wJXGWNC4iTmSfJeiO9QgcF3hdL0Y8eyQ4GInAt8BvwHqPW//P/wHccOuc+5kbyTCdHPWUQG4jthase387rYGPOA/+/hQnyHN9YC1/n3iC3XSOaPgHR8h6PXATPqnHht+n3DrdyVUko1LdwOyyillAqAlrtSSkUgLXellIpAWu5KKRWBtNyVUioCabkrpVQE0nJXSqkIpOWulFIR6P8DQ68UTl0NZTMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(lr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference.py:18: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(open(config_path))\n",
      "Some weights of the model checkpoint at ../pretrained/bert were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "initialization: Kaiming\n",
      "  0%|                                                  | 0/5000 [00:00<?, ?it/s]/opt/conda/envs/pytorch_py3/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:22<00:00, 35.03it/s]\n"
     ]
    }
   ],
   "source": [
    "!python inference.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_py3",
   "language": "python",
   "name": "conda_pytorch_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
